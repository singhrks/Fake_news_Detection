{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import nltk\nimport re\nimport string \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom numpy import array\nfrom numpy import asarray\nfrom numpy import zeros\nimport tensorflow as tf\nfrom tensorflow import keras\nimport keras\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom keras.preprocessing import text,sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Embedding,LSTM,Dropout","metadata":{"execution":{"iopub.status.busy":"2022-04-17T10:21:01.840925Z","iopub.execute_input":"2022-04-17T10:21:01.841908Z","iopub.status.idle":"2022-04-17T10:21:07.745708Z","shell.execute_reply.started":"2022-04-17T10:21:01.841777Z","shell.execute_reply":"2022-04-17T10:21:07.744977Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"pip install -q -U keras-tuner","metadata":{"execution":{"iopub.status.busy":"2022-04-17T10:21:07.747515Z","iopub.execute_input":"2022-04-17T10:21:07.747989Z","iopub.status.idle":"2022-04-17T10:21:18.682840Z","shell.execute_reply.started":"2022-04-17T10:21:07.747951Z","shell.execute_reply":"2022-04-17T10:21:18.682052Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import keras_tuner as kt","metadata":{"execution":{"iopub.status.busy":"2022-04-17T10:21:18.684706Z","iopub.execute_input":"2022-04-17T10:21:18.684992Z","iopub.status.idle":"2022-04-17T10:21:19.032921Z","shell.execute_reply.started":"2022-04-17T10:21:18.684953Z","shell.execute_reply":"2022-04-17T10:21:19.032103Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"real_data = pd.read_csv('../input/tf-data/True.csv')\nfake_data = pd.read_csv('../input/tf-data/Fake.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-17T10:21:19.035100Z","iopub.execute_input":"2022-04-17T10:21:19.035379Z","iopub.status.idle":"2022-04-17T10:21:21.093776Z","shell.execute_reply.started":"2022-04-17T10:21:19.035342Z","shell.execute_reply":"2022-04-17T10:21:21.093040Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"real_data['target'] = 1\nfake_data['target'] = 0","metadata":{"execution":{"iopub.status.busy":"2022-04-17T10:21:21.095276Z","iopub.execute_input":"2022-04-17T10:21:21.095541Z","iopub.status.idle":"2022-04-17T10:21:21.106700Z","shell.execute_reply.started":"2022-04-17T10:21:21.095505Z","shell.execute_reply":"2022-04-17T10:21:21.106002Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data = pd.concat([real_data, fake_data], ignore_index=True, sort=False)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-17T10:21:21.108167Z","iopub.execute_input":"2022-04-17T10:21:21.108809Z","iopub.status.idle":"2022-04-17T10:21:21.133697Z","shell.execute_reply.started":"2022-04-17T10:21:21.108771Z","shell.execute_reply":"2022-04-17T10:21:21.133082Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                               title  \\\n0  As U.S. budget fight looms, Republicans flip t...   \n1  U.S. military to accept transgender recruits o...   \n2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n3  FBI Russia probe helped by Australian diplomat...   \n4  Trump wants Postal Service to charge 'much mor...   \n\n                                                text       subject  \\\n0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n\n                 date  target  \n0  December 31, 2017        1  \n1  December 29, 2017        1  \n2  December 31, 2017        1  \n3  December 30, 2017        1  \n4  December 29, 2017        1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>text</th>\n      <th>subject</th>\n      <th>date</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>As U.S. budget fight looms, Republicans flip t...</td>\n      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n      <td>politicsNews</td>\n      <td>December 31, 2017</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>U.S. military to accept transgender recruits o...</td>\n      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n      <td>politicsNews</td>\n      <td>December 29, 2017</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n      <td>politicsNews</td>\n      <td>December 31, 2017</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>FBI Russia probe helped by Australian diplomat...</td>\n      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n      <td>politicsNews</td>\n      <td>December 30, 2017</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Trump wants Postal Service to charge 'much mor...</td>\n      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n      <td>politicsNews</td>\n      <td>December 29, 2017</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data['text']= data['subject'] + \" \" + data['title'] + \" \" + data['text']\ndel data['title']\ndel data['subject']\ndel data['date']\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-17T10:21:21.134757Z","iopub.execute_input":"2022-04-17T10:21:21.135156Z","iopub.status.idle":"2022-04-17T10:21:21.305779Z","shell.execute_reply.started":"2022-04-17T10:21:21.135119Z","shell.execute_reply":"2022-04-17T10:21:21.305094Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                text  target\n0  politicsNews As U.S. budget fight looms, Repub...       1\n1  politicsNews U.S. military to accept transgend...       1\n2  politicsNews Senior U.S. Republican senator: '...       1\n3  politicsNews FBI Russia probe helped by Austra...       1\n4  politicsNews Trump wants Postal Service to cha...       1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>politicsNews As U.S. budget fight looms, Repub...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>politicsNews U.S. military to accept transgend...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>politicsNews Senior U.S. Republican senator: '...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>politicsNews FBI Russia probe helped by Austra...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>politicsNews Trump wants Postal Service to cha...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.dropna()\ndata.fillna(\"\", inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T10:21:21.307142Z","iopub.execute_input":"2022-04-17T10:21:21.307451Z","iopub.status.idle":"2022-04-17T10:21:21.328286Z","shell.execute_reply.started":"2022-04-17T10:21:21.307406Z","shell.execute_reply":"2022-04-17T10:21:21.327642Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"pip install bs4","metadata":{"execution":{"iopub.status.busy":"2022-04-17T10:21:21.331254Z","iopub.execute_input":"2022-04-17T10:21:21.331444Z","iopub.status.idle":"2022-04-17T10:21:31.263824Z","shell.execute_reply.started":"2022-04-17T10:21:21.331421Z","shell.execute_reply":"2022-04-17T10:21:31.262976Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Collecting bs4\n  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from bs4) (4.10.0)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->bs4) (2.3.1)\nBuilding wheels for collected packages: bs4\n  Building wheel for bs4 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1271 sha256=c5b5373b5bf797a3c513d23b0f128bb2132f8ce847086b697636862951a63d09\n  Stored in directory: /root/.cache/pip/wheels/0a/9e/ba/20e5bbc1afef3a491f0b3bb74d508f99403aabe76eda2167ca\nSuccessfully built bs4\nInstalling collected packages: bs4\nSuccessfully installed bs4-0.0.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import nltk\nnltk.download('punkt')\nfrom bs4 import BeautifulSoup\nnltk.download(\"stopwords\")   \nfrom nltk.corpus import stopwords\nnltk.download('wordnet')","metadata":{"execution":{"iopub.status.busy":"2022-04-17T10:21:31.268040Z","iopub.execute_input":"2022-04-17T10:21:31.268261Z","iopub.status.idle":"2022-04-17T10:21:31.800019Z","shell.execute_reply.started":"2022-04-17T10:21:31.268234Z","shell.execute_reply":"2022-04-17T10:21:31.799270Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"def remove_characters(text):\n    return re.sub(\"[^a-zA-Z]\",\" \",text)\n\n#Removal of stopwords \ndef remove_stopwords_and_lemmatization(text):\n    final_text = []\n    text = text.lower()\n    text = nltk.word_tokenize(text)\n    \n    for word in text:\n        if word not in set(stopwords.words('english')):\n            lemma = nltk.WordNetLemmatizer()\n            word = lemma.lemmatize(word) \n            final_text.append(word)\n    return \" \".join(final_text)\n\n#Total function\ndef cleaning(text):\n    text = remove_characters(text)\n    text = remove_stopwords_and_lemmatization(text)\n    return text\n\n#Apply function on text column\ndata['text']=data['text'].apply(cleaning)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T10:21:31.801248Z","iopub.execute_input":"2022-04-17T10:21:31.801580Z","iopub.status.idle":"2022-04-17T11:04:17.062983Z","shell.execute_reply.started":"2022-04-17T10:21:31.801541Z","shell.execute_reply":"2022-04-17T11:04:17.062233Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"data=data.sample(frac=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T11:04:17.064285Z","iopub.execute_input":"2022-04-17T11:04:17.064540Z","iopub.status.idle":"2022-04-17T11:04:17.074356Z","shell.execute_reply.started":"2022-04-17T11:04:17.064507Z","shell.execute_reply":"2022-04-17T11:04:17.073686Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2022-04-17T11:04:17.075820Z","iopub.execute_input":"2022-04-17T11:04:17.076105Z","iopub.status.idle":"2022-04-17T11:04:17.090794Z","shell.execute_reply.started":"2022-04-17T11:04:17.076044Z","shell.execute_reply":"2022-04-17T11:04:17.090047Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                                    text  target\n20846  worldnews gupta email still investigation top ...       1\n42959  left news obama dream team illegal alien drug ...       0\n25681  news breaking trump campaign caught paying hil...       0\n12730  worldnews last hour yemen saleh dubai reuters ...       1\n3325   politicsnews trump pick white collar crime law...       1\n...                                                  ...     ...\n38063  government news obama economic legacy easy rea...       0\n13879  worldnews momentum grows another grand coaliti...       1\n23363  news devin nunes credibility officially shatte...       0\n10979  politicsnews u senator introduces bill speed e...       1\n8264   politicsnews u conservative activist phyllis s...       1\n\n[44898 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>20846</th>\n      <td>worldnews gupta email still investigation top ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>42959</th>\n      <td>left news obama dream team illegal alien drug ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>25681</th>\n      <td>news breaking trump campaign caught paying hil...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12730</th>\n      <td>worldnews last hour yemen saleh dubai reuters ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3325</th>\n      <td>politicsnews trump pick white collar crime law...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>38063</th>\n      <td>government news obama economic legacy easy rea...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13879</th>\n      <td>worldnews momentum grows another grand coaliti...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>23363</th>\n      <td>news devin nunes credibility officially shatte...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10979</th>\n      <td>politicsnews u senator introduces bill speed e...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8264</th>\n      <td>politicsnews u conservative activist phyllis s...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>44898 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X_train1, X_test, y_train1, y_test = train_test_split(data['text'], data['target'],test_size=0.1 ,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T11:04:17.092137Z","iopub.execute_input":"2022-04-17T11:04:17.092556Z","iopub.status.idle":"2022-04-17T11:04:17.104232Z","shell.execute_reply.started":"2022-04-17T11:04:17.092498Z","shell.execute_reply":"2022-04-17T11:04:17.103571Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"X_lvl, X_unl, y_lvl, y_unl = train_test_split(X_train1,y_train1,test_size=0.90,random_state=0)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T11:04:17.106892Z","iopub.execute_input":"2022-04-17T11:04:17.107315Z","iopub.status.idle":"2022-04-17T11:04:17.118431Z","shell.execute_reply.started":"2022-04-17T11:04:17.107261Z","shell.execute_reply":"2022-04-17T11:04:17.117598Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"max_features = 3000\nmaxlen = 50","metadata":{"execution":{"iopub.status.busy":"2022-04-17T11:04:17.119500Z","iopub.execute_input":"2022-04-17T11:04:17.119712Z","iopub.status.idle":"2022-04-17T11:04:17.125744Z","shell.execute_reply.started":"2022-04-17T11:04:17.119679Z","shell.execute_reply":"2022-04-17T11:04:17.125060Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"tokenizer = text.Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(X_lvl)\ntokenized_train = tokenizer.texts_to_sequences(X_lvl)\nX_lvl = sequence.pad_sequences(tokenized_train, maxlen=maxlen)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T11:04:17.126958Z","iopub.execute_input":"2022-04-17T11:04:17.127632Z","iopub.status.idle":"2022-04-17T11:04:18.311021Z","shell.execute_reply.started":"2022-04-17T11:04:17.127596Z","shell.execute_reply":"2022-04-17T11:04:18.310241Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"tokenized_test = tokenizer.texts_to_sequences(X_test)\nX_test = sequence.pad_sequences(tokenized_test, maxlen=maxlen)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T11:04:18.312337Z","iopub.execute_input":"2022-04-17T11:04:18.312579Z","iopub.status.idle":"2022-04-17T11:04:18.903703Z","shell.execute_reply.started":"2022-04-17T11:04:18.312547Z","shell.execute_reply":"2022-04-17T11:04:18.903029Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"tokenized_unl = tokenizer.texts_to_sequences(X_unl)\nX_unl = sequence.pad_sequences(tokenized_unl, maxlen=maxlen)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T11:04:18.905038Z","iopub.execute_input":"2022-04-17T11:04:18.905293Z","iopub.status.idle":"2022-04-17T11:04:23.825678Z","shell.execute_reply.started":"2022-04-17T11:04:18.905258Z","shell.execute_reply":"2022-04-17T11:04:23.824958Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"batch_size = 128","metadata":{"execution":{"iopub.status.busy":"2022-04-17T11:04:23.826953Z","iopub.execute_input":"2022-04-17T11:04:23.827210Z","iopub.status.idle":"2022-04-17T11:04:23.832738Z","shell.execute_reply.started":"2022-04-17T11:04:23.827160Z","shell.execute_reply":"2022-04-17T11:04:23.832084Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras import regularizers\n\ndef build_model(hp):\n    model = Sequential()\n    neurons = hp.Choice('units', values=[32,64, 128,256])\n    model.add(Embedding(max_features, output_dim=100, input_length=maxlen, trainable=False))\n    model.add(LSTM(units=neurons , return_sequences = True , recurrent_dropout =0.25,dropout=0.25))\n    model.add(LSTM(units=neurons , recurrent_dropout = 0.25 , dropout = 0.25))\n    model.add(Dense(units=neurons , activation = 'relu'))\n    model.add(Dense(1, activation='sigmoid'))\n    hp_learning_rate = hp.Choice('learning_rate', values=[1e-1, 1e-2, 1e-3])\n    model.compile(tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),loss='binary_crossentropy', metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-17T11:04:23.833806Z","iopub.execute_input":"2022-04-17T11:04:23.835380Z","iopub.status.idle":"2022-04-17T11:04:23.844385Z","shell.execute_reply.started":"2022-04-17T11:04:23.835338Z","shell.execute_reply":"2022-04-17T11:04:23.843687Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"tuner = kt.Hyperband(build_model,\n                     objective='val_accuracy',\n                     max_epochs=5,\n                     factor=3)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T11:04:23.845289Z","iopub.execute_input":"2022-04-17T11:04:23.845471Z","iopub.status.idle":"2022-04-17T11:04:26.537275Z","shell.execute_reply.started":"2022-04-17T11:04:23.845448Z","shell.execute_reply":"2022-04-17T11:04:26.536557Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"2022-04-17 11:04:23.943363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-17 11:04:24.069515: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-17 11:04:24.070387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-17 11:04:24.071602: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-04-17 11:04:24.072665: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-17 11:04:24.073342: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-17 11:04:24.073967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-17 11:04:25.946535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-17 11:04:25.947355: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-17 11:04:25.948006: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-17 11:04:25.948619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T11:04:26.540284Z","iopub.execute_input":"2022-04-17T11:04:26.540510Z","iopub.status.idle":"2022-04-17T11:04:26.546431Z","shell.execute_reply.started":"2022-04-17T11:04:26.540464Z","shell.execute_reply":"2022-04-17T11:04:26.545718Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"tuner.search(X_lvl,y_lvl, epochs=10, validation_split=0.2, callbacks=[stop_early])\n# Get the optimal hyperparameters\nbest_hps=tuner.get_best_hyperparameters(num_trials=1)[0]","metadata":{"execution":{"iopub.status.busy":"2022-04-17T11:04:26.547501Z","iopub.execute_input":"2022-04-17T11:04:26.547756Z","iopub.status.idle":"2022-04-17T11:13:55.178403Z","shell.execute_reply.started":"2022-04-17T11:04:26.547714Z","shell.execute_reply":"2022-04-17T11:13:55.177712Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Trial 10 Complete [00h 01m 25s]\nval_accuracy: 0.8527227640151978\n\nBest val_accuracy So Far: 0.8836633563041687\nTotal elapsed time: 00h 09m 28s\n","output_type":"stream"}]},{"cell_type":"code","source":"#model=build_model()","metadata":{"execution":{"iopub.status.busy":"2022-04-17T11:13:55.182399Z","iopub.execute_input":"2022-04-17T11:13:55.184276Z","iopub.status.idle":"2022-04-17T11:13:55.189136Z","shell.execute_reply.started":"2022-04-17T11:13:55.184235Z","shell.execute_reply":"2022-04-17T11:13:55.188527Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"maxitr=3\nitera=0\nminconf=0.75\ntl=len(data)-len(X_test)\nixll=len(X_lvl)\nixul=len(X_unl)\nX_train=X_lvl\ny_train=y_lvl\nmodel=tuner.hypermodel.build(best_hps)\nhistory = model.fit(X_train, y_train, validation_split=0.3, epochs=100, batch_size=batch_size, shuffle=True, verbose = 1)\nwhile(len(X_unl)>0):\n    pred1=(model.predict(X_unl))\n    pred0=1-pred1\n    df_pred_prob = pd.DataFrame([])\n    df_pred_prob['prob_0'] = (pred0).tolist()\n    df_pred_prob['prob_1'] = (pred1).tolist()\n    df_pred_prob['text']=X_unl.tolist()\n    df=df_pred_prob\n    yln=[]\n    Xln=[]\n    Xun=[]\n    for i in range(len(X_unl)):\n        if((df['prob_0'][i][0])>minconf):\n            yln=yln+[0]\n            Xln=Xln+[df['text'][i]]\n        elif((df['prob_1'][i][0])>minconf):\n            yln=yln+[1]\n            Xln=Xln+[df['text'][i]]\n        else:\n            Xun=Xun+[df['text'][i]]\n    \n    y_train=np.concatenate((y_train,yln),axis=0)\n    X_train=np.concatenate((X_train,Xln),axis=0)\n    ixll=len(X_train)\n    print(\"length of train data:=\")\n    print(ixll)\n    model=tuner.hypermodel.build(best_hps)\n    history = model.fit(X_train, y_train, validation_split=0.3, epochs=50, batch_size=batch_size, shuffle=True, verbose = 1)\n    X_unl = np.array(Xun)\n    print(\"length of remaining unlabled data:=\")\n    print(len(X_unl))\n    itera=itera+1\n    if (itera==maxitr):\n        break\n    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-17T11:13:55.191570Z","iopub.execute_input":"2022-04-17T11:13:55.192641Z","iopub.status.idle":"2022-04-17T15:17:43.743267Z","shell.execute_reply.started":"2022-04-17T11:13:55.192602Z","shell.execute_reply":"2022-04-17T15:17:43.742133Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Epoch 1/100\n23/23 [==============================] - 14s 432ms/step - loss: 0.5937 - accuracy: 0.6513 - val_loss: 0.4340 - val_accuracy: 0.7880\nEpoch 2/100\n23/23 [==============================] - 10s 403ms/step - loss: 0.4096 - accuracy: 0.8045 - val_loss: 0.5815 - val_accuracy: 0.7781\nEpoch 3/100\n23/23 [==============================] - 9s 389ms/step - loss: 0.3858 - accuracy: 0.8211 - val_loss: 0.3522 - val_accuracy: 0.8424\nEpoch 4/100\n23/23 [==============================] - 10s 420ms/step - loss: 0.3284 - accuracy: 0.8515 - val_loss: 0.3131 - val_accuracy: 0.8721\nEpoch 5/100\n23/23 [==============================] - 10s 434ms/step - loss: 0.3244 - accuracy: 0.8582 - val_loss: 0.2744 - val_accuracy: 0.8894\nEpoch 6/100\n23/23 [==============================] - 9s 403ms/step - loss: 0.2791 - accuracy: 0.8837 - val_loss: 0.2646 - val_accuracy: 0.8919\nEpoch 7/100\n23/23 [==============================] - 9s 402ms/step - loss: 0.2681 - accuracy: 0.8883 - val_loss: 0.2477 - val_accuracy: 0.9010\nEpoch 8/100\n23/23 [==============================] - 10s 432ms/step - loss: 0.2640 - accuracy: 0.8900 - val_loss: 0.3045 - val_accuracy: 0.8771\nEpoch 9/100\n23/23 [==============================] - 10s 419ms/step - loss: 0.2654 - accuracy: 0.8883 - val_loss: 0.2569 - val_accuracy: 0.8936\nEpoch 10/100\n23/23 [==============================] - 9s 399ms/step - loss: 0.2456 - accuracy: 0.8971 - val_loss: 0.2566 - val_accuracy: 0.9002\nEpoch 11/100\n23/23 [==============================] - 9s 388ms/step - loss: 0.2429 - accuracy: 0.9059 - val_loss: 0.2347 - val_accuracy: 0.9125\nEpoch 12/100\n23/23 [==============================] - 10s 444ms/step - loss: 0.2270 - accuracy: 0.9120 - val_loss: 0.2289 - val_accuracy: 0.9101\nEpoch 13/100\n23/23 [==============================] - 9s 412ms/step - loss: 0.2153 - accuracy: 0.9169 - val_loss: 0.2561 - val_accuracy: 0.9010\nEpoch 14/100\n23/23 [==============================] - 9s 410ms/step - loss: 0.2052 - accuracy: 0.9226 - val_loss: 0.2174 - val_accuracy: 0.9191\nEpoch 15/100\n23/23 [==============================] - 10s 455ms/step - loss: 0.1965 - accuracy: 0.9261 - val_loss: 0.2177 - val_accuracy: 0.9101\nEpoch 16/100\n23/23 [==============================] - 9s 406ms/step - loss: 0.1891 - accuracy: 0.9282 - val_loss: 0.2261 - val_accuracy: 0.9101\nEpoch 17/100\n23/23 [==============================] - 9s 412ms/step - loss: 0.1773 - accuracy: 0.9286 - val_loss: 0.2165 - val_accuracy: 0.9134\nEpoch 18/100\n23/23 [==============================] - 9s 383ms/step - loss: 0.1882 - accuracy: 0.9240 - val_loss: 0.2368 - val_accuracy: 0.9043\nEpoch 19/100\n23/23 [==============================] - 10s 427ms/step - loss: 0.1950 - accuracy: 0.9254 - val_loss: 0.2370 - val_accuracy: 0.9068\nEpoch 20/100\n23/23 [==============================] - 9s 398ms/step - loss: 0.1732 - accuracy: 0.9378 - val_loss: 0.2215 - val_accuracy: 0.9134\nEpoch 21/100\n23/23 [==============================] - 9s 408ms/step - loss: 0.1512 - accuracy: 0.9395 - val_loss: 0.2143 - val_accuracy: 0.9158\nEpoch 22/100\n23/23 [==============================] - 10s 454ms/step - loss: 0.1575 - accuracy: 0.9402 - val_loss: 0.2183 - val_accuracy: 0.9191\nEpoch 23/100\n23/23 [==============================] - 9s 406ms/step - loss: 0.1496 - accuracy: 0.9388 - val_loss: 0.2118 - val_accuracy: 0.9241\nEpoch 24/100\n23/23 [==============================] - 10s 423ms/step - loss: 0.1477 - accuracy: 0.9441 - val_loss: 0.2186 - val_accuracy: 0.9200\nEpoch 25/100\n23/23 [==============================] - 10s 417ms/step - loss: 0.1547 - accuracy: 0.9385 - val_loss: 0.2075 - val_accuracy: 0.9200\nEpoch 26/100\n23/23 [==============================] - 10s 428ms/step - loss: 0.1285 - accuracy: 0.9508 - val_loss: 0.2250 - val_accuracy: 0.9200\nEpoch 27/100\n23/23 [==============================] - 9s 400ms/step - loss: 0.1487 - accuracy: 0.9395 - val_loss: 0.2098 - val_accuracy: 0.9183\nEpoch 28/100\n23/23 [==============================] - 9s 414ms/step - loss: 0.1223 - accuracy: 0.9551 - val_loss: 0.2276 - val_accuracy: 0.9076\nEpoch 29/100\n23/23 [==============================] - 10s 441ms/step - loss: 0.1717 - accuracy: 0.9353 - val_loss: 0.1954 - val_accuracy: 0.9307\nEpoch 30/100\n23/23 [==============================] - 10s 415ms/step - loss: 0.1485 - accuracy: 0.9438 - val_loss: 0.2282 - val_accuracy: 0.9290\nEpoch 31/100\n23/23 [==============================] - 9s 410ms/step - loss: 0.1520 - accuracy: 0.9438 - val_loss: 0.2087 - val_accuracy: 0.9266\nEpoch 32/100\n23/23 [==============================] - 9s 395ms/step - loss: 0.1417 - accuracy: 0.9487 - val_loss: 0.2002 - val_accuracy: 0.9290\nEpoch 33/100\n23/23 [==============================] - 9s 395ms/step - loss: 0.1156 - accuracy: 0.9558 - val_loss: 0.2176 - val_accuracy: 0.9142\nEpoch 34/100\n23/23 [==============================] - 9s 395ms/step - loss: 0.1368 - accuracy: 0.9466 - val_loss: 0.2265 - val_accuracy: 0.9158\nEpoch 35/100\n23/23 [==============================] - 10s 417ms/step - loss: 0.1111 - accuracy: 0.9569 - val_loss: 0.2012 - val_accuracy: 0.9348\nEpoch 36/100\n23/23 [==============================] - 10s 437ms/step - loss: 0.1033 - accuracy: 0.9604 - val_loss: 0.2070 - val_accuracy: 0.9307\nEpoch 37/100\n23/23 [==============================] - 9s 393ms/step - loss: 0.0927 - accuracy: 0.9661 - val_loss: 0.1978 - val_accuracy: 0.9323\nEpoch 38/100\n23/23 [==============================] - 9s 402ms/step - loss: 0.0815 - accuracy: 0.9696 - val_loss: 0.2192 - val_accuracy: 0.9373\nEpoch 39/100\n23/23 [==============================] - 9s 408ms/step - loss: 0.0798 - accuracy: 0.9675 - val_loss: 0.2100 - val_accuracy: 0.9365\nEpoch 40/100\n23/23 [==============================] - 10s 427ms/step - loss: 0.0726 - accuracy: 0.9668 - val_loss: 0.2490 - val_accuracy: 0.9389\nEpoch 41/100\n23/23 [==============================] - 9s 394ms/step - loss: 0.0707 - accuracy: 0.9724 - val_loss: 0.2272 - val_accuracy: 0.9332\nEpoch 42/100\n23/23 [==============================] - 9s 403ms/step - loss: 0.0623 - accuracy: 0.9767 - val_loss: 0.2533 - val_accuracy: 0.9332\nEpoch 43/100\n23/23 [==============================] - 10s 432ms/step - loss: 0.0837 - accuracy: 0.9668 - val_loss: 0.2101 - val_accuracy: 0.9348\nEpoch 44/100\n23/23 [==============================] - 9s 410ms/step - loss: 0.1084 - accuracy: 0.9600 - val_loss: 0.2161 - val_accuracy: 0.9332\nEpoch 45/100\n23/23 [==============================] - 9s 403ms/step - loss: 0.0665 - accuracy: 0.9752 - val_loss: 0.2198 - val_accuracy: 0.9332\nEpoch 46/100\n23/23 [==============================] - 10s 430ms/step - loss: 0.0579 - accuracy: 0.9749 - val_loss: 0.1971 - val_accuracy: 0.9348\nEpoch 47/100\n23/23 [==============================] - 10s 406ms/step - loss: 0.0597 - accuracy: 0.9781 - val_loss: 0.2662 - val_accuracy: 0.9414\nEpoch 48/100\n23/23 [==============================] - 9s 380ms/step - loss: 0.0582 - accuracy: 0.9770 - val_loss: 0.2267 - val_accuracy: 0.9348\nEpoch 49/100\n23/23 [==============================] - 9s 402ms/step - loss: 0.0480 - accuracy: 0.9813 - val_loss: 0.2279 - val_accuracy: 0.9340\nEpoch 50/100\n23/23 [==============================] - 10s 431ms/step - loss: 0.0445 - accuracy: 0.9820 - val_loss: 0.2243 - val_accuracy: 0.9282\nEpoch 51/100\n23/23 [==============================] - 9s 414ms/step - loss: 0.0631 - accuracy: 0.9738 - val_loss: 0.1862 - val_accuracy: 0.9340\nEpoch 52/100\n23/23 [==============================] - 9s 405ms/step - loss: 0.0484 - accuracy: 0.9809 - val_loss: 0.2209 - val_accuracy: 0.9356\nEpoch 53/100\n23/23 [==============================] - 10s 427ms/step - loss: 0.0426 - accuracy: 0.9848 - val_loss: 0.2666 - val_accuracy: 0.9274\nEpoch 54/100\n23/23 [==============================] - 10s 418ms/step - loss: 0.0492 - accuracy: 0.9820 - val_loss: 0.2203 - val_accuracy: 0.9398\nEpoch 55/100\n23/23 [==============================] - 9s 389ms/step - loss: 0.0314 - accuracy: 0.9890 - val_loss: 0.2693 - val_accuracy: 0.9332\nEpoch 56/100\n23/23 [==============================] - 9s 405ms/step - loss: 0.0411 - accuracy: 0.9862 - val_loss: 0.3027 - val_accuracy: 0.9340\nEpoch 57/100\n23/23 [==============================] - 10s 430ms/step - loss: 0.0424 - accuracy: 0.9841 - val_loss: 0.3234 - val_accuracy: 0.9356\nEpoch 58/100\n23/23 [==============================] - 9s 396ms/step - loss: 0.0390 - accuracy: 0.9830 - val_loss: 0.2367 - val_accuracy: 0.9356\nEpoch 59/100\n23/23 [==============================] - 9s 407ms/step - loss: 0.0402 - accuracy: 0.9851 - val_loss: 0.2144 - val_accuracy: 0.9356\nEpoch 60/100\n23/23 [==============================] - 10s 437ms/step - loss: 0.0480 - accuracy: 0.9813 - val_loss: 0.2041 - val_accuracy: 0.9381\nEpoch 61/100\n23/23 [==============================] - 9s 391ms/step - loss: 0.0369 - accuracy: 0.9873 - val_loss: 0.2622 - val_accuracy: 0.9398\nEpoch 62/100\n23/23 [==============================] - 9s 389ms/step - loss: 0.0328 - accuracy: 0.9901 - val_loss: 0.3032 - val_accuracy: 0.9348\nEpoch 63/100\n23/23 [==============================] - 10s 425ms/step - loss: 0.0583 - accuracy: 0.9784 - val_loss: 0.2404 - val_accuracy: 0.9365\nEpoch 64/100\n23/23 [==============================] - 10s 435ms/step - loss: 0.0393 - accuracy: 0.9837 - val_loss: 0.2137 - val_accuracy: 0.9307\nEpoch 65/100\n23/23 [==============================] - 9s 399ms/step - loss: 0.0470 - accuracy: 0.9830 - val_loss: 0.3026 - val_accuracy: 0.9332\nEpoch 66/100\n23/23 [==============================] - 9s 400ms/step - loss: 0.0398 - accuracy: 0.9873 - val_loss: 0.2442 - val_accuracy: 0.9241\nEpoch 67/100\n23/23 [==============================] - 10s 437ms/step - loss: 0.0322 - accuracy: 0.9890 - val_loss: 0.2621 - val_accuracy: 0.9340\nEpoch 68/100\n23/23 [==============================] - 9s 403ms/step - loss: 0.0290 - accuracy: 0.9905 - val_loss: 0.2342 - val_accuracy: 0.9381\nEpoch 69/100\n23/23 [==============================] - 9s 388ms/step - loss: 0.0202 - accuracy: 0.9940 - val_loss: 0.2735 - val_accuracy: 0.9398\nEpoch 70/100\n23/23 [==============================] - 9s 407ms/step - loss: 0.0237 - accuracy: 0.9922 - val_loss: 0.2613 - val_accuracy: 0.9414\nEpoch 71/100\n23/23 [==============================] - 10s 427ms/step - loss: 0.0206 - accuracy: 0.9940 - val_loss: 0.2368 - val_accuracy: 0.9348\nEpoch 72/100\n23/23 [==============================] - 9s 405ms/step - loss: 0.0266 - accuracy: 0.9908 - val_loss: 0.2506 - val_accuracy: 0.9406\nEpoch 73/100\n23/23 [==============================] - 9s 402ms/step - loss: 0.0196 - accuracy: 0.9926 - val_loss: 0.3833 - val_accuracy: 0.9356\nEpoch 74/100\n23/23 [==============================] - 10s 423ms/step - loss: 0.0661 - accuracy: 0.9784 - val_loss: 0.2017 - val_accuracy: 0.9381\nEpoch 75/100\n23/23 [==============================] - 9s 392ms/step - loss: 0.0342 - accuracy: 0.9883 - val_loss: 0.2213 - val_accuracy: 0.9332\nEpoch 76/100\n23/23 [==============================] - 9s 386ms/step - loss: 0.0311 - accuracy: 0.9880 - val_loss: 0.1987 - val_accuracy: 0.9398\nEpoch 77/100\n23/23 [==============================] - 9s 406ms/step - loss: 0.0251 - accuracy: 0.9908 - val_loss: 0.2525 - val_accuracy: 0.9332\nEpoch 78/100\n23/23 [==============================] - 10s 444ms/step - loss: 0.0288 - accuracy: 0.9894 - val_loss: 0.2649 - val_accuracy: 0.9340\nEpoch 79/100\n23/23 [==============================] - 9s 410ms/step - loss: 0.0249 - accuracy: 0.9905 - val_loss: 0.2406 - val_accuracy: 0.9398\nEpoch 80/100\n23/23 [==============================] - 10s 417ms/step - loss: 0.0214 - accuracy: 0.9926 - val_loss: 0.2279 - val_accuracy: 0.9439\nEpoch 81/100\n23/23 [==============================] - 10s 456ms/step - loss: 0.0194 - accuracy: 0.9933 - val_loss: 0.2537 - val_accuracy: 0.9398\nEpoch 82/100\n23/23 [==============================] - 9s 403ms/step - loss: 0.0204 - accuracy: 0.9943 - val_loss: 0.2246 - val_accuracy: 0.9348\nEpoch 83/100\n23/23 [==============================] - 9s 399ms/step - loss: 0.0246 - accuracy: 0.9922 - val_loss: 0.2793 - val_accuracy: 0.9398\nEpoch 84/100\n23/23 [==============================] - 9s 397ms/step - loss: 0.0254 - accuracy: 0.9901 - val_loss: 0.2341 - val_accuracy: 0.9389\nEpoch 85/100\n23/23 [==============================] - 10s 441ms/step - loss: 0.0155 - accuracy: 0.9936 - val_loss: 0.4198 - val_accuracy: 0.9323\nEpoch 86/100\n23/23 [==============================] - 9s 409ms/step - loss: 0.1113 - accuracy: 0.9664 - val_loss: 0.1594 - val_accuracy: 0.9356\nEpoch 87/100\n23/23 [==============================] - 9s 409ms/step - loss: 0.0397 - accuracy: 0.9873 - val_loss: 0.2050 - val_accuracy: 0.9381\nEpoch 88/100\n23/23 [==============================] - 10s 435ms/step - loss: 0.0219 - accuracy: 0.9926 - val_loss: 0.3015 - val_accuracy: 0.9406\nEpoch 89/100\n23/23 [==============================] - 9s 392ms/step - loss: 0.0240 - accuracy: 0.9922 - val_loss: 0.2195 - val_accuracy: 0.9323\nEpoch 90/100\n23/23 [==============================] - 9s 385ms/step - loss: 0.0163 - accuracy: 0.9950 - val_loss: 0.2462 - val_accuracy: 0.9406\nEpoch 91/100\n23/23 [==============================] - 9s 384ms/step - loss: 0.0211 - accuracy: 0.9929 - val_loss: 0.2470 - val_accuracy: 0.9381\nEpoch 92/100\n23/23 [==============================] - 10s 432ms/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.2962 - val_accuracy: 0.9373\nEpoch 93/100\n23/23 [==============================] - 9s 403ms/step - loss: 0.0181 - accuracy: 0.9940 - val_loss: 0.3226 - val_accuracy: 0.9365\nEpoch 94/100\n23/23 [==============================] - 9s 403ms/step - loss: 0.0223 - accuracy: 0.9926 - val_loss: 0.2190 - val_accuracy: 0.9389\nEpoch 95/100\n23/23 [==============================] - 10s 446ms/step - loss: 0.0219 - accuracy: 0.9915 - val_loss: 0.2456 - val_accuracy: 0.9447\nEpoch 96/100\n23/23 [==============================] - 9s 409ms/step - loss: 0.0157 - accuracy: 0.9943 - val_loss: 0.2602 - val_accuracy: 0.9431\nEpoch 97/100\n23/23 [==============================] - 9s 381ms/step - loss: 0.0268 - accuracy: 0.9926 - val_loss: 0.2236 - val_accuracy: 0.9447\nEpoch 98/100\n23/23 [==============================] - 9s 400ms/step - loss: 0.0112 - accuracy: 0.9954 - val_loss: 0.2692 - val_accuracy: 0.9431\nEpoch 99/100\n23/23 [==============================] - 10s 434ms/step - loss: 0.0126 - accuracy: 0.9954 - val_loss: 0.2544 - val_accuracy: 0.9274\nEpoch 100/100\n23/23 [==============================] - 9s 410ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.3039 - val_accuracy: 0.9389\nlength of train data:=\n39885\nEpoch 1/50\n219/219 [==============================] - 95s 416ms/step - loss: 0.3106 - accuracy: 0.8618 - val_loss: 0.1860 - val_accuracy: 0.9269\nEpoch 2/50\n219/219 [==============================] - 92s 418ms/step - loss: 0.1898 - accuracy: 0.9252 - val_loss: 0.1371 - val_accuracy: 0.9506\nEpoch 3/50\n219/219 [==============================] - 90s 411ms/step - loss: 0.1469 - accuracy: 0.9437 - val_loss: 0.1056 - val_accuracy: 0.9596\nEpoch 4/50\n219/219 [==============================] - 91s 415ms/step - loss: 0.1256 - accuracy: 0.9525 - val_loss: 0.0902 - val_accuracy: 0.9656\nEpoch 5/50\n219/219 [==============================] - 89s 408ms/step - loss: 0.1174 - accuracy: 0.9551 - val_loss: 0.0966 - val_accuracy: 0.9594\nEpoch 6/50\n219/219 [==============================] - 89s 408ms/step - loss: 0.1067 - accuracy: 0.9607 - val_loss: 0.0844 - val_accuracy: 0.9698\nEpoch 7/50\n219/219 [==============================] - 89s 406ms/step - loss: 0.0977 - accuracy: 0.9628 - val_loss: 0.0788 - val_accuracy: 0.9715\nEpoch 8/50\n219/219 [==============================] - 88s 403ms/step - loss: 0.0914 - accuracy: 0.9647 - val_loss: 0.0917 - val_accuracy: 0.9648\nEpoch 9/50\n219/219 [==============================] - 88s 401ms/step - loss: 0.0871 - accuracy: 0.9677 - val_loss: 0.0765 - val_accuracy: 0.9718\nEpoch 10/50\n219/219 [==============================] - 89s 406ms/step - loss: 0.0811 - accuracy: 0.9698 - val_loss: 0.0740 - val_accuracy: 0.9730\nEpoch 11/50\n219/219 [==============================] - 88s 400ms/step - loss: 0.0795 - accuracy: 0.9682 - val_loss: 0.0732 - val_accuracy: 0.9725\nEpoch 12/50\n219/219 [==============================] - 88s 403ms/step - loss: 0.0766 - accuracy: 0.9706 - val_loss: 0.0738 - val_accuracy: 0.9732\nEpoch 13/50\n219/219 [==============================] - 89s 404ms/step - loss: 0.0734 - accuracy: 0.9723 - val_loss: 0.0688 - val_accuracy: 0.9745\nEpoch 14/50\n219/219 [==============================] - 88s 402ms/step - loss: 0.0708 - accuracy: 0.9730 - val_loss: 0.0758 - val_accuracy: 0.9702\nEpoch 15/50\n219/219 [==============================] - 88s 403ms/step - loss: 0.0654 - accuracy: 0.9752 - val_loss: 0.0708 - val_accuracy: 0.9737\nEpoch 16/50\n219/219 [==============================] - 89s 405ms/step - loss: 0.0630 - accuracy: 0.9758 - val_loss: 0.0855 - val_accuracy: 0.9692\nEpoch 17/50\n219/219 [==============================] - 90s 409ms/step - loss: 0.0611 - accuracy: 0.9771 - val_loss: 0.0631 - val_accuracy: 0.9765\nEpoch 18/50\n219/219 [==============================] - 88s 403ms/step - loss: 0.0577 - accuracy: 0.9782 - val_loss: 0.0690 - val_accuracy: 0.9767\nEpoch 19/50\n219/219 [==============================] - 88s 403ms/step - loss: 0.0539 - accuracy: 0.9796 - val_loss: 0.0692 - val_accuracy: 0.9763\nEpoch 20/50\n219/219 [==============================] - 88s 404ms/step - loss: 0.0545 - accuracy: 0.9798 - val_loss: 0.0659 - val_accuracy: 0.9774\nEpoch 21/50\n219/219 [==============================] - 88s 401ms/step - loss: 0.0550 - accuracy: 0.9792 - val_loss: 0.0649 - val_accuracy: 0.9770\nEpoch 22/50\n219/219 [==============================] - 90s 409ms/step - loss: 0.0470 - accuracy: 0.9819 - val_loss: 0.0650 - val_accuracy: 0.9778\nEpoch 23/50\n219/219 [==============================] - 88s 402ms/step - loss: 0.0485 - accuracy: 0.9816 - val_loss: 0.0641 - val_accuracy: 0.9780\nEpoch 24/50\n219/219 [==============================] - 88s 404ms/step - loss: 0.0472 - accuracy: 0.9830 - val_loss: 0.0612 - val_accuracy: 0.9784\nEpoch 25/50\n219/219 [==============================] - 89s 407ms/step - loss: 0.0445 - accuracy: 0.9831 - val_loss: 0.0633 - val_accuracy: 0.9794\nEpoch 26/50\n219/219 [==============================] - 88s 402ms/step - loss: 0.0450 - accuracy: 0.9825 - val_loss: 0.0795 - val_accuracy: 0.9764\nEpoch 27/50\n219/219 [==============================] - 88s 404ms/step - loss: 0.0415 - accuracy: 0.9845 - val_loss: 0.0666 - val_accuracy: 0.9786\nEpoch 28/50\n219/219 [==============================] - 88s 402ms/step - loss: 0.0405 - accuracy: 0.9845 - val_loss: 0.0620 - val_accuracy: 0.9786\nEpoch 29/50\n219/219 [==============================] - 90s 411ms/step - loss: 0.0377 - accuracy: 0.9861 - val_loss: 0.0614 - val_accuracy: 0.9786\nEpoch 30/50\n219/219 [==============================] - 89s 406ms/step - loss: 0.0394 - accuracy: 0.9852 - val_loss: 0.0646 - val_accuracy: 0.9768\nEpoch 31/50\n219/219 [==============================] - 89s 404ms/step - loss: 0.0355 - accuracy: 0.9870 - val_loss: 0.0660 - val_accuracy: 0.9799\nEpoch 32/50\n219/219 [==============================] - 91s 413ms/step - loss: 0.0364 - accuracy: 0.9865 - val_loss: 0.0658 - val_accuracy: 0.9805\nEpoch 33/50\n219/219 [==============================] - 89s 406ms/step - loss: 0.0344 - accuracy: 0.9870 - val_loss: 0.0679 - val_accuracy: 0.9802\nEpoch 34/50\n219/219 [==============================] - 89s 406ms/step - loss: 0.0326 - accuracy: 0.9880 - val_loss: 0.0663 - val_accuracy: 0.9799\nEpoch 35/50\n219/219 [==============================] - 90s 409ms/step - loss: 0.0335 - accuracy: 0.9874 - val_loss: 0.0663 - val_accuracy: 0.9785\nEpoch 36/50\n219/219 [==============================] - 89s 407ms/step - loss: 0.0326 - accuracy: 0.9879 - val_loss: 0.0662 - val_accuracy: 0.9797\nEpoch 37/50\n219/219 [==============================] - 90s 409ms/step - loss: 0.0309 - accuracy: 0.9890 - val_loss: 0.0711 - val_accuracy: 0.9792\nEpoch 38/50\n219/219 [==============================] - 90s 410ms/step - loss: 0.0327 - accuracy: 0.9874 - val_loss: 0.0723 - val_accuracy: 0.9755\nEpoch 39/50\n219/219 [==============================] - 89s 407ms/step - loss: 0.0334 - accuracy: 0.9879 - val_loss: 0.0661 - val_accuracy: 0.9789\nEpoch 40/50\n219/219 [==============================] - 89s 406ms/step - loss: 0.0312 - accuracy: 0.9884 - val_loss: 0.0825 - val_accuracy: 0.9729\nEpoch 41/50\n219/219 [==============================] - 88s 400ms/step - loss: 0.0311 - accuracy: 0.9879 - val_loss: 0.0645 - val_accuracy: 0.9799\nEpoch 42/50\n219/219 [==============================] - 90s 413ms/step - loss: 0.0289 - accuracy: 0.9888 - val_loss: 0.0699 - val_accuracy: 0.9804\nEpoch 43/50\n219/219 [==============================] - 89s 406ms/step - loss: 0.0288 - accuracy: 0.9888 - val_loss: 0.0660 - val_accuracy: 0.9786\nEpoch 44/50\n219/219 [==============================] - 89s 408ms/step - loss: 0.0259 - accuracy: 0.9908 - val_loss: 0.0655 - val_accuracy: 0.9814\nEpoch 45/50\n219/219 [==============================] - 89s 407ms/step - loss: 0.0253 - accuracy: 0.9912 - val_loss: 0.0687 - val_accuracy: 0.9794\nEpoch 46/50\n219/219 [==============================] - 89s 406ms/step - loss: 0.0281 - accuracy: 0.9895 - val_loss: 0.0646 - val_accuracy: 0.9807\nEpoch 47/50\n219/219 [==============================] - 89s 405ms/step - loss: 0.0280 - accuracy: 0.9896 - val_loss: 0.0680 - val_accuracy: 0.9801\nEpoch 48/50\n219/219 [==============================] - 89s 407ms/step - loss: 0.0273 - accuracy: 0.9904 - val_loss: 0.0653 - val_accuracy: 0.9783\nEpoch 49/50\n219/219 [==============================] - 90s 411ms/step - loss: 0.0230 - accuracy: 0.9914 - val_loss: 0.0672 - val_accuracy: 0.9805\nEpoch 50/50\n219/219 [==============================] - 89s 407ms/step - loss: 0.0260 - accuracy: 0.9905 - val_loss: 0.0706 - val_accuracy: 0.9806\nlength of remaining unlabled data:=\n523\nlength of train data:=\n40342\nEpoch 1/50\n221/221 [==============================] - 95s 412ms/step - loss: 0.3070 - accuracy: 0.8639 - val_loss: 0.2065 - val_accuracy: 0.9205\nEpoch 2/50\n221/221 [==============================] - 91s 408ms/step - loss: 0.1840 - accuracy: 0.9246 - val_loss: 0.1653 - val_accuracy: 0.9373\nEpoch 3/50\n221/221 [==============================] - 91s 411ms/step - loss: 0.1483 - accuracy: 0.9423 - val_loss: 0.1268 - val_accuracy: 0.9516\nEpoch 4/50\n221/221 [==============================] - 91s 412ms/step - loss: 0.1210 - accuracy: 0.9546 - val_loss: 0.1109 - val_accuracy: 0.9541\nEpoch 5/50\n221/221 [==============================] - 92s 414ms/step - loss: 0.1143 - accuracy: 0.9565 - val_loss: 0.1182 - val_accuracy: 0.9513\nEpoch 6/50\n221/221 [==============================] - 90s 409ms/step - loss: 0.0977 - accuracy: 0.9636 - val_loss: 0.1015 - val_accuracy: 0.9590\nEpoch 7/50\n221/221 [==============================] - 92s 415ms/step - loss: 0.0922 - accuracy: 0.9664 - val_loss: 0.0900 - val_accuracy: 0.9645\nEpoch 8/50\n221/221 [==============================] - 92s 416ms/step - loss: 0.0867 - accuracy: 0.9679 - val_loss: 0.0832 - val_accuracy: 0.9671\nEpoch 9/50\n221/221 [==============================] - 90s 409ms/step - loss: 0.0804 - accuracy: 0.9706 - val_loss: 0.0900 - val_accuracy: 0.9655\nEpoch 10/50\n221/221 [==============================] - 90s 406ms/step - loss: 0.0833 - accuracy: 0.9686 - val_loss: 0.1108 - val_accuracy: 0.9622\nEpoch 11/50\n221/221 [==============================] - 91s 413ms/step - loss: 0.0748 - accuracy: 0.9716 - val_loss: 0.0842 - val_accuracy: 0.9690\nEpoch 12/50\n221/221 [==============================] - 90s 408ms/step - loss: 0.0720 - accuracy: 0.9735 - val_loss: 0.0778 - val_accuracy: 0.9691\nEpoch 13/50\n221/221 [==============================] - 90s 409ms/step - loss: 0.0731 - accuracy: 0.9738 - val_loss: 0.0781 - val_accuracy: 0.9708\nEpoch 14/50\n221/221 [==============================] - 91s 409ms/step - loss: 0.0653 - accuracy: 0.9759 - val_loss: 0.0764 - val_accuracy: 0.9697\nEpoch 15/50\n221/221 [==============================] - 91s 414ms/step - loss: 0.0637 - accuracy: 0.9769 - val_loss: 0.0759 - val_accuracy: 0.9702\nEpoch 16/50\n221/221 [==============================] - 91s 412ms/step - loss: 0.0600 - accuracy: 0.9767 - val_loss: 0.0857 - val_accuracy: 0.9693\nEpoch 17/50\n221/221 [==============================] - 91s 410ms/step - loss: 0.0588 - accuracy: 0.9789 - val_loss: 0.0746 - val_accuracy: 0.9716\nEpoch 18/50\n221/221 [==============================] - 91s 411ms/step - loss: 0.0554 - accuracy: 0.9789 - val_loss: 0.0703 - val_accuracy: 0.9741\nEpoch 19/50\n221/221 [==============================] - 91s 413ms/step - loss: 0.0525 - accuracy: 0.9808 - val_loss: 0.0774 - val_accuracy: 0.9711\nEpoch 20/50\n221/221 [==============================] - 90s 408ms/step - loss: 0.0493 - accuracy: 0.9811 - val_loss: 0.0815 - val_accuracy: 0.9713\nEpoch 21/50\n221/221 [==============================] - 91s 410ms/step - loss: 0.0494 - accuracy: 0.9813 - val_loss: 0.0720 - val_accuracy: 0.9741\nEpoch 22/50\n221/221 [==============================] - 90s 408ms/step - loss: 0.0475 - accuracy: 0.9821 - val_loss: 0.0778 - val_accuracy: 0.9716\nEpoch 23/50\n221/221 [==============================] - 90s 409ms/step - loss: 0.0450 - accuracy: 0.9826 - val_loss: 0.0809 - val_accuracy: 0.9716\nEpoch 24/50\n221/221 [==============================] - 91s 411ms/step - loss: 0.0396 - accuracy: 0.9855 - val_loss: 0.0825 - val_accuracy: 0.9693\nEpoch 25/50\n221/221 [==============================] - 90s 409ms/step - loss: 0.0400 - accuracy: 0.9852 - val_loss: 0.0769 - val_accuracy: 0.9745\nEpoch 26/50\n221/221 [==============================] - 92s 414ms/step - loss: 0.0394 - accuracy: 0.9862 - val_loss: 0.0779 - val_accuracy: 0.9744\nEpoch 27/50\n221/221 [==============================] - 92s 416ms/step - loss: 0.0410 - accuracy: 0.9843 - val_loss: 0.0763 - val_accuracy: 0.9731\nEpoch 28/50\n221/221 [==============================] - 91s 410ms/step - loss: 0.0387 - accuracy: 0.9861 - val_loss: 0.0772 - val_accuracy: 0.9746\nEpoch 29/50\n221/221 [==============================] - 91s 410ms/step - loss: 0.0367 - accuracy: 0.9866 - val_loss: 0.0750 - val_accuracy: 0.9727\nEpoch 30/50\n221/221 [==============================] - 91s 412ms/step - loss: 0.0359 - accuracy: 0.9864 - val_loss: 0.0793 - val_accuracy: 0.9746\nEpoch 31/50\n221/221 [==============================] - 91s 413ms/step - loss: 0.0341 - accuracy: 0.9876 - val_loss: 0.0731 - val_accuracy: 0.9741\nEpoch 32/50\n221/221 [==============================] - 91s 413ms/step - loss: 0.0323 - accuracy: 0.9881 - val_loss: 0.0825 - val_accuracy: 0.9748\nEpoch 33/50\n221/221 [==============================] - 91s 413ms/step - loss: 0.0333 - accuracy: 0.9877 - val_loss: 0.0833 - val_accuracy: 0.9743\nEpoch 34/50\n221/221 [==============================] - 91s 412ms/step - loss: 0.0328 - accuracy: 0.9874 - val_loss: 0.0745 - val_accuracy: 0.9742\nEpoch 35/50\n221/221 [==============================] - 91s 412ms/step - loss: 0.0300 - accuracy: 0.9894 - val_loss: 0.0719 - val_accuracy: 0.9753\nEpoch 36/50\n221/221 [==============================] - 92s 418ms/step - loss: 0.0314 - accuracy: 0.9884 - val_loss: 0.0965 - val_accuracy: 0.9692\nEpoch 37/50\n221/221 [==============================] - 91s 411ms/step - loss: 0.0324 - accuracy: 0.9884 - val_loss: 0.0781 - val_accuracy: 0.9763\nEpoch 38/50\n221/221 [==============================] - 91s 413ms/step - loss: 0.0270 - accuracy: 0.9900 - val_loss: 0.0771 - val_accuracy: 0.9750\nEpoch 39/50\n221/221 [==============================] - 91s 411ms/step - loss: 0.0299 - accuracy: 0.9892 - val_loss: 0.0815 - val_accuracy: 0.9755\nEpoch 40/50\n221/221 [==============================] - 92s 415ms/step - loss: 0.0241 - accuracy: 0.9910 - val_loss: 0.0894 - val_accuracy: 0.9750\nEpoch 41/50\n221/221 [==============================] - 90s 406ms/step - loss: 0.0271 - accuracy: 0.9900 - val_loss: 0.0815 - val_accuracy: 0.9750\nEpoch 42/50\n221/221 [==============================] - 91s 413ms/step - loss: 0.0285 - accuracy: 0.9892 - val_loss: 0.0884 - val_accuracy: 0.9736\nEpoch 43/50\n221/221 [==============================] - 91s 412ms/step - loss: 0.0265 - accuracy: 0.9904 - val_loss: 0.0847 - val_accuracy: 0.9742\nEpoch 44/50\n221/221 [==============================] - 90s 408ms/step - loss: 0.0243 - accuracy: 0.9913 - val_loss: 0.0919 - val_accuracy: 0.9743\nEpoch 45/50\n221/221 [==============================] - 90s 408ms/step - loss: 0.0240 - accuracy: 0.9913 - val_loss: 0.0893 - val_accuracy: 0.9731\nEpoch 46/50\n221/221 [==============================] - 92s 415ms/step - loss: 0.0244 - accuracy: 0.9913 - val_loss: 0.0804 - val_accuracy: 0.9756\nEpoch 47/50\n221/221 [==============================] - 92s 415ms/step - loss: 0.0266 - accuracy: 0.9897 - val_loss: 0.0853 - val_accuracy: 0.9749\nEpoch 48/50\n221/221 [==============================] - 91s 413ms/step - loss: 0.0233 - accuracy: 0.9915 - val_loss: 0.0835 - val_accuracy: 0.9750\nEpoch 49/50\n221/221 [==============================] - 91s 410ms/step - loss: 0.0245 - accuracy: 0.9911 - val_loss: 0.0915 - val_accuracy: 0.9728\nEpoch 50/50\n221/221 [==============================] - 92s 416ms/step - loss: 0.0236 - accuracy: 0.9913 - val_loss: 0.0817 - val_accuracy: 0.9752\nlength of remaining unlabled data:=\n66\nlength of train data:=\n40398\nEpoch 1/50\n221/221 [==============================] - 96s 413ms/step - loss: 0.3079 - accuracy: 0.8589 - val_loss: 0.2023 - val_accuracy: 0.9170\nEpoch 2/50\n221/221 [==============================] - 91s 410ms/step - loss: 0.1858 - accuracy: 0.9259 - val_loss: 0.1673 - val_accuracy: 0.9348\nEpoch 3/50\n221/221 [==============================] - 91s 410ms/step - loss: 0.1634 - accuracy: 0.9385 - val_loss: 0.1497 - val_accuracy: 0.9457\nEpoch 4/50\n221/221 [==============================] - 92s 416ms/step - loss: 0.1415 - accuracy: 0.9471 - val_loss: 0.1469 - val_accuracy: 0.9412\nEpoch 5/50\n221/221 [==============================] - 92s 417ms/step - loss: 0.1267 - accuracy: 0.9523 - val_loss: 0.1111 - val_accuracy: 0.9553\nEpoch 6/50\n221/221 [==============================] - 90s 408ms/step - loss: 0.1116 - accuracy: 0.9581 - val_loss: 0.1021 - val_accuracy: 0.9578\nEpoch 7/50\n221/221 [==============================] - 91s 411ms/step - loss: 0.1036 - accuracy: 0.9607 - val_loss: 0.1155 - val_accuracy: 0.9527\nEpoch 8/50\n221/221 [==============================] - 91s 413ms/step - loss: 0.0957 - accuracy: 0.9646 - val_loss: 0.1082 - val_accuracy: 0.9557\nEpoch 9/50\n221/221 [==============================] - 91s 413ms/step - loss: 0.0880 - accuracy: 0.9658 - val_loss: 0.0922 - val_accuracy: 0.9625\nEpoch 10/50\n221/221 [==============================] - 92s 416ms/step - loss: 0.0830 - accuracy: 0.9681 - val_loss: 0.0935 - val_accuracy: 0.9620\nEpoch 11/50\n221/221 [==============================] - 91s 413ms/step - loss: 0.0786 - accuracy: 0.9697 - val_loss: 0.0919 - val_accuracy: 0.9629\nEpoch 12/50\n221/221 [==============================] - 91s 413ms/step - loss: 0.0727 - accuracy: 0.9720 - val_loss: 0.0847 - val_accuracy: 0.9661\nEpoch 13/50\n221/221 [==============================] - 91s 410ms/step - loss: 0.0714 - accuracy: 0.9722 - val_loss: 0.0843 - val_accuracy: 0.9672\nEpoch 14/50\n221/221 [==============================] - 91s 411ms/step - loss: 0.0668 - accuracy: 0.9747 - val_loss: 0.0883 - val_accuracy: 0.9676\nEpoch 15/50\n221/221 [==============================] - 90s 409ms/step - loss: 0.0652 - accuracy: 0.9750 - val_loss: 0.0862 - val_accuracy: 0.9672\nEpoch 16/50\n221/221 [==============================] - 91s 412ms/step - loss: 0.0622 - accuracy: 0.9765 - val_loss: 0.0884 - val_accuracy: 0.9667\nEpoch 17/50\n221/221 [==============================] - 92s 416ms/step - loss: 0.0585 - accuracy: 0.9782 - val_loss: 0.0870 - val_accuracy: 0.9684\nEpoch 18/50\n221/221 [==============================] - 90s 409ms/step - loss: 0.0536 - accuracy: 0.9798 - val_loss: 0.0890 - val_accuracy: 0.9699\nEpoch 19/50\n221/221 [==============================] - 91s 410ms/step - loss: 0.0549 - accuracy: 0.9785 - val_loss: 0.0839 - val_accuracy: 0.9693\nEpoch 20/50\n221/221 [==============================] - 92s 416ms/step - loss: 0.0492 - accuracy: 0.9813 - val_loss: 0.0883 - val_accuracy: 0.9694\nEpoch 21/50\n221/221 [==============================] - 91s 411ms/step - loss: 0.0462 - accuracy: 0.9825 - val_loss: 0.0889 - val_accuracy: 0.9687\nEpoch 22/50\n221/221 [==============================] - 91s 412ms/step - loss: 0.0459 - accuracy: 0.9824 - val_loss: 0.0962 - val_accuracy: 0.9664\nEpoch 23/50\n221/221 [==============================] - 90s 409ms/step - loss: 0.0472 - accuracy: 0.9820 - val_loss: 0.0925 - val_accuracy: 0.9683\nEpoch 24/50\n221/221 [==============================] - 91s 413ms/step - loss: 0.0427 - accuracy: 0.9833 - val_loss: 0.0860 - val_accuracy: 0.9693\nEpoch 25/50\n221/221 [==============================] - 91s 411ms/step - loss: 0.0389 - accuracy: 0.9849 - val_loss: 0.0979 - val_accuracy: 0.9677\nEpoch 26/50\n221/221 [==============================] - 91s 411ms/step - loss: 0.0409 - accuracy: 0.9855 - val_loss: 0.0887 - val_accuracy: 0.9724\nEpoch 27/50\n221/221 [==============================] - 91s 412ms/step - loss: 0.0354 - accuracy: 0.9867 - val_loss: 0.0906 - val_accuracy: 0.9692\nEpoch 28/50\n221/221 [==============================] - 90s 409ms/step - loss: 0.0368 - accuracy: 0.9861 - val_loss: 0.0879 - val_accuracy: 0.9705\nEpoch 29/50\n221/221 [==============================] - 91s 411ms/step - loss: 0.0355 - accuracy: 0.9868 - val_loss: 0.0924 - val_accuracy: 0.9712\nEpoch 30/50\n221/221 [==============================] - 92s 414ms/step - loss: 0.0352 - accuracy: 0.9865 - val_loss: 0.0930 - val_accuracy: 0.9666\nEpoch 31/50\n221/221 [==============================] - 91s 411ms/step - loss: 0.0330 - accuracy: 0.9876 - val_loss: 0.0973 - val_accuracy: 0.9703\nEpoch 32/50\n221/221 [==============================] - 89s 405ms/step - loss: 0.0316 - accuracy: 0.9883 - val_loss: 0.0923 - val_accuracy: 0.9720\nEpoch 33/50\n221/221 [==============================] - 91s 413ms/step - loss: 0.0312 - accuracy: 0.9882 - val_loss: 0.0929 - val_accuracy: 0.9738\nEpoch 34/50\n221/221 [==============================] - 91s 412ms/step - loss: 0.0336 - accuracy: 0.9871 - val_loss: 0.0892 - val_accuracy: 0.9722\nEpoch 36/50\n221/221 [==============================] - 90s 408ms/step - loss: 0.0303 - accuracy: 0.9887 - val_loss: 0.0991 - val_accuracy: 0.9723\nEpoch 37/50\n221/221 [==============================] - 90s 408ms/step - loss: 0.0281 - accuracy: 0.9887 - val_loss: 0.0980 - val_accuracy: 0.9713\nEpoch 38/50\n221/221 [==============================] - 91s 411ms/step - loss: 0.0300 - accuracy: 0.9889 - val_loss: 0.0904 - val_accuracy: 0.9731\nEpoch 39/50\n221/221 [==============================] - 90s 407ms/step - loss: 0.0287 - accuracy: 0.9885 - val_loss: 0.0862 - val_accuracy: 0.9735\nEpoch 40/50\n221/221 [==============================] - 91s 411ms/step - loss: 0.0249 - accuracy: 0.9906 - val_loss: 0.1035 - val_accuracy: 0.9738\nEpoch 41/50\n221/221 [==============================] - 91s 410ms/step - loss: 0.0267 - accuracy: 0.9899 - val_loss: 0.0980 - val_accuracy: 0.9724\nEpoch 42/50\n221/221 [==============================] - 92s 417ms/step - loss: 0.0271 - accuracy: 0.9901 - val_loss: 0.0946 - val_accuracy: 0.9745\nEpoch 43/50\n221/221 [==============================] - 90s 406ms/step - loss: 0.0250 - accuracy: 0.9903 - val_loss: 0.1045 - val_accuracy: 0.9726\nEpoch 44/50\n221/221 [==============================] - 91s 412ms/step - loss: 0.0248 - accuracy: 0.9903 - val_loss: 0.1052 - val_accuracy: 0.9724\nEpoch 45/50\n221/221 [==============================] - 91s 413ms/step - loss: 0.0254 - accuracy: 0.9907 - val_loss: 0.0938 - val_accuracy: 0.9747\nEpoch 46/50\n221/221 [==============================] - 91s 413ms/step - loss: 0.0240 - accuracy: 0.9906 - val_loss: 0.0975 - val_accuracy: 0.9734\nEpoch 47/50\n221/221 [==============================] - 90s 406ms/step - loss: 0.0245 - accuracy: 0.9916 - val_loss: 0.0903 - val_accuracy: 0.9743\nEpoch 48/50\n221/221 [==============================] - 90s 409ms/step - loss: 0.0247 - accuracy: 0.9908 - val_loss: 0.1150 - val_accuracy: 0.9686\nEpoch 49/50\n221/221 [==============================] - 91s 411ms/step - loss: 0.0263 - accuracy: 0.9906 - val_loss: 0.0973 - val_accuracy: 0.9729\nEpoch 50/50\n221/221 [==============================] - 92s 415ms/step - loss: 0.0236 - accuracy: 0.9914 - val_loss: 0.1103 - val_accuracy: 0.9689\nlength of remaining unlabled data:=\n10\n","output_type":"stream"}]},{"cell_type":"code","source":"test_res=(model.predict(X_test) > 0.5).astype(\"int32\")\ntest_res=test_res.flatten()\ny_test_c = y_test.to_numpy()","metadata":{"execution":{"iopub.status.busy":"2022-04-17T15:17:43.744819Z","iopub.execute_input":"2022-04-17T15:17:43.745065Z","iopub.status.idle":"2022-04-17T15:17:47.332422Z","shell.execute_reply.started":"2022-04-17T15:17:43.745031Z","shell.execute_reply":"2022-04-17T15:17:47.331650Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"count=0\nfor i in range(0,len(y_test_c)):\n    if(y_test_c[i]==test_res[i]):\n        count=count+1\nprint(count)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T15:17:47.336269Z","iopub.execute_input":"2022-04-17T15:17:47.336535Z","iopub.status.idle":"2022-04-17T15:17:47.345435Z","shell.execute_reply.started":"2022-04-17T15:17:47.336498Z","shell.execute_reply":"2022-04-17T15:17:47.344403Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"4270\n","output_type":"stream"}]},{"cell_type":"code","source":"accuracy=(count/len(test_res))*100","metadata":{"execution":{"iopub.status.busy":"2022-04-17T15:17:47.346872Z","iopub.execute_input":"2022-04-17T15:17:47.347384Z","iopub.status.idle":"2022-04-17T15:17:47.355837Z","shell.execute_reply.started":"2022-04-17T15:17:47.347338Z","shell.execute_reply":"2022-04-17T15:17:47.355066Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"print(\"Accuracy at 10% labled data\",accuracy)","metadata":{"execution":{"iopub.status.busy":"2022-04-17T15:17:47.357133Z","iopub.execute_input":"2022-04-17T15:17:47.357485Z","iopub.status.idle":"2022-04-17T15:17:47.367153Z","shell.execute_reply.started":"2022-04-17T15:17:47.357446Z","shell.execute_reply":"2022-04-17T15:17:47.366484Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Accuracy at 10% labled data 95.10022271714922\n","output_type":"stream"}]},{"cell_type":"code","source":"print(classification_report(y_test,test_res, target_names = ['Fake','Real']))","metadata":{"execution":{"iopub.status.busy":"2022-04-17T15:17:47.369079Z","iopub.execute_input":"2022-04-17T15:17:47.369739Z","iopub.status.idle":"2022-04-17T15:17:47.388513Z","shell.execute_reply.started":"2022-04-17T15:17:47.369698Z","shell.execute_reply":"2022-04-17T15:17:47.387853Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n        Fake       0.98      0.92      0.95      2285\n        Real       0.93      0.98      0.95      2205\n\n    accuracy                           0.95      4490\n   macro avg       0.95      0.95      0.95      4490\nweighted avg       0.95      0.95      0.95      4490\n\n","output_type":"stream"}]}]}