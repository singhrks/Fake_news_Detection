{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-06T12:43:00.503054Z","iopub.execute_input":"2022-04-06T12:43:00.503363Z","iopub.status.idle":"2022-04-06T12:43:00.542490Z","shell.execute_reply.started":"2022-04-06T12:43:00.503285Z","shell.execute_reply":"2022-04-06T12:43:00.541267Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/glove-emb/glove.6B.100d.txt\n/kaggle/input/fake-news/train.tsv\n/kaggle/input/fake-news/valid.tsv\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom numpy import array\nfrom numpy import asarray\nfrom numpy import zeros\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers import Embedding\n\nimport nltk\nimport re\nimport string \n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\nimport keras\nfrom keras.preprocessing import text,sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Embedding,LSTM,Dropout\nimport tensorflow as tf\nfrom keras.layers import *\nfrom keras.utils.np_utils import to_categorical\nfrom keras.initializers import Constant\nimport re\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-04-06T12:43:00.544053Z","iopub.execute_input":"2022-04-06T12:43:00.544514Z","iopub.status.idle":"2022-04-06T12:43:07.022558Z","shell.execute_reply.started":"2022-04-06T12:43:00.544467Z","shell.execute_reply":"2022-04-06T12:43:07.021797Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/fake-news/train.tsv',sep=\"\\t\")","metadata":{"execution":{"iopub.status.busy":"2022-04-06T12:43:07.024343Z","iopub.execute_input":"2022-04-06T12:43:07.025054Z","iopub.status.idle":"2022-04-06T12:43:07.113689Z","shell.execute_reply.started":"2022-04-06T12:43:07.025016Z","shell.execute_reply":"2022-04-06T12:43:07.112915Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_data.columns=['id','label','statement','subjects','speaker','speaker_job_title','state_info','party_affiliation','count_1','count_2','count_3','count_4','count_5','context']","metadata":{"execution":{"iopub.status.busy":"2022-04-06T12:43:07.115450Z","iopub.execute_input":"2022-04-06T12:43:07.115715Z","iopub.status.idle":"2022-04-06T12:43:07.120627Z","shell.execute_reply.started":"2022-04-06T12:43:07.115681Z","shell.execute_reply":"2022-04-06T12:43:07.119722Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"for i in range(0,len(train_data)):\n  if((train_data['label'][i]=='true')):\n    train_data['label'][i]=1\n  else:\n    train_data['label'][i]=0","metadata":{"execution":{"iopub.status.busy":"2022-04-06T12:43:07.122025Z","iopub.execute_input":"2022-04-06T12:43:07.122503Z","iopub.status.idle":"2022-04-06T12:43:10.374409Z","shell.execute_reply.started":"2022-04-06T12:43:07.122460Z","shell.execute_reply":"2022-04-06T12:43:10.373701Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  \"\"\"\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  This is separate from the ipykernel package so we can avoid doing imports until\n","output_type":"stream"}]},{"cell_type":"code","source":"data=train_data\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-06T12:43:10.376765Z","iopub.execute_input":"2022-04-06T12:43:10.377252Z","iopub.status.idle":"2022-04-06T12:43:10.399744Z","shell.execute_reply.started":"2022-04-06T12:43:10.377214Z","shell.execute_reply":"2022-04-06T12:43:10.398995Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"           id label                                          statement  \\\n0  10540.json     0  When did the decline of coal start? It started...   \n1    324.json     0  Hillary Clinton agrees with John McCain \"by vo...   \n2   1123.json     0  Health care reform legislation is likely to ma...   \n3   9028.json     0  The economic turnaround started at the end of ...   \n4  12465.json     1  The Chicago Bears have had more starting quart...   \n\n                             subjects         speaker  \\\n0  energy,history,job-accomplishments  scott-surovell   \n1                      foreign-policy    barack-obama   \n2                         health-care    blog-posting   \n3                        economy,jobs   charlie-crist   \n4                           education       robin-vos   \n\n            speaker_job_title state_info party_affiliation  count_1  count_2  \\\n0              State delegate   Virginia          democrat      0.0      0.0   \n1                   President   Illinois          democrat     70.0     71.0   \n2                         NaN        NaN              none      7.0     19.0   \n3                         NaN    Florida          democrat     15.0      9.0   \n4  Wisconsin Assembly speaker  Wisconsin        republican      0.0      3.0   \n\n   count_3  count_4  count_5                    context  \n0      1.0      1.0      0.0            a floor speech.  \n1    160.0    163.0      9.0                     Denver  \n2      3.0      5.0     44.0             a news release  \n3     20.0     19.0      2.0        an interview on CNN  \n4      2.0      5.0      1.0  a an online opinion-piece  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n      <th>statement</th>\n      <th>subjects</th>\n      <th>speaker</th>\n      <th>speaker_job_title</th>\n      <th>state_info</th>\n      <th>party_affiliation</th>\n      <th>count_1</th>\n      <th>count_2</th>\n      <th>count_3</th>\n      <th>count_4</th>\n      <th>count_5</th>\n      <th>context</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10540.json</td>\n      <td>0</td>\n      <td>When did the decline of coal start? It started...</td>\n      <td>energy,history,job-accomplishments</td>\n      <td>scott-surovell</td>\n      <td>State delegate</td>\n      <td>Virginia</td>\n      <td>democrat</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>a floor speech.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>324.json</td>\n      <td>0</td>\n      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n      <td>foreign-policy</td>\n      <td>barack-obama</td>\n      <td>President</td>\n      <td>Illinois</td>\n      <td>democrat</td>\n      <td>70.0</td>\n      <td>71.0</td>\n      <td>160.0</td>\n      <td>163.0</td>\n      <td>9.0</td>\n      <td>Denver</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1123.json</td>\n      <td>0</td>\n      <td>Health care reform legislation is likely to ma...</td>\n      <td>health-care</td>\n      <td>blog-posting</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>none</td>\n      <td>7.0</td>\n      <td>19.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>44.0</td>\n      <td>a news release</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9028.json</td>\n      <td>0</td>\n      <td>The economic turnaround started at the end of ...</td>\n      <td>economy,jobs</td>\n      <td>charlie-crist</td>\n      <td>NaN</td>\n      <td>Florida</td>\n      <td>democrat</td>\n      <td>15.0</td>\n      <td>9.0</td>\n      <td>20.0</td>\n      <td>19.0</td>\n      <td>2.0</td>\n      <td>an interview on CNN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12465.json</td>\n      <td>1</td>\n      <td>The Chicago Bears have had more starting quart...</td>\n      <td>education</td>\n      <td>robin-vos</td>\n      <td>Wisconsin Assembly speaker</td>\n      <td>Wisconsin</td>\n      <td>republican</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>a an online opinion-piece</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data['text']= data['statement'] + \" \" + data['subjects'] + \" \" + data['context']\ndel data['statement']\ndel data['id']\ndel data['subjects']\ndel data['context']\ndel data['speaker']\ndel data['speaker_job_title']\ndel data['state_info']\ndel data['party_affiliation']\ndel data['count_1']\ndel data['count_2']\ndel data['count_3']\ndel data['count_4']\ndel data['count_5']\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-06T12:43:10.401074Z","iopub.execute_input":"2022-04-06T12:43:10.401324Z","iopub.status.idle":"2022-04-06T12:43:10.432815Z","shell.execute_reply.started":"2022-04-06T12:43:10.401292Z","shell.execute_reply":"2022-04-06T12:43:10.432079Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"  label                                               text\n0     0  When did the decline of coal start? It started...\n1     0  Hillary Clinton agrees with John McCain \"by vo...\n2     0  Health care reform legislation is likely to ma...\n3     0  The economic turnaround started at the end of ...\n4     1  The Chicago Bears have had more starting quart...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>When did the decline of coal start? It started...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>Health care reform legislation is likely to ma...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>The economic turnaround started at the end of ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>The Chicago Bears have had more starting quart...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.dropna()\ndata.fillna(\"\", inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T12:43:10.434153Z","iopub.execute_input":"2022-04-06T12:43:10.434389Z","iopub.status.idle":"2022-04-06T12:43:10.449798Z","shell.execute_reply.started":"2022-04-06T12:43:10.434357Z","shell.execute_reply":"2022-04-06T12:43:10.449066Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"pip install bs4","metadata":{"execution":{"iopub.status.busy":"2022-04-06T12:43:10.453350Z","iopub.execute_input":"2022-04-06T12:43:10.453527Z","iopub.status.idle":"2022-04-06T12:43:20.802395Z","shell.execute_reply.started":"2022-04-06T12:43:10.453506Z","shell.execute_reply":"2022-04-06T12:43:20.801519Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Collecting bs4\n  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from bs4) (4.10.0)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->bs4) (2.3.1)\nBuilding wheels for collected packages: bs4\n  Building wheel for bs4 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1271 sha256=fbbeae09c20245b757619d09187edf8f016b17ae57d383ee4a9a6436894321c5\n  Stored in directory: /root/.cache/pip/wheels/0a/9e/ba/20e5bbc1afef3a491f0b3bb74d508f99403aabe76eda2167ca\nSuccessfully built bs4\nInstalling collected packages: bs4\nSuccessfully installed bs4-0.0.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import nltk\nnltk.download('punkt')\nfrom bs4 import BeautifulSoup\nnltk.download(\"stopwords\")   \nfrom nltk.corpus import stopwords\nnltk.download('wordnet')","metadata":{"execution":{"iopub.status.busy":"2022-04-06T12:43:20.804179Z","iopub.execute_input":"2022-04-06T12:43:20.804471Z","iopub.status.idle":"2022-04-06T12:43:21.186648Z","shell.execute_reply.started":"2022-04-06T12:43:20.804434Z","shell.execute_reply":"2022-04-06T12:43:21.185903Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"def remove_characters(text):\n    return re.sub(\"[^a-zA-Z]\",\" \",text)\n\n#Removal of stopwords \ndef remove_stopwords_and_lemmatization(text):\n    final_text = []\n    text = text.lower()\n    text = nltk.word_tokenize(text)\n    \n    for word in text:\n        if word not in set(stopwords.words('english')):\n            lemma = nltk.WordNetLemmatizer()\n            word = lemma.lemmatize(word) \n            final_text.append(word)\n    return \" \".join(final_text)\n\n#Total function\ndef cleaning(text):\n    text = remove_characters(text)\n    text = remove_stopwords_and_lemmatization(text)\n    return text\n\n#Apply function on text column\ndata['text']=data['text'].apply(cleaning)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T12:43:21.189232Z","iopub.execute_input":"2022-04-06T12:43:21.189429Z","iopub.status.idle":"2022-04-06T12:43:59.993389Z","shell.execute_reply.started":"2022-04-06T12:43:21.189405Z","shell.execute_reply":"2022-04-06T12:43:59.992648Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"data=data.sample(frac=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T12:43:59.995359Z","iopub.execute_input":"2022-04-06T12:43:59.995796Z","iopub.status.idle":"2022-04-06T12:44:00.002881Z","shell.execute_reply.started":"2022-04-06T12:43:59.995699Z","shell.execute_reply":"2022-04-06T12:44:00.002084Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"**Training when data is 5% labled**","metadata":{}},{"cell_type":"code","source":"X_train1, X_test, y_train1, y_test = train_test_split(data['text'], data['label'],test_size=0.2 ,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T12:44:00.004337Z","iopub.execute_input":"2022-04-06T12:44:00.004589Z","iopub.status.idle":"2022-04-06T12:44:00.014293Z","shell.execute_reply.started":"2022-04-06T12:44:00.004557Z","shell.execute_reply":"2022-04-06T12:44:00.013568Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"X_lvl, X_unl, y_lvl, y_unl = train_test_split(X_train1,y_train1,test_size=0.95,random_state=0)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T12:44:00.017206Z","iopub.execute_input":"2022-04-06T12:44:00.017394Z","iopub.status.idle":"2022-04-06T12:44:00.024316Z","shell.execute_reply.started":"2022-04-06T12:44:00.017370Z","shell.execute_reply":"2022-04-06T12:44:00.023657Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"max_features = 3000\nmaxlen = 50","metadata":{"execution":{"iopub.status.busy":"2022-04-06T12:44:00.025418Z","iopub.execute_input":"2022-04-06T12:44:00.025859Z","iopub.status.idle":"2022-04-06T12:44:00.031780Z","shell.execute_reply.started":"2022-04-06T12:44:00.025826Z","shell.execute_reply":"2022-04-06T12:44:00.031120Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"tokenizer = text.Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(X_lvl)\ntokenized_train = tokenizer.texts_to_sequences(X_lvl)\nX_lvl = sequence.pad_sequences(tokenized_train, maxlen=maxlen)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T12:44:00.033125Z","iopub.execute_input":"2022-04-06T12:44:00.033468Z","iopub.status.idle":"2022-04-06T12:44:00.059522Z","shell.execute_reply.started":"2022-04-06T12:44:00.033433Z","shell.execute_reply":"2022-04-06T12:44:00.058860Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"tokenized_test = tokenizer.texts_to_sequences(X_test)\nX_test = sequence.pad_sequences(tokenized_test, maxlen=maxlen)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T12:44:00.062483Z","iopub.execute_input":"2022-04-06T12:44:00.063130Z","iopub.status.idle":"2022-04-06T12:44:00.113897Z","shell.execute_reply.started":"2022-04-06T12:44:00.063094Z","shell.execute_reply":"2022-04-06T12:44:00.113127Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"tokenized_unl = tokenizer.texts_to_sequences(X_unl)\nX_unl = sequence.pad_sequences(tokenized_unl, maxlen=maxlen)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T12:44:00.114950Z","iopub.execute_input":"2022-04-06T12:44:00.115649Z","iopub.status.idle":"2022-04-06T12:44:00.280755Z","shell.execute_reply.started":"2022-04-06T12:44:00.115619Z","shell.execute_reply":"2022-04-06T12:44:00.280104Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"batch_size = 128","metadata":{"execution":{"iopub.status.busy":"2022-04-06T12:44:00.281756Z","iopub.execute_input":"2022-04-06T12:44:00.281975Z","iopub.status.idle":"2022-04-06T12:44:00.285329Z","shell.execute_reply.started":"2022-04-06T12:44:00.281945Z","shell.execute_reply":"2022-04-06T12:44:00.284638Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras import regularizers\n\ndef build_model():\n  model = Sequential()\n  hp_units=160\n  model.add(Embedding(max_features, output_dim=100, input_length=maxlen, trainable=False))\n  model.add(LSTM(units=hp_units , return_sequences = True , recurrent_dropout =0.5,dropout=0.5))\n  model.add(LSTM(units=hp_units , recurrent_dropout = 0.5 , dropout = 0.5))\n  model.add(Dense(units=hp_units , activation = 'relu'))\n  model.add(Dense(1, activation='sigmoid'))\n  hp_learning_rate =.001\n  model.compile(tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),loss='binary_crossentropy', metrics=['accuracy'])\n  return model\n","metadata":{"execution":{"iopub.status.busy":"2022-04-06T12:44:00.286672Z","iopub.execute_input":"2022-04-06T12:44:00.287064Z","iopub.status.idle":"2022-04-06T12:44:00.618668Z","shell.execute_reply.started":"2022-04-06T12:44:00.287023Z","shell.execute_reply":"2022-04-06T12:44:00.617956Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"model=build_model()","metadata":{"execution":{"iopub.status.busy":"2022-04-06T12:44:00.620010Z","iopub.execute_input":"2022-04-06T12:44:00.620262Z","iopub.status.idle":"2022-04-06T12:44:03.441092Z","shell.execute_reply.started":"2022-04-06T12:44:00.620229Z","shell.execute_reply":"2022-04-06T12:44:03.440365Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"2022-04-06 12:44:00.695404: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-06 12:44:00.855418: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-06 12:44:00.856259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-06 12:44:00.857630: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-04-06 12:44:00.858762: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-06 12:44:00.859488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-06 12:44:00.860155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-06 12:44:02.824093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-06 12:44:02.825028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-06 12:44:02.825698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-06 12:44:02.826330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"history = model.fit(X_lvl, y_lvl, validation_split=0.3, epochs=300, batch_size=batch_size, shuffle=True, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T12:44:03.442282Z","iopub.execute_input":"2022-04-06T12:44:03.442527Z","iopub.status.idle":"2022-04-06T12:50:41.934158Z","shell.execute_reply.started":"2022-04-06T12:44:03.442495Z","shell.execute_reply":"2022-04-06T12:50:41.933397Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"2022-04-06 12:44:03.496355: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/300\n3/3 [==============================] - 6s 622ms/step - loss: 0.6864 - accuracy: 0.6154 - val_loss: 0.6080 - val_accuracy: 0.8862\nEpoch 2/300\n3/3 [==============================] - 1s 409ms/step - loss: 0.5860 - accuracy: 0.8182 - val_loss: 0.3657 - val_accuracy: 0.8862\nEpoch 3/300\n3/3 [==============================] - 1s 454ms/step - loss: 0.4825 - accuracy: 0.8182 - val_loss: 0.3814 - val_accuracy: 0.8862\nEpoch 4/300\n3/3 [==============================] - 1s 427ms/step - loss: 0.4835 - accuracy: 0.8182 - val_loss: 0.3748 - val_accuracy: 0.8862\nEpoch 5/300\n3/3 [==============================] - 1s 434ms/step - loss: 0.4770 - accuracy: 0.8182 - val_loss: 0.4024 - val_accuracy: 0.8862\nEpoch 6/300\n3/3 [==============================] - 2s 395ms/step - loss: 0.4854 - accuracy: 0.8182 - val_loss: 0.3903 - val_accuracy: 0.8862\nEpoch 7/300\n3/3 [==============================] - 1s 408ms/step - loss: 0.4763 - accuracy: 0.8182 - val_loss: 0.3629 - val_accuracy: 0.8862\nEpoch 8/300\n3/3 [==============================] - 1s 422ms/step - loss: 0.4835 - accuracy: 0.8182 - val_loss: 0.3570 - val_accuracy: 0.8862\nEpoch 9/300\n3/3 [==============================] - 1s 406ms/step - loss: 0.4781 - accuracy: 0.8182 - val_loss: 0.3729 - val_accuracy: 0.8862\nEpoch 10/300\n3/3 [==============================] - 1s 450ms/step - loss: 0.4772 - accuracy: 0.8182 - val_loss: 0.3899 - val_accuracy: 0.8862\nEpoch 11/300\n3/3 [==============================] - 1s 419ms/step - loss: 0.4801 - accuracy: 0.8182 - val_loss: 0.3796 - val_accuracy: 0.8862\nEpoch 12/300\n3/3 [==============================] - 1s 424ms/step - loss: 0.4746 - accuracy: 0.8182 - val_loss: 0.3698 - val_accuracy: 0.8862\nEpoch 13/300\n3/3 [==============================] - 1s 424ms/step - loss: 0.4767 - accuracy: 0.8182 - val_loss: 0.3655 - val_accuracy: 0.8862\nEpoch 14/300\n3/3 [==============================] - 2s 607ms/step - loss: 0.4752 - accuracy: 0.8182 - val_loss: 0.3727 - val_accuracy: 0.8862\nEpoch 15/300\n3/3 [==============================] - 1s 391ms/step - loss: 0.4731 - accuracy: 0.8182 - val_loss: 0.3757 - val_accuracy: 0.8862\nEpoch 16/300\n3/3 [==============================] - 1s 392ms/step - loss: 0.4741 - accuracy: 0.8182 - val_loss: 0.3690 - val_accuracy: 0.8862\nEpoch 17/300\n3/3 [==============================] - 2s 573ms/step - loss: 0.4739 - accuracy: 0.8182 - val_loss: 0.3651 - val_accuracy: 0.8862\nEpoch 18/300\n3/3 [==============================] - 1s 410ms/step - loss: 0.4768 - accuracy: 0.8182 - val_loss: 0.3584 - val_accuracy: 0.8862\nEpoch 19/300\n3/3 [==============================] - 1s 425ms/step - loss: 0.4760 - accuracy: 0.8182 - val_loss: 0.3621 - val_accuracy: 0.8862\nEpoch 20/300\n3/3 [==============================] - 1s 390ms/step - loss: 0.4794 - accuracy: 0.8182 - val_loss: 0.3698 - val_accuracy: 0.8862\nEpoch 21/300\n3/3 [==============================] - 1s 395ms/step - loss: 0.4748 - accuracy: 0.8182 - val_loss: 0.3627 - val_accuracy: 0.8862\nEpoch 22/300\n3/3 [==============================] - 1s 484ms/step - loss: 0.4717 - accuracy: 0.8182 - val_loss: 0.3700 - val_accuracy: 0.8862\nEpoch 23/300\n3/3 [==============================] - 1s 420ms/step - loss: 0.4755 - accuracy: 0.8182 - val_loss: 0.3761 - val_accuracy: 0.8862\nEpoch 24/300\n3/3 [==============================] - 1s 414ms/step - loss: 0.4762 - accuracy: 0.8182 - val_loss: 0.3720 - val_accuracy: 0.8862\nEpoch 25/300\n3/3 [==============================] - 1s 427ms/step - loss: 0.4750 - accuracy: 0.8182 - val_loss: 0.3692 - val_accuracy: 0.8862\nEpoch 26/300\n3/3 [==============================] - 1s 420ms/step - loss: 0.4735 - accuracy: 0.8182 - val_loss: 0.3676 - val_accuracy: 0.8862\nEpoch 27/300\n3/3 [==============================] - 1s 409ms/step - loss: 0.4754 - accuracy: 0.8182 - val_loss: 0.3605 - val_accuracy: 0.8862\nEpoch 28/300\n3/3 [==============================] - 1s 436ms/step - loss: 0.4746 - accuracy: 0.8182 - val_loss: 0.3586 - val_accuracy: 0.8862\nEpoch 29/300\n3/3 [==============================] - 1s 411ms/step - loss: 0.4793 - accuracy: 0.8182 - val_loss: 0.3636 - val_accuracy: 0.8862\nEpoch 30/300\n3/3 [==============================] - 1s 423ms/step - loss: 0.4739 - accuracy: 0.8182 - val_loss: 0.3713 - val_accuracy: 0.8862\nEpoch 31/300\n3/3 [==============================] - 2s 635ms/step - loss: 0.4760 - accuracy: 0.8182 - val_loss: 0.3727 - val_accuracy: 0.8862\nEpoch 32/300\n3/3 [==============================] - 1s 420ms/step - loss: 0.4742 - accuracy: 0.8182 - val_loss: 0.3704 - val_accuracy: 0.8862\nEpoch 33/300\n3/3 [==============================] - 1s 423ms/step - loss: 0.4738 - accuracy: 0.8182 - val_loss: 0.3633 - val_accuracy: 0.8862\nEpoch 34/300\n3/3 [==============================] - 1s 425ms/step - loss: 0.4739 - accuracy: 0.8182 - val_loss: 0.3602 - val_accuracy: 0.8862\nEpoch 35/300\n3/3 [==============================] - 1s 411ms/step - loss: 0.4758 - accuracy: 0.8182 - val_loss: 0.3663 - val_accuracy: 0.8862\nEpoch 36/300\n3/3 [==============================] - 1s 415ms/step - loss: 0.4750 - accuracy: 0.8182 - val_loss: 0.3806 - val_accuracy: 0.8862\nEpoch 37/300\n3/3 [==============================] - 1s 402ms/step - loss: 0.4766 - accuracy: 0.8182 - val_loss: 0.3993 - val_accuracy: 0.8862\nEpoch 38/300\n3/3 [==============================] - 1s 404ms/step - loss: 0.4800 - accuracy: 0.8182 - val_loss: 0.3726 - val_accuracy: 0.8862\nEpoch 39/300\n3/3 [==============================] - 1s 459ms/step - loss: 0.4716 - accuracy: 0.8182 - val_loss: 0.3589 - val_accuracy: 0.8862\nEpoch 40/300\n3/3 [==============================] - 2s 442ms/step - loss: 0.4760 - accuracy: 0.8182 - val_loss: 0.3595 - val_accuracy: 0.8862\nEpoch 41/300\n3/3 [==============================] - 1s 452ms/step - loss: 0.4750 - accuracy: 0.8182 - val_loss: 0.3651 - val_accuracy: 0.8862\nEpoch 42/300\n3/3 [==============================] - 2s 406ms/step - loss: 0.4707 - accuracy: 0.8182 - val_loss: 0.3680 - val_accuracy: 0.8862\nEpoch 43/300\n3/3 [==============================] - 1s 417ms/step - loss: 0.4734 - accuracy: 0.8182 - val_loss: 0.3765 - val_accuracy: 0.8862\nEpoch 44/300\n3/3 [==============================] - 1s 396ms/step - loss: 0.4740 - accuracy: 0.8182 - val_loss: 0.3779 - val_accuracy: 0.8862\nEpoch 45/300\n3/3 [==============================] - 1s 421ms/step - loss: 0.4715 - accuracy: 0.8182 - val_loss: 0.3686 - val_accuracy: 0.8862\nEpoch 46/300\n3/3 [==============================] - 1s 412ms/step - loss: 0.4727 - accuracy: 0.8182 - val_loss: 0.3795 - val_accuracy: 0.8862\nEpoch 47/300\n3/3 [==============================] - 1s 418ms/step - loss: 0.4720 - accuracy: 0.8182 - val_loss: 0.3889 - val_accuracy: 0.8862\nEpoch 48/300\n3/3 [==============================] - 2s 475ms/step - loss: 0.4780 - accuracy: 0.8182 - val_loss: 0.3830 - val_accuracy: 0.8862\nEpoch 49/300\n3/3 [==============================] - 1s 400ms/step - loss: 0.4727 - accuracy: 0.8182 - val_loss: 0.3556 - val_accuracy: 0.8862\nEpoch 50/300\n3/3 [==============================] - 1s 419ms/step - loss: 0.4804 - accuracy: 0.8182 - val_loss: 0.3542 - val_accuracy: 0.8862\nEpoch 51/300\n3/3 [==============================] - 1s 415ms/step - loss: 0.4787 - accuracy: 0.8182 - val_loss: 0.3567 - val_accuracy: 0.8862\nEpoch 52/300\n3/3 [==============================] - 1s 409ms/step - loss: 0.4719 - accuracy: 0.8182 - val_loss: 0.3783 - val_accuracy: 0.8862\nEpoch 53/300\n3/3 [==============================] - 1s 448ms/step - loss: 0.4751 - accuracy: 0.8182 - val_loss: 0.3883 - val_accuracy: 0.8862\nEpoch 54/300\n3/3 [==============================] - 1s 415ms/step - loss: 0.4746 - accuracy: 0.8182 - val_loss: 0.3774 - val_accuracy: 0.8862\nEpoch 55/300\n3/3 [==============================] - 1s 399ms/step - loss: 0.4695 - accuracy: 0.8182 - val_loss: 0.3681 - val_accuracy: 0.8862\nEpoch 56/300\n3/3 [==============================] - 2s 607ms/step - loss: 0.4662 - accuracy: 0.8182 - val_loss: 0.3632 - val_accuracy: 0.8862\nEpoch 57/300\n3/3 [==============================] - 1s 428ms/step - loss: 0.4659 - accuracy: 0.8182 - val_loss: 0.3570 - val_accuracy: 0.8862\nEpoch 58/300\n3/3 [==============================] - 1s 395ms/step - loss: 0.4677 - accuracy: 0.8182 - val_loss: 0.3642 - val_accuracy: 0.8862\nEpoch 59/300\n3/3 [==============================] - 1s 418ms/step - loss: 0.4611 - accuracy: 0.8182 - val_loss: 0.3701 - val_accuracy: 0.8862\nEpoch 60/300\n3/3 [==============================] - 1s 401ms/step - loss: 0.4580 - accuracy: 0.8182 - val_loss: 0.3621 - val_accuracy: 0.8862\nEpoch 61/300\n3/3 [==============================] - 1s 419ms/step - loss: 0.4518 - accuracy: 0.8182 - val_loss: 0.4650 - val_accuracy: 0.8862\nEpoch 62/300\n3/3 [==============================] - 1s 435ms/step - loss: 0.4719 - accuracy: 0.8147 - val_loss: 0.3525 - val_accuracy: 0.8862\nEpoch 63/300\n3/3 [==============================] - 1s 427ms/step - loss: 0.4498 - accuracy: 0.8182 - val_loss: 0.3792 - val_accuracy: 0.8862\nEpoch 64/300\n3/3 [==============================] - 1s 422ms/step - loss: 0.4557 - accuracy: 0.8182 - val_loss: 0.3760 - val_accuracy: 0.8862\nEpoch 65/300\n3/3 [==============================] - 2s 541ms/step - loss: 0.4392 - accuracy: 0.8182 - val_loss: 0.3568 - val_accuracy: 0.8862\nEpoch 66/300\n3/3 [==============================] - 2s 709ms/step - loss: 0.4415 - accuracy: 0.8182 - val_loss: 0.3584 - val_accuracy: 0.8862\nEpoch 67/300\n3/3 [==============================] - 1s 398ms/step - loss: 0.4302 - accuracy: 0.8182 - val_loss: 0.3702 - val_accuracy: 0.8862\nEpoch 68/300\n3/3 [==============================] - 1s 397ms/step - loss: 0.4389 - accuracy: 0.8182 - val_loss: 0.3774 - val_accuracy: 0.8862\nEpoch 69/300\n3/3 [==============================] - 1s 437ms/step - loss: 0.4392 - accuracy: 0.8182 - val_loss: 0.3869 - val_accuracy: 0.8862\nEpoch 70/300\n3/3 [==============================] - 1s 442ms/step - loss: 0.4352 - accuracy: 0.8182 - val_loss: 0.3750 - val_accuracy: 0.8862\nEpoch 71/300\n3/3 [==============================] - 1s 424ms/step - loss: 0.4163 - accuracy: 0.8182 - val_loss: 0.3694 - val_accuracy: 0.8862\nEpoch 72/300\n3/3 [==============================] - 1s 436ms/step - loss: 0.4240 - accuracy: 0.8182 - val_loss: 0.4443 - val_accuracy: 0.8862\nEpoch 73/300\n3/3 [==============================] - 2s 547ms/step - loss: 0.4318 - accuracy: 0.8182 - val_loss: 0.3789 - val_accuracy: 0.8862\nEpoch 74/300\n3/3 [==============================] - 1s 402ms/step - loss: 0.4029 - accuracy: 0.8217 - val_loss: 0.3865 - val_accuracy: 0.8862\nEpoch 75/300\n3/3 [==============================] - 1s 420ms/step - loss: 0.4172 - accuracy: 0.8217 - val_loss: 0.4309 - val_accuracy: 0.8862\nEpoch 76/300\n3/3 [==============================] - 1s 393ms/step - loss: 0.4128 - accuracy: 0.8322 - val_loss: 0.3975 - val_accuracy: 0.8862\nEpoch 77/300\n3/3 [==============================] - 1s 398ms/step - loss: 0.4456 - accuracy: 0.8252 - val_loss: 0.4070 - val_accuracy: 0.8862\nEpoch 78/300\n3/3 [==============================] - 1s 418ms/step - loss: 0.4018 - accuracy: 0.8322 - val_loss: 0.4060 - val_accuracy: 0.8862\nEpoch 79/300\n3/3 [==============================] - 1s 414ms/step - loss: 0.4071 - accuracy: 0.8252 - val_loss: 0.3843 - val_accuracy: 0.8862\nEpoch 80/300\n3/3 [==============================] - 1s 437ms/step - loss: 0.4290 - accuracy: 0.8217 - val_loss: 0.3825 - val_accuracy: 0.8862\nEpoch 81/300\n3/3 [==============================] - 2s 563ms/step - loss: 0.3850 - accuracy: 0.8322 - val_loss: 0.4629 - val_accuracy: 0.8618\nEpoch 82/300\n3/3 [==============================] - 1s 392ms/step - loss: 0.4322 - accuracy: 0.8252 - val_loss: 0.3929 - val_accuracy: 0.8780\nEpoch 83/300\n3/3 [==============================] - 1s 440ms/step - loss: 0.4020 - accuracy: 0.8322 - val_loss: 0.3832 - val_accuracy: 0.8862\nEpoch 84/300\n3/3 [==============================] - 1s 418ms/step - loss: 0.4198 - accuracy: 0.8182 - val_loss: 0.3955 - val_accuracy: 0.8780\nEpoch 85/300\n3/3 [==============================] - 1s 399ms/step - loss: 0.3862 - accuracy: 0.8427 - val_loss: 0.4553 - val_accuracy: 0.8537\nEpoch 86/300\n3/3 [==============================] - 1s 414ms/step - loss: 0.3850 - accuracy: 0.8392 - val_loss: 0.4131 - val_accuracy: 0.8780\nEpoch 87/300\n3/3 [==============================] - 1s 413ms/step - loss: 0.4096 - accuracy: 0.8112 - val_loss: 0.4139 - val_accuracy: 0.8780\nEpoch 88/300\n3/3 [==============================] - 1s 413ms/step - loss: 0.3619 - accuracy: 0.8357 - val_loss: 0.4431 - val_accuracy: 0.8455\nEpoch 89/300\n3/3 [==============================] - 1s 417ms/step - loss: 0.3816 - accuracy: 0.8357 - val_loss: 0.3984 - val_accuracy: 0.8780\nEpoch 90/300\n3/3 [==============================] - 2s 700ms/step - loss: 0.3616 - accuracy: 0.8357 - val_loss: 0.4085 - val_accuracy: 0.8780\nEpoch 91/300\n3/3 [==============================] - 2s 406ms/step - loss: 0.3695 - accuracy: 0.8497 - val_loss: 0.4524 - val_accuracy: 0.8374\nEpoch 92/300\n3/3 [==============================] - 1s 393ms/step - loss: 0.3816 - accuracy: 0.8497 - val_loss: 0.4238 - val_accuracy: 0.8780\nEpoch 93/300\n3/3 [==============================] - 1s 393ms/step - loss: 0.3441 - accuracy: 0.8531 - val_loss: 0.4450 - val_accuracy: 0.8537\nEpoch 94/300\n3/3 [==============================] - 1s 428ms/step - loss: 0.3895 - accuracy: 0.8112 - val_loss: 0.4770 - val_accuracy: 0.8293\nEpoch 95/300\n3/3 [==============================] - 1s 415ms/step - loss: 0.3323 - accuracy: 0.8706 - val_loss: 0.4288 - val_accuracy: 0.8780\nEpoch 96/300\n3/3 [==============================] - 1s 398ms/step - loss: 0.3962 - accuracy: 0.8427 - val_loss: 0.4489 - val_accuracy: 0.8374\nEpoch 97/300\n3/3 [==============================] - 1s 418ms/step - loss: 0.3918 - accuracy: 0.8217 - val_loss: 0.5085 - val_accuracy: 0.8049\nEpoch 98/300\n3/3 [==============================] - 2s 610ms/step - loss: 0.3797 - accuracy: 0.8462 - val_loss: 0.4138 - val_accuracy: 0.8699\nEpoch 99/300\n3/3 [==============================] - 1s 396ms/step - loss: 0.3607 - accuracy: 0.8462 - val_loss: 0.4124 - val_accuracy: 0.8780\nEpoch 100/300\n3/3 [==============================] - 1s 411ms/step - loss: 0.3731 - accuracy: 0.8217 - val_loss: 0.4578 - val_accuracy: 0.8374\nEpoch 101/300\n3/3 [==============================] - 1s 430ms/step - loss: 0.3658 - accuracy: 0.8462 - val_loss: 0.5174 - val_accuracy: 0.7724\nEpoch 102/300\n3/3 [==============================] - 1s 396ms/step - loss: 0.3629 - accuracy: 0.8392 - val_loss: 0.4449 - val_accuracy: 0.8618\nEpoch 103/300\n3/3 [==============================] - 1s 393ms/step - loss: 0.3461 - accuracy: 0.8462 - val_loss: 0.4509 - val_accuracy: 0.8699\nEpoch 104/300\n3/3 [==============================] - 1s 424ms/step - loss: 0.3674 - accuracy: 0.8427 - val_loss: 0.4596 - val_accuracy: 0.8293\nEpoch 105/300\n3/3 [==============================] - 1s 405ms/step - loss: 0.3929 - accuracy: 0.8601 - val_loss: 0.4984 - val_accuracy: 0.7967\nEpoch 106/300\n3/3 [==============================] - 1s 407ms/step - loss: 0.3778 - accuracy: 0.8357 - val_loss: 0.4236 - val_accuracy: 0.8618\nEpoch 107/300\n3/3 [==============================] - 2s 558ms/step - loss: 0.3560 - accuracy: 0.8462 - val_loss: 0.4124 - val_accuracy: 0.8780\nEpoch 108/300\n3/3 [==============================] - 1s 387ms/step - loss: 0.3304 - accuracy: 0.8531 - val_loss: 0.4480 - val_accuracy: 0.8293\nEpoch 109/300\n3/3 [==============================] - 1s 406ms/step - loss: 0.3914 - accuracy: 0.8112 - val_loss: 0.5232 - val_accuracy: 0.7398\nEpoch 110/300\n3/3 [==============================] - 1s 425ms/step - loss: 0.3489 - accuracy: 0.8601 - val_loss: 0.4367 - val_accuracy: 0.8537\nEpoch 111/300\n3/3 [==============================] - 1s 440ms/step - loss: 0.3414 - accuracy: 0.8357 - val_loss: 0.4374 - val_accuracy: 0.8618\nEpoch 112/300\n3/3 [==============================] - 1s 421ms/step - loss: 0.3290 - accuracy: 0.8636 - val_loss: 0.4782 - val_accuracy: 0.8211\nEpoch 113/300\n3/3 [==============================] - 1s 423ms/step - loss: 0.3368 - accuracy: 0.8497 - val_loss: 0.5444 - val_accuracy: 0.7642\nEpoch 114/300\n3/3 [==============================] - 1s 403ms/step - loss: 0.2809 - accuracy: 0.8951 - val_loss: 0.5408 - val_accuracy: 0.8130\nEpoch 115/300\n3/3 [==============================] - 2s 830ms/step - loss: 0.3010 - accuracy: 0.8846 - val_loss: 0.5692 - val_accuracy: 0.7886\nEpoch 116/300\n3/3 [==============================] - 1s 396ms/step - loss: 0.3536 - accuracy: 0.8531 - val_loss: 0.5780 - val_accuracy: 0.7642\nEpoch 117/300\n3/3 [==============================] - 1s 407ms/step - loss: 0.3230 - accuracy: 0.8392 - val_loss: 0.4566 - val_accuracy: 0.8374\nEpoch 118/300\n3/3 [==============================] - 1s 444ms/step - loss: 0.3613 - accuracy: 0.8531 - val_loss: 0.4179 - val_accuracy: 0.8780\nEpoch 119/300\n3/3 [==============================] - 1s 407ms/step - loss: 0.3406 - accuracy: 0.8427 - val_loss: 0.4197 - val_accuracy: 0.8699\nEpoch 120/300\n3/3 [==============================] - 1s 429ms/step - loss: 0.3479 - accuracy: 0.8497 - val_loss: 0.4594 - val_accuracy: 0.8130\nEpoch 121/300\n3/3 [==============================] - 1s 394ms/step - loss: 0.3355 - accuracy: 0.8636 - val_loss: 0.4585 - val_accuracy: 0.8293\nEpoch 122/300\n3/3 [==============================] - 1s 408ms/step - loss: 0.3465 - accuracy: 0.8601 - val_loss: 0.4590 - val_accuracy: 0.8374\nEpoch 123/300\n3/3 [==============================] - 1s 410ms/step - loss: 0.3200 - accuracy: 0.8741 - val_loss: 0.5157 - val_accuracy: 0.7805\nEpoch 124/300\n3/3 [==============================] - 2s 402ms/step - loss: 0.3186 - accuracy: 0.8531 - val_loss: 0.5292 - val_accuracy: 0.7886\nEpoch 125/300\n3/3 [==============================] - 1s 401ms/step - loss: 0.2765 - accuracy: 0.8811 - val_loss: 0.5287 - val_accuracy: 0.8374\nEpoch 126/300\n3/3 [==============================] - 1s 427ms/step - loss: 0.3185 - accuracy: 0.8741 - val_loss: 0.5418 - val_accuracy: 0.8211\nEpoch 127/300\n3/3 [==============================] - 1s 408ms/step - loss: 0.3436 - accuracy: 0.8601 - val_loss: 0.5395 - val_accuracy: 0.7886\nEpoch 128/300\n3/3 [==============================] - 1s 393ms/step - loss: 0.3078 - accuracy: 0.8636 - val_loss: 0.4908 - val_accuracy: 0.7967\nEpoch 129/300\n3/3 [==============================] - 1s 424ms/step - loss: 0.2932 - accuracy: 0.8671 - val_loss: 0.4828 - val_accuracy: 0.8374\nEpoch 130/300\n3/3 [==============================] - 1s 389ms/step - loss: 0.3059 - accuracy: 0.8741 - val_loss: 0.5094 - val_accuracy: 0.8293\nEpoch 131/300\n3/3 [==============================] - 1s 400ms/step - loss: 0.3052 - accuracy: 0.8776 - val_loss: 0.5434 - val_accuracy: 0.7967\nEpoch 132/300\n3/3 [==============================] - 1s 536ms/step - loss: 0.3738 - accuracy: 0.8112 - val_loss: 0.4933 - val_accuracy: 0.8293\nEpoch 133/300\n3/3 [==============================] - 1s 411ms/step - loss: 0.2987 - accuracy: 0.8566 - val_loss: 0.4749 - val_accuracy: 0.8455\nEpoch 134/300\n3/3 [==============================] - 1s 410ms/step - loss: 0.2691 - accuracy: 0.8951 - val_loss: 0.5120 - val_accuracy: 0.7886\nEpoch 135/300\n3/3 [==============================] - 1s 404ms/step - loss: 0.2884 - accuracy: 0.8741 - val_loss: 0.4982 - val_accuracy: 0.8211\nEpoch 136/300\n3/3 [==============================] - 1s 441ms/step - loss: 0.3398 - accuracy: 0.8706 - val_loss: 0.4777 - val_accuracy: 0.8374\nEpoch 137/300\n3/3 [==============================] - 1s 429ms/step - loss: 0.3023 - accuracy: 0.8671 - val_loss: 0.4952 - val_accuracy: 0.8374\nEpoch 138/300\n3/3 [==============================] - 1s 444ms/step - loss: 0.3058 - accuracy: 0.8497 - val_loss: 0.4902 - val_accuracy: 0.8374\nEpoch 139/300\n3/3 [==============================] - 1s 416ms/step - loss: 0.2546 - accuracy: 0.8986 - val_loss: 0.4792 - val_accuracy: 0.8618\nEpoch 140/300\n3/3 [==============================] - 2s 847ms/step - loss: 0.2974 - accuracy: 0.8846 - val_loss: 0.4676 - val_accuracy: 0.8374\nEpoch 141/300\n3/3 [==============================] - 1s 404ms/step - loss: 0.3236 - accuracy: 0.8776 - val_loss: 0.4742 - val_accuracy: 0.8293\nEpoch 142/300\n3/3 [==============================] - 1s 398ms/step - loss: 0.3056 - accuracy: 0.8776 - val_loss: 0.4701 - val_accuracy: 0.8618\nEpoch 143/300\n3/3 [==============================] - 1s 443ms/step - loss: 0.3495 - accuracy: 0.8636 - val_loss: 0.4600 - val_accuracy: 0.8293\nEpoch 144/300\n3/3 [==============================] - 1s 432ms/step - loss: 0.3097 - accuracy: 0.8776 - val_loss: 0.4998 - val_accuracy: 0.8130\nEpoch 145/300\n3/3 [==============================] - 1s 429ms/step - loss: 0.3014 - accuracy: 0.8811 - val_loss: 0.4539 - val_accuracy: 0.8374\nEpoch 146/300\n3/3 [==============================] - 1s 430ms/step - loss: 0.3064 - accuracy: 0.8776 - val_loss: 0.4526 - val_accuracy: 0.8618\nEpoch 147/300\n3/3 [==============================] - 1s 399ms/step - loss: 0.3215 - accuracy: 0.8776 - val_loss: 0.4744 - val_accuracy: 0.8618\nEpoch 148/300\n3/3 [==============================] - 1s 434ms/step - loss: 0.2730 - accuracy: 0.8846 - val_loss: 0.5254 - val_accuracy: 0.8130\nEpoch 149/300\n3/3 [==============================] - 2s 609ms/step - loss: 0.2892 - accuracy: 0.8741 - val_loss: 0.5546 - val_accuracy: 0.8211\nEpoch 150/300\n3/3 [==============================] - 1s 407ms/step - loss: 0.3296 - accuracy: 0.8671 - val_loss: 0.5064 - val_accuracy: 0.8293\nEpoch 151/300\n3/3 [==============================] - 1s 411ms/step - loss: 0.3134 - accuracy: 0.8741 - val_loss: 0.4552 - val_accuracy: 0.8455\nEpoch 152/300\n3/3 [==============================] - 1s 410ms/step - loss: 0.3023 - accuracy: 0.8776 - val_loss: 0.4402 - val_accuracy: 0.8455\nEpoch 153/300\n3/3 [==============================] - 1s 443ms/step - loss: 0.2920 - accuracy: 0.8706 - val_loss: 0.4520 - val_accuracy: 0.8374\nEpoch 154/300\n3/3 [==============================] - 1s 418ms/step - loss: 0.3058 - accuracy: 0.8811 - val_loss: 0.4505 - val_accuracy: 0.8293\nEpoch 155/300\n3/3 [==============================] - 1s 388ms/step - loss: 0.2964 - accuracy: 0.8811 - val_loss: 0.4453 - val_accuracy: 0.8618\nEpoch 156/300\n3/3 [==============================] - 1s 426ms/step - loss: 0.2861 - accuracy: 0.8776 - val_loss: 0.4560 - val_accuracy: 0.8455\nEpoch 157/300\n3/3 [==============================] - 1s 466ms/step - loss: 0.2824 - accuracy: 0.8776 - val_loss: 0.4833 - val_accuracy: 0.8130\nEpoch 158/300\n3/3 [==============================] - 1s 398ms/step - loss: 0.2784 - accuracy: 0.8951 - val_loss: 0.4783 - val_accuracy: 0.8130\nEpoch 159/300\n3/3 [==============================] - 1s 408ms/step - loss: 0.2978 - accuracy: 0.8741 - val_loss: 0.4787 - val_accuracy: 0.8211\nEpoch 160/300\n3/3 [==============================] - 1s 423ms/step - loss: 0.2771 - accuracy: 0.8741 - val_loss: 0.5033 - val_accuracy: 0.8049\nEpoch 161/300\n3/3 [==============================] - 1s 439ms/step - loss: 0.2973 - accuracy: 0.8636 - val_loss: 0.4754 - val_accuracy: 0.8049\nEpoch 162/300\n3/3 [==============================] - 1s 402ms/step - loss: 0.2699 - accuracy: 0.8776 - val_loss: 0.4623 - val_accuracy: 0.8130\nEpoch 163/300\n3/3 [==============================] - 1s 424ms/step - loss: 0.3018 - accuracy: 0.8776 - val_loss: 0.4648 - val_accuracy: 0.8211\nEpoch 164/300\n3/3 [==============================] - 1s 417ms/step - loss: 0.2753 - accuracy: 0.8881 - val_loss: 0.4532 - val_accuracy: 0.8537\nEpoch 165/300\n3/3 [==============================] - 2s 870ms/step - loss: 0.2314 - accuracy: 0.9161 - val_loss: 0.4782 - val_accuracy: 0.8130\nEpoch 166/300\n3/3 [==============================] - 1s 396ms/step - loss: 0.2683 - accuracy: 0.8846 - val_loss: 0.5080 - val_accuracy: 0.8049\nEpoch 167/300\n3/3 [==============================] - 1s 402ms/step - loss: 0.3158 - accuracy: 0.8671 - val_loss: 0.4995 - val_accuracy: 0.8130\nEpoch 168/300\n3/3 [==============================] - 1s 394ms/step - loss: 0.2484 - accuracy: 0.8916 - val_loss: 0.4872 - val_accuracy: 0.8049\nEpoch 169/300\n3/3 [==============================] - 1s 418ms/step - loss: 0.2933 - accuracy: 0.8776 - val_loss: 0.4637 - val_accuracy: 0.8211\nEpoch 170/300\n3/3 [==============================] - 1s 413ms/step - loss: 0.2684 - accuracy: 0.8916 - val_loss: 0.4546 - val_accuracy: 0.8537\nEpoch 171/300\n3/3 [==============================] - 1s 427ms/step - loss: 0.2805 - accuracy: 0.8986 - val_loss: 0.4845 - val_accuracy: 0.8293\nEpoch 172/300\n3/3 [==============================] - 1s 432ms/step - loss: 0.2890 - accuracy: 0.8811 - val_loss: 0.5391 - val_accuracy: 0.7886\nEpoch 173/300\n3/3 [==============================] - 1s 424ms/step - loss: 0.2560 - accuracy: 0.8951 - val_loss: 0.5088 - val_accuracy: 0.8049\nEpoch 174/300\n3/3 [==============================] - 2s 616ms/step - loss: 0.2630 - accuracy: 0.8881 - val_loss: 0.4931 - val_accuracy: 0.8374\nEpoch 175/300\n3/3 [==============================] - 1s 392ms/step - loss: 0.2883 - accuracy: 0.8811 - val_loss: 0.5011 - val_accuracy: 0.8049\nEpoch 176/300\n3/3 [==============================] - 1s 398ms/step - loss: 0.2241 - accuracy: 0.8986 - val_loss: 0.4995 - val_accuracy: 0.8049\nEpoch 177/300\n3/3 [==============================] - 1s 390ms/step - loss: 0.2889 - accuracy: 0.8916 - val_loss: 0.4950 - val_accuracy: 0.7805\nEpoch 178/300\n3/3 [==============================] - 1s 436ms/step - loss: 0.2683 - accuracy: 0.8916 - val_loss: 0.4928 - val_accuracy: 0.7886\nEpoch 179/300\n3/3 [==============================] - 1s 461ms/step - loss: 0.2810 - accuracy: 0.8706 - val_loss: 0.4617 - val_accuracy: 0.8130\nEpoch 180/300\n3/3 [==============================] - 1s 520ms/step - loss: 0.2704 - accuracy: 0.8986 - val_loss: 0.4443 - val_accuracy: 0.8374\nEpoch 181/300\n3/3 [==============================] - 1s 446ms/step - loss: 0.2603 - accuracy: 0.9091 - val_loss: 0.4478 - val_accuracy: 0.8293\nEpoch 182/300\n3/3 [==============================] - 1s 530ms/step - loss: 0.2681 - accuracy: 0.8916 - val_loss: 0.4621 - val_accuracy: 0.8211\nEpoch 183/300\n3/3 [==============================] - 1s 412ms/step - loss: 0.2688 - accuracy: 0.8951 - val_loss: 0.4890 - val_accuracy: 0.8130\nEpoch 184/300\n3/3 [==============================] - 1s 394ms/step - loss: 0.2921 - accuracy: 0.8846 - val_loss: 0.5269 - val_accuracy: 0.7886\nEpoch 185/300\n3/3 [==============================] - 1s 397ms/step - loss: 0.2512 - accuracy: 0.9091 - val_loss: 0.5543 - val_accuracy: 0.7724\nEpoch 186/300\n3/3 [==============================] - 1s 429ms/step - loss: 0.2656 - accuracy: 0.8951 - val_loss: 0.5136 - val_accuracy: 0.8130\nEpoch 187/300\n3/3 [==============================] - 1s 425ms/step - loss: 0.2525 - accuracy: 0.8986 - val_loss: 0.5546 - val_accuracy: 0.7886\nEpoch 188/300\n3/3 [==============================] - 1s 414ms/step - loss: 0.3246 - accuracy: 0.8706 - val_loss: 0.6214 - val_accuracy: 0.7480\nEpoch 189/300\n3/3 [==============================] - 1s 408ms/step - loss: 0.3488 - accuracy: 0.8601 - val_loss: 0.4962 - val_accuracy: 0.8130\nEpoch 190/300\n3/3 [==============================] - 2s 746ms/step - loss: 0.2534 - accuracy: 0.8846 - val_loss: 0.5047 - val_accuracy: 0.8618\nEpoch 191/300\n3/3 [==============================] - 2s 413ms/step - loss: 0.3162 - accuracy: 0.8566 - val_loss: 0.4909 - val_accuracy: 0.8374\nEpoch 192/300\n3/3 [==============================] - 1s 396ms/step - loss: 0.2657 - accuracy: 0.8881 - val_loss: 0.4711 - val_accuracy: 0.8293\nEpoch 193/300\n3/3 [==============================] - 1s 432ms/step - loss: 0.2715 - accuracy: 0.8916 - val_loss: 0.4692 - val_accuracy: 0.8211\nEpoch 194/300\n3/3 [==============================] - 1s 418ms/step - loss: 0.3002 - accuracy: 0.8706 - val_loss: 0.4874 - val_accuracy: 0.7886\nEpoch 195/300\n3/3 [==============================] - 1s 408ms/step - loss: 0.2713 - accuracy: 0.9091 - val_loss: 0.4647 - val_accuracy: 0.8293\nEpoch 196/300\n3/3 [==============================] - 1s 439ms/step - loss: 0.2760 - accuracy: 0.8951 - val_loss: 0.4932 - val_accuracy: 0.8049\nEpoch 197/300\n3/3 [==============================] - 1s 408ms/step - loss: 0.2488 - accuracy: 0.9056 - val_loss: 0.5249 - val_accuracy: 0.7967\nEpoch 198/300\n3/3 [==============================] - 1s 419ms/step - loss: 0.2697 - accuracy: 0.8951 - val_loss: 0.5572 - val_accuracy: 0.7805\nEpoch 199/300\n3/3 [==============================] - 2s 579ms/step - loss: 0.2638 - accuracy: 0.8846 - val_loss: 0.5731 - val_accuracy: 0.7724\nEpoch 200/300\n3/3 [==============================] - 1s 411ms/step - loss: 0.2893 - accuracy: 0.8811 - val_loss: 0.5628 - val_accuracy: 0.7805\nEpoch 201/300\n3/3 [==============================] - 1s 425ms/step - loss: 0.2537 - accuracy: 0.8951 - val_loss: 0.5109 - val_accuracy: 0.8130\nEpoch 202/300\n3/3 [==============================] - 1s 430ms/step - loss: 0.2441 - accuracy: 0.8881 - val_loss: 0.4972 - val_accuracy: 0.8699\nEpoch 203/300\n3/3 [==============================] - 1s 440ms/step - loss: 0.2326 - accuracy: 0.8986 - val_loss: 0.5045 - val_accuracy: 0.8455\nEpoch 204/300\n3/3 [==============================] - 1s 438ms/step - loss: 0.2301 - accuracy: 0.9021 - val_loss: 0.5280 - val_accuracy: 0.8049\nEpoch 205/300\n3/3 [==============================] - 1s 410ms/step - loss: 0.2831 - accuracy: 0.8881 - val_loss: 0.5632 - val_accuracy: 0.7724\nEpoch 206/300\n3/3 [==============================] - 1s 406ms/step - loss: 0.2503 - accuracy: 0.9021 - val_loss: 0.5632 - val_accuracy: 0.7724\nEpoch 207/300\n3/3 [==============================] - 1s 416ms/step - loss: 0.2425 - accuracy: 0.9021 - val_loss: 0.5574 - val_accuracy: 0.8618\nEpoch 208/300\n3/3 [==============================] - 2s 502ms/step - loss: 0.2879 - accuracy: 0.8951 - val_loss: 0.5429 - val_accuracy: 0.8455\nEpoch 209/300\n3/3 [==============================] - 1s 413ms/step - loss: 0.2236 - accuracy: 0.8951 - val_loss: 0.5718 - val_accuracy: 0.7724\nEpoch 210/300\n3/3 [==============================] - 1s 400ms/step - loss: 0.2940 - accuracy: 0.8951 - val_loss: 0.5758 - val_accuracy: 0.7480\nEpoch 211/300\n3/3 [==============================] - 1s 400ms/step - loss: 0.2663 - accuracy: 0.8916 - val_loss: 0.5171 - val_accuracy: 0.7886\nEpoch 212/300\n3/3 [==============================] - 1s 411ms/step - loss: 0.2588 - accuracy: 0.8986 - val_loss: 0.4910 - val_accuracy: 0.8211\nEpoch 213/300\n3/3 [==============================] - 1s 406ms/step - loss: 0.2757 - accuracy: 0.8811 - val_loss: 0.4766 - val_accuracy: 0.8537\nEpoch 214/300\n3/3 [==============================] - 1s 427ms/step - loss: 0.3112 - accuracy: 0.8916 - val_loss: 0.4616 - val_accuracy: 0.8537\nEpoch 215/300\n3/3 [==============================] - 2s 716ms/step - loss: 0.2838 - accuracy: 0.8846 - val_loss: 0.4686 - val_accuracy: 0.8211\nEpoch 216/300\n3/3 [==============================] - 2s 652ms/step - loss: 0.2759 - accuracy: 0.8916 - val_loss: 0.4625 - val_accuracy: 0.8130\nEpoch 217/300\n3/3 [==============================] - 1s 421ms/step - loss: 0.2773 - accuracy: 0.9021 - val_loss: 0.4481 - val_accuracy: 0.8455\nEpoch 218/300\n3/3 [==============================] - 1s 390ms/step - loss: 0.2327 - accuracy: 0.8881 - val_loss: 0.4661 - val_accuracy: 0.8374\nEpoch 219/300\n3/3 [==============================] - 1s 415ms/step - loss: 0.2420 - accuracy: 0.8986 - val_loss: 0.5295 - val_accuracy: 0.8049\nEpoch 220/300\n3/3 [==============================] - 1s 415ms/step - loss: 0.2249 - accuracy: 0.9126 - val_loss: 0.5814 - val_accuracy: 0.7967\nEpoch 221/300\n3/3 [==============================] - 1s 408ms/step - loss: 0.2650 - accuracy: 0.9126 - val_loss: 0.5947 - val_accuracy: 0.7805\nEpoch 222/300\n3/3 [==============================] - 1s 406ms/step - loss: 0.2169 - accuracy: 0.9091 - val_loss: 0.5769 - val_accuracy: 0.7886\nEpoch 223/300\n3/3 [==============================] - 1s 402ms/step - loss: 0.2466 - accuracy: 0.9056 - val_loss: 0.5462 - val_accuracy: 0.8130\nEpoch 224/300\n3/3 [==============================] - 1s 436ms/step - loss: 0.2573 - accuracy: 0.9021 - val_loss: 0.5260 - val_accuracy: 0.8293\nEpoch 225/300\n3/3 [==============================] - 2s 426ms/step - loss: 0.1978 - accuracy: 0.9161 - val_loss: 0.5394 - val_accuracy: 0.7967\nEpoch 226/300\n3/3 [==============================] - 1s 396ms/step - loss: 0.2189 - accuracy: 0.9056 - val_loss: 0.5599 - val_accuracy: 0.7886\nEpoch 227/300\n3/3 [==============================] - 1s 401ms/step - loss: 0.2452 - accuracy: 0.8916 - val_loss: 0.5482 - val_accuracy: 0.7886\nEpoch 228/300\n3/3 [==============================] - 1s 413ms/step - loss: 0.2208 - accuracy: 0.9161 - val_loss: 0.5122 - val_accuracy: 0.8130\nEpoch 229/300\n3/3 [==============================] - 1s 401ms/step - loss: 0.2210 - accuracy: 0.9021 - val_loss: 0.4906 - val_accuracy: 0.8537\nEpoch 230/300\n3/3 [==============================] - 1s 408ms/step - loss: 0.2822 - accuracy: 0.8741 - val_loss: 0.4788 - val_accuracy: 0.8455\nEpoch 231/300\n3/3 [==============================] - 1s 433ms/step - loss: 0.2674 - accuracy: 0.8741 - val_loss: 0.5165 - val_accuracy: 0.7724\nEpoch 232/300\n3/3 [==============================] - 1s 417ms/step - loss: 0.2282 - accuracy: 0.8951 - val_loss: 0.5262 - val_accuracy: 0.7967\nEpoch 233/300\n3/3 [==============================] - 2s 629ms/step - loss: 0.2518 - accuracy: 0.8986 - val_loss: 0.5347 - val_accuracy: 0.8374\nEpoch 234/300\n3/3 [==============================] - 1s 415ms/step - loss: 0.2779 - accuracy: 0.8881 - val_loss: 0.5136 - val_accuracy: 0.8293\nEpoch 235/300\n3/3 [==============================] - 1s 455ms/step - loss: 0.2366 - accuracy: 0.8951 - val_loss: 0.4968 - val_accuracy: 0.8293\nEpoch 236/300\n3/3 [==============================] - 1s 411ms/step - loss: 0.2269 - accuracy: 0.9161 - val_loss: 0.5035 - val_accuracy: 0.7805\nEpoch 237/300\n3/3 [==============================] - 1s 429ms/step - loss: 0.2250 - accuracy: 0.9091 - val_loss: 0.5135 - val_accuracy: 0.7967\nEpoch 238/300\n3/3 [==============================] - 1s 418ms/step - loss: 0.2373 - accuracy: 0.8846 - val_loss: 0.5381 - val_accuracy: 0.8293\nEpoch 239/300\n3/3 [==============================] - 1s 466ms/step - loss: 0.2238 - accuracy: 0.9231 - val_loss: 0.5879 - val_accuracy: 0.8049\nEpoch 240/300\n3/3 [==============================] - 2s 644ms/step - loss: 0.2562 - accuracy: 0.8986 - val_loss: 0.6926 - val_accuracy: 0.7154\nEpoch 241/300\n3/3 [==============================] - 2s 639ms/step - loss: 0.2528 - accuracy: 0.8846 - val_loss: 0.6060 - val_accuracy: 0.7886\nEpoch 242/300\n3/3 [==============================] - 1s 414ms/step - loss: 0.2433 - accuracy: 0.8951 - val_loss: 0.5447 - val_accuracy: 0.8374\nEpoch 243/300\n3/3 [==============================] - 1s 414ms/step - loss: 0.2578 - accuracy: 0.8881 - val_loss: 0.4954 - val_accuracy: 0.8537\nEpoch 244/300\n3/3 [==============================] - 1s 398ms/step - loss: 0.2607 - accuracy: 0.8951 - val_loss: 0.4927 - val_accuracy: 0.7967\nEpoch 245/300\n3/3 [==============================] - 1s 417ms/step - loss: 0.2577 - accuracy: 0.8951 - val_loss: 0.5009 - val_accuracy: 0.7642\nEpoch 246/300\n3/3 [==============================] - 1s 426ms/step - loss: 0.2251 - accuracy: 0.9126 - val_loss: 0.4971 - val_accuracy: 0.8049\nEpoch 247/300\n3/3 [==============================] - 1s 433ms/step - loss: 0.2271 - accuracy: 0.9266 - val_loss: 0.5187 - val_accuracy: 0.8130\nEpoch 248/300\n3/3 [==============================] - 1s 489ms/step - loss: 0.2313 - accuracy: 0.9056 - val_loss: 0.5409 - val_accuracy: 0.8211\nEpoch 249/300\n3/3 [==============================] - 2s 670ms/step - loss: 0.2206 - accuracy: 0.9056 - val_loss: 0.5727 - val_accuracy: 0.7967\nEpoch 250/300\n3/3 [==============================] - 1s 433ms/step - loss: 0.2135 - accuracy: 0.9161 - val_loss: 0.5710 - val_accuracy: 0.7886\nEpoch 251/300\n3/3 [==============================] - 1s 398ms/step - loss: 0.2009 - accuracy: 0.9336 - val_loss: 0.5802 - val_accuracy: 0.7967\nEpoch 252/300\n3/3 [==============================] - 1s 396ms/step - loss: 0.1624 - accuracy: 0.9441 - val_loss: 0.6050 - val_accuracy: 0.8374\nEpoch 253/300\n3/3 [==============================] - 1s 421ms/step - loss: 0.2407 - accuracy: 0.9021 - val_loss: 0.6112 - val_accuracy: 0.8455\nEpoch 254/300\n3/3 [==============================] - 1s 413ms/step - loss: 0.3256 - accuracy: 0.8811 - val_loss: 0.5502 - val_accuracy: 0.8211\nEpoch 255/300\n3/3 [==============================] - 1s 429ms/step - loss: 0.2244 - accuracy: 0.9091 - val_loss: 0.5274 - val_accuracy: 0.8293\nEpoch 256/300\n3/3 [==============================] - 1s 440ms/step - loss: 0.2490 - accuracy: 0.8811 - val_loss: 0.4899 - val_accuracy: 0.8374\nEpoch 257/300\n3/3 [==============================] - 1s 406ms/step - loss: 0.2869 - accuracy: 0.8776 - val_loss: 0.4854 - val_accuracy: 0.7805\nEpoch 258/300\n3/3 [==============================] - 2s 542ms/step - loss: 0.2614 - accuracy: 0.9021 - val_loss: 0.4546 - val_accuracy: 0.8537\nEpoch 259/300\n3/3 [==============================] - 1s 409ms/step - loss: 0.2454 - accuracy: 0.9091 - val_loss: 0.4465 - val_accuracy: 0.8537\nEpoch 260/300\n3/3 [==============================] - 1s 425ms/step - loss: 0.2444 - accuracy: 0.8986 - val_loss: 0.5084 - val_accuracy: 0.7886\nEpoch 261/300\n3/3 [==============================] - 1s 403ms/step - loss: 0.2748 - accuracy: 0.8881 - val_loss: 0.5050 - val_accuracy: 0.7886\nEpoch 262/300\n3/3 [==============================] - 1s 429ms/step - loss: 0.2767 - accuracy: 0.8881 - val_loss: 0.4386 - val_accuracy: 0.8618\nEpoch 263/300\n3/3 [==============================] - 1s 423ms/step - loss: 0.2377 - accuracy: 0.8986 - val_loss: 0.4359 - val_accuracy: 0.8699\nEpoch 264/300\n3/3 [==============================] - 1s 419ms/step - loss: 0.2530 - accuracy: 0.9021 - val_loss: 0.4508 - val_accuracy: 0.8537\nEpoch 265/300\n3/3 [==============================] - 2s 559ms/step - loss: 0.2809 - accuracy: 0.8776 - val_loss: 0.4728 - val_accuracy: 0.8293\nEpoch 266/300\n3/3 [==============================] - 2s 621ms/step - loss: 0.2698 - accuracy: 0.8881 - val_loss: 0.4828 - val_accuracy: 0.8293\nEpoch 267/300\n3/3 [==============================] - 1s 422ms/step - loss: 0.2251 - accuracy: 0.9056 - val_loss: 0.4839 - val_accuracy: 0.8374\nEpoch 268/300\n3/3 [==============================] - 1s 420ms/step - loss: 0.2404 - accuracy: 0.8986 - val_loss: 0.4845 - val_accuracy: 0.8374\nEpoch 269/300\n3/3 [==============================] - 1s 420ms/step - loss: 0.2989 - accuracy: 0.8846 - val_loss: 0.4855 - val_accuracy: 0.8211\nEpoch 270/300\n3/3 [==============================] - 1s 408ms/step - loss: 0.2354 - accuracy: 0.9021 - val_loss: 0.4891 - val_accuracy: 0.8293\nEpoch 271/300\n3/3 [==============================] - 1s 443ms/step - loss: 0.2669 - accuracy: 0.8881 - val_loss: 0.4847 - val_accuracy: 0.8293\nEpoch 272/300\n3/3 [==============================] - 1s 433ms/step - loss: 0.2180 - accuracy: 0.9301 - val_loss: 0.4858 - val_accuracy: 0.8049\nEpoch 273/300\n3/3 [==============================] - 1s 458ms/step - loss: 0.2291 - accuracy: 0.9056 - val_loss: 0.4960 - val_accuracy: 0.8049\nEpoch 274/300\n3/3 [==============================] - 2s 589ms/step - loss: 0.2584 - accuracy: 0.8776 - val_loss: 0.4898 - val_accuracy: 0.8293\nEpoch 275/300\n3/3 [==============================] - 1s 427ms/step - loss: 0.2318 - accuracy: 0.8951 - val_loss: 0.4906 - val_accuracy: 0.8211\nEpoch 276/300\n3/3 [==============================] - 1s 418ms/step - loss: 0.2081 - accuracy: 0.9196 - val_loss: 0.5066 - val_accuracy: 0.8211\nEpoch 277/300\n3/3 [==============================] - 1s 414ms/step - loss: 0.2329 - accuracy: 0.9196 - val_loss: 0.5256 - val_accuracy: 0.8049\nEpoch 278/300\n3/3 [==============================] - 1s 409ms/step - loss: 0.2675 - accuracy: 0.8636 - val_loss: 0.5449 - val_accuracy: 0.8049\nEpoch 279/300\n3/3 [==============================] - 1s 423ms/step - loss: 0.2208 - accuracy: 0.9056 - val_loss: 0.5718 - val_accuracy: 0.8374\nEpoch 280/300\n3/3 [==============================] - 1s 410ms/step - loss: 0.2323 - accuracy: 0.9126 - val_loss: 0.5593 - val_accuracy: 0.8211\nEpoch 281/300\n3/3 [==============================] - 1s 413ms/step - loss: 0.2152 - accuracy: 0.9161 - val_loss: 0.5513 - val_accuracy: 0.7967\nEpoch 282/300\n3/3 [==============================] - 1s 409ms/step - loss: 0.1812 - accuracy: 0.9161 - val_loss: 0.5835 - val_accuracy: 0.7724\nEpoch 283/300\n3/3 [==============================] - 2s 609ms/step - loss: 0.2365 - accuracy: 0.8916 - val_loss: 0.5881 - val_accuracy: 0.8130\nEpoch 284/300\n3/3 [==============================] - 1s 413ms/step - loss: 0.2283 - accuracy: 0.9126 - val_loss: 0.5711 - val_accuracy: 0.8374\nEpoch 285/300\n3/3 [==============================] - 1s 417ms/step - loss: 0.2301 - accuracy: 0.9161 - val_loss: 0.5160 - val_accuracy: 0.8293\nEpoch 286/300\n3/3 [==============================] - 1s 413ms/step - loss: 0.2395 - accuracy: 0.8951 - val_loss: 0.5085 - val_accuracy: 0.7967\nEpoch 287/300\n3/3 [==============================] - 1s 407ms/step - loss: 0.2445 - accuracy: 0.8986 - val_loss: 0.4938 - val_accuracy: 0.8130\nEpoch 288/300\n3/3 [==============================] - 1s 420ms/step - loss: 0.2492 - accuracy: 0.9161 - val_loss: 0.5018 - val_accuracy: 0.8211\nEpoch 289/300\n3/3 [==============================] - 1s 395ms/step - loss: 0.2085 - accuracy: 0.9196 - val_loss: 0.5540 - val_accuracy: 0.7724\nEpoch 290/300\n3/3 [==============================] - 1s 507ms/step - loss: 0.2460 - accuracy: 0.9056 - val_loss: 0.5449 - val_accuracy: 0.7805\nEpoch 291/300\n3/3 [==============================] - 2s 639ms/step - loss: 0.2135 - accuracy: 0.9161 - val_loss: 0.5174 - val_accuracy: 0.8455\nEpoch 292/300\n3/3 [==============================] - 1s 403ms/step - loss: 0.2173 - accuracy: 0.9056 - val_loss: 0.5163 - val_accuracy: 0.8537\nEpoch 293/300\n3/3 [==============================] - 1s 422ms/step - loss: 0.2237 - accuracy: 0.9091 - val_loss: 0.5189 - val_accuracy: 0.8455\nEpoch 294/300\n3/3 [==============================] - 1s 421ms/step - loss: 0.2253 - accuracy: 0.8916 - val_loss: 0.5441 - val_accuracy: 0.7805\nEpoch 295/300\n3/3 [==============================] - 1s 411ms/step - loss: 0.1925 - accuracy: 0.9371 - val_loss: 0.5955 - val_accuracy: 0.7317\nEpoch 296/300\n3/3 [==============================] - 1s 407ms/step - loss: 0.2697 - accuracy: 0.8671 - val_loss: 0.5665 - val_accuracy: 0.7480\nEpoch 297/300\n3/3 [==============================] - 1s 457ms/step - loss: 0.2070 - accuracy: 0.8986 - val_loss: 0.5480 - val_accuracy: 0.7886\nEpoch 298/300\n3/3 [==============================] - 1s 408ms/step - loss: 0.2121 - accuracy: 0.9021 - val_loss: 0.5623 - val_accuracy: 0.7886\nEpoch 299/300\n3/3 [==============================] - 1s 519ms/step - loss: 0.2536 - accuracy: 0.8986 - val_loss: 0.5620 - val_accuracy: 0.7886\nEpoch 300/300\n3/3 [==============================] - 1s 412ms/step - loss: 0.2041 - accuracy: 0.9056 - val_loss: 0.5289 - val_accuracy: 0.8211\n","output_type":"stream"}]},{"cell_type":"code","source":"pred=(model.predict(X_unl) > 0.5).astype(\"int32\")","metadata":{"execution":{"iopub.status.busy":"2022-04-06T12:50:41.935895Z","iopub.execute_input":"2022-04-06T12:50:41.936149Z","iopub.status.idle":"2022-04-06T12:50:48.127388Z","shell.execute_reply.started":"2022-04-06T12:50:41.936115Z","shell.execute_reply":"2022-04-06T12:50:48.126611Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"X_train=np.concatenate((X_lvl,X_unl))\npred2=pred.flatten()\ny_unl = pd.Series(pred2)\ny_train=np.concatenate((y_lvl,y_unl))","metadata":{"execution":{"iopub.status.busy":"2022-04-06T12:50:48.134050Z","iopub.execute_input":"2022-04-06T12:50:48.134266Z","iopub.status.idle":"2022-04-06T12:50:48.140689Z","shell.execute_reply.started":"2022-04-06T12:50:48.134241Z","shell.execute_reply":"2022-04-06T12:50:48.139799Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"model=build_model()","metadata":{"execution":{"iopub.status.busy":"2022-04-06T12:50:48.142000Z","iopub.execute_input":"2022-04-06T12:50:48.142445Z","iopub.status.idle":"2022-04-06T12:50:48.380021Z","shell.execute_reply.started":"2022-04-06T12:50:48.142405Z","shell.execute_reply":"2022-04-06T12:50:48.379298Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_train, y_train, validation_split=0.3, epochs=100, batch_size=batch_size, shuffle=True, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T12:50:48.381122Z","iopub.execute_input":"2022-04-06T12:50:48.381351Z","iopub.status.idle":"2022-04-06T13:23:25.142980Z","shell.execute_reply.started":"2022-04-06T12:50:48.381318Z","shell.execute_reply":"2022-04-06T13:23:25.142241Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Epoch 1/100\n45/45 [==============================] - 24s 439ms/step - loss: 0.2692 - accuracy: 0.9330 - val_loss: 0.1867 - val_accuracy: 0.9557\nEpoch 2/100\n45/45 [==============================] - 19s 427ms/step - loss: 0.2175 - accuracy: 0.9438 - val_loss: 0.1821 - val_accuracy: 0.9557\nEpoch 3/100\n45/45 [==============================] - 20s 444ms/step - loss: 0.2165 - accuracy: 0.9438 - val_loss: 0.1814 - val_accuracy: 0.9557\nEpoch 4/100\n45/45 [==============================] - 20s 443ms/step - loss: 0.2154 - accuracy: 0.9438 - val_loss: 0.1807 - val_accuracy: 0.9557\nEpoch 5/100\n45/45 [==============================] - 19s 423ms/step - loss: 0.2155 - accuracy: 0.9438 - val_loss: 0.1771 - val_accuracy: 0.9557\nEpoch 6/100\n45/45 [==============================] - 20s 435ms/step - loss: 0.2108 - accuracy: 0.9437 - val_loss: 0.1749 - val_accuracy: 0.9557\nEpoch 7/100\n45/45 [==============================] - 20s 434ms/step - loss: 0.2064 - accuracy: 0.9438 - val_loss: 0.1777 - val_accuracy: 0.9557\nEpoch 8/100\n45/45 [==============================] - 21s 466ms/step - loss: 0.2018 - accuracy: 0.9438 - val_loss: 0.1675 - val_accuracy: 0.9557\nEpoch 9/100\n45/45 [==============================] - 20s 451ms/step - loss: 0.2021 - accuracy: 0.9438 - val_loss: 0.1660 - val_accuracy: 0.9557\nEpoch 10/100\n45/45 [==============================] - 20s 439ms/step - loss: 0.1998 - accuracy: 0.9438 - val_loss: 0.1673 - val_accuracy: 0.9557\nEpoch 11/100\n45/45 [==============================] - 20s 455ms/step - loss: 0.1987 - accuracy: 0.9438 - val_loss: 0.1664 - val_accuracy: 0.9557\nEpoch 12/100\n45/45 [==============================] - 20s 438ms/step - loss: 0.1994 - accuracy: 0.9438 - val_loss: 0.1655 - val_accuracy: 0.9557\nEpoch 13/100\n45/45 [==============================] - 20s 446ms/step - loss: 0.1968 - accuracy: 0.9438 - val_loss: 0.1594 - val_accuracy: 0.9557\nEpoch 14/100\n45/45 [==============================] - 20s 456ms/step - loss: 0.1965 - accuracy: 0.9438 - val_loss: 0.1586 - val_accuracy: 0.9557\nEpoch 15/100\n45/45 [==============================] - 20s 437ms/step - loss: 0.1928 - accuracy: 0.9438 - val_loss: 0.1567 - val_accuracy: 0.9557\nEpoch 16/100\n45/45 [==============================] - 20s 439ms/step - loss: 0.1930 - accuracy: 0.9438 - val_loss: 0.1607 - val_accuracy: 0.9557\nEpoch 17/100\n45/45 [==============================] - 19s 418ms/step - loss: 0.1942 - accuracy: 0.9438 - val_loss: 0.1644 - val_accuracy: 0.9557\nEpoch 18/100\n45/45 [==============================] - 20s 447ms/step - loss: 0.1942 - accuracy: 0.9440 - val_loss: 0.1544 - val_accuracy: 0.9557\nEpoch 19/100\n45/45 [==============================] - 20s 443ms/step - loss: 0.1867 - accuracy: 0.9440 - val_loss: 0.1545 - val_accuracy: 0.9557\nEpoch 20/100\n45/45 [==============================] - 19s 420ms/step - loss: 0.1890 - accuracy: 0.9438 - val_loss: 0.1522 - val_accuracy: 0.9557\nEpoch 21/100\n45/45 [==============================] - 20s 435ms/step - loss: 0.1854 - accuracy: 0.9435 - val_loss: 0.1486 - val_accuracy: 0.9557\nEpoch 22/100\n45/45 [==============================] - 20s 436ms/step - loss: 0.1857 - accuracy: 0.9438 - val_loss: 0.1479 - val_accuracy: 0.9557\nEpoch 23/100\n45/45 [==============================] - 20s 444ms/step - loss: 0.1812 - accuracy: 0.9444 - val_loss: 0.1540 - val_accuracy: 0.9557\nEpoch 24/100\n45/45 [==============================] - 20s 445ms/step - loss: 0.1819 - accuracy: 0.9437 - val_loss: 0.1474 - val_accuracy: 0.9557\nEpoch 25/100\n45/45 [==============================] - 20s 434ms/step - loss: 0.1808 - accuracy: 0.9437 - val_loss: 0.1449 - val_accuracy: 0.9557\nEpoch 26/100\n45/45 [==============================] - 20s 439ms/step - loss: 0.1799 - accuracy: 0.9438 - val_loss: 0.1505 - val_accuracy: 0.9557\nEpoch 27/100\n45/45 [==============================] - 20s 449ms/step - loss: 0.1833 - accuracy: 0.9445 - val_loss: 0.1442 - val_accuracy: 0.9557\nEpoch 28/100\n45/45 [==============================] - 19s 433ms/step - loss: 0.1802 - accuracy: 0.9445 - val_loss: 0.1480 - val_accuracy: 0.9561\nEpoch 29/100\n45/45 [==============================] - 20s 438ms/step - loss: 0.1790 - accuracy: 0.9444 - val_loss: 0.1437 - val_accuracy: 0.9561\nEpoch 30/100\n45/45 [==============================] - 19s 412ms/step - loss: 0.1820 - accuracy: 0.9430 - val_loss: 0.1468 - val_accuracy: 0.9561\nEpoch 31/100\n45/45 [==============================] - 20s 433ms/step - loss: 0.1809 - accuracy: 0.9442 - val_loss: 0.1499 - val_accuracy: 0.9573\nEpoch 32/100\n45/45 [==============================] - 20s 438ms/step - loss: 0.1800 - accuracy: 0.9451 - val_loss: 0.1446 - val_accuracy: 0.9557\nEpoch 33/100\n45/45 [==============================] - 19s 427ms/step - loss: 0.1791 - accuracy: 0.9447 - val_loss: 0.1452 - val_accuracy: 0.9557\nEpoch 34/100\n45/45 [==============================] - 19s 432ms/step - loss: 0.1799 - accuracy: 0.9456 - val_loss: 0.1434 - val_accuracy: 0.9557\nEpoch 35/100\n45/45 [==============================] - 19s 424ms/step - loss: 0.1779 - accuracy: 0.9438 - val_loss: 0.1405 - val_accuracy: 0.9561\nEpoch 36/100\n45/45 [==============================] - 20s 452ms/step - loss: 0.1761 - accuracy: 0.9440 - val_loss: 0.1383 - val_accuracy: 0.9561\nEpoch 37/100\n45/45 [==============================] - 20s 440ms/step - loss: 0.1726 - accuracy: 0.9444 - val_loss: 0.1408 - val_accuracy: 0.9565\nEpoch 38/100\n45/45 [==============================] - 19s 428ms/step - loss: 0.1760 - accuracy: 0.9447 - val_loss: 0.1429 - val_accuracy: 0.9565\nEpoch 39/100\n45/45 [==============================] - 19s 426ms/step - loss: 0.1722 - accuracy: 0.9458 - val_loss: 0.1397 - val_accuracy: 0.9561\nEpoch 40/100\n45/45 [==============================] - 19s 419ms/step - loss: 0.1751 - accuracy: 0.9442 - val_loss: 0.1468 - val_accuracy: 0.9569\nEpoch 41/100\n45/45 [==============================] - 20s 441ms/step - loss: 0.1776 - accuracy: 0.9431 - val_loss: 0.1406 - val_accuracy: 0.9561\nEpoch 42/100\n45/45 [==============================] - 20s 442ms/step - loss: 0.1739 - accuracy: 0.9437 - val_loss: 0.1400 - val_accuracy: 0.9561\nEpoch 43/100\n45/45 [==============================] - 19s 420ms/step - loss: 0.1750 - accuracy: 0.9449 - val_loss: 0.1437 - val_accuracy: 0.9557\nEpoch 44/100\n45/45 [==============================] - 20s 447ms/step - loss: 0.1715 - accuracy: 0.9438 - val_loss: 0.1408 - val_accuracy: 0.9557\nEpoch 45/100\n45/45 [==============================] - 19s 420ms/step - loss: 0.1759 - accuracy: 0.9449 - val_loss: 0.1437 - val_accuracy: 0.9557\nEpoch 46/100\n45/45 [==============================] - 20s 439ms/step - loss: 0.1741 - accuracy: 0.9444 - val_loss: 0.1483 - val_accuracy: 0.9573\nEpoch 47/100\n45/45 [==============================] - 20s 438ms/step - loss: 0.1718 - accuracy: 0.9445 - val_loss: 0.1410 - val_accuracy: 0.9561\nEpoch 48/100\n45/45 [==============================] - 19s 417ms/step - loss: 0.1741 - accuracy: 0.9433 - val_loss: 0.1448 - val_accuracy: 0.9557\nEpoch 49/100\n45/45 [==============================] - 20s 437ms/step - loss: 0.1734 - accuracy: 0.9433 - val_loss: 0.1389 - val_accuracy: 0.9561\nEpoch 50/100\n45/45 [==============================] - 19s 427ms/step - loss: 0.1712 - accuracy: 0.9442 - val_loss: 0.1403 - val_accuracy: 0.9561\nEpoch 51/100\n45/45 [==============================] - 20s 443ms/step - loss: 0.1684 - accuracy: 0.9442 - val_loss: 0.1397 - val_accuracy: 0.9561\nEpoch 52/100\n45/45 [==============================] - 19s 428ms/step - loss: 0.1707 - accuracy: 0.9449 - val_loss: 0.1404 - val_accuracy: 0.9561\nEpoch 53/100\n45/45 [==============================] - 19s 421ms/step - loss: 0.1703 - accuracy: 0.9449 - val_loss: 0.1401 - val_accuracy: 0.9561\nEpoch 54/100\n45/45 [==============================] - 20s 441ms/step - loss: 0.1680 - accuracy: 0.9445 - val_loss: 0.1379 - val_accuracy: 0.9561\nEpoch 55/100\n45/45 [==============================] - 19s 433ms/step - loss: 0.1674 - accuracy: 0.9447 - val_loss: 0.1446 - val_accuracy: 0.9557\nEpoch 56/100\n45/45 [==============================] - 20s 434ms/step - loss: 0.1631 - accuracy: 0.9452 - val_loss: 0.1370 - val_accuracy: 0.9561\nEpoch 57/100\n45/45 [==============================] - 19s 429ms/step - loss: 0.1656 - accuracy: 0.9449 - val_loss: 0.1391 - val_accuracy: 0.9561\nEpoch 58/100\n45/45 [==============================] - 19s 430ms/step - loss: 0.1689 - accuracy: 0.9442 - val_loss: 0.1388 - val_accuracy: 0.9561\nEpoch 59/100\n45/45 [==============================] - 20s 443ms/step - loss: 0.1633 - accuracy: 0.9452 - val_loss: 0.1376 - val_accuracy: 0.9561\nEpoch 60/100\n45/45 [==============================] - 19s 421ms/step - loss: 0.1696 - accuracy: 0.9451 - val_loss: 0.1377 - val_accuracy: 0.9561\nEpoch 61/100\n45/45 [==============================] - 20s 438ms/step - loss: 0.1656 - accuracy: 0.9449 - val_loss: 0.1374 - val_accuracy: 0.9565\nEpoch 62/100\n45/45 [==============================] - 19s 433ms/step - loss: 0.1671 - accuracy: 0.9428 - val_loss: 0.1381 - val_accuracy: 0.9561\nEpoch 63/100\n45/45 [==============================] - 19s 424ms/step - loss: 0.1663 - accuracy: 0.9442 - val_loss: 0.1402 - val_accuracy: 0.9561\nEpoch 64/100\n45/45 [==============================] - 20s 444ms/step - loss: 0.1648 - accuracy: 0.9449 - val_loss: 0.1407 - val_accuracy: 0.9561\nEpoch 65/100\n45/45 [==============================] - 18s 410ms/step - loss: 0.1640 - accuracy: 0.9449 - val_loss: 0.1361 - val_accuracy: 0.9565\nEpoch 66/100\n45/45 [==============================] - 20s 438ms/step - loss: 0.1675 - accuracy: 0.9452 - val_loss: 0.1469 - val_accuracy: 0.9540\nEpoch 67/100\n45/45 [==============================] - 19s 420ms/step - loss: 0.1640 - accuracy: 0.9452 - val_loss: 0.1376 - val_accuracy: 0.9565\nEpoch 68/100\n45/45 [==============================] - 20s 449ms/step - loss: 0.1615 - accuracy: 0.9456 - val_loss: 0.1395 - val_accuracy: 0.9561\nEpoch 69/100\n45/45 [==============================] - 19s 425ms/step - loss: 0.1644 - accuracy: 0.9456 - val_loss: 0.1413 - val_accuracy: 0.9561\nEpoch 70/100\n45/45 [==============================] - 19s 429ms/step - loss: 0.1591 - accuracy: 0.9447 - val_loss: 0.1372 - val_accuracy: 0.9561\nEpoch 71/100\n45/45 [==============================] - 20s 444ms/step - loss: 0.1620 - accuracy: 0.9454 - val_loss: 0.1377 - val_accuracy: 0.9565\nEpoch 72/100\n45/45 [==============================] - 19s 424ms/step - loss: 0.1618 - accuracy: 0.9433 - val_loss: 0.1361 - val_accuracy: 0.9577\nEpoch 73/100\n45/45 [==============================] - 19s 430ms/step - loss: 0.1585 - accuracy: 0.9466 - val_loss: 0.1416 - val_accuracy: 0.9561\nEpoch 74/100\n45/45 [==============================] - 20s 439ms/step - loss: 0.1606 - accuracy: 0.9459 - val_loss: 0.1412 - val_accuracy: 0.9561\nEpoch 75/100\n45/45 [==============================] - 19s 431ms/step - loss: 0.1642 - accuracy: 0.9461 - val_loss: 0.1446 - val_accuracy: 0.9561\nEpoch 76/100\n45/45 [==============================] - 20s 446ms/step - loss: 0.1616 - accuracy: 0.9452 - val_loss: 0.1431 - val_accuracy: 0.9552\nEpoch 77/100\n45/45 [==============================] - 19s 416ms/step - loss: 0.1523 - accuracy: 0.9461 - val_loss: 0.1359 - val_accuracy: 0.9581\nEpoch 78/100\n45/45 [==============================] - 19s 430ms/step - loss: 0.1606 - accuracy: 0.9478 - val_loss: 0.1373 - val_accuracy: 0.9585\nEpoch 79/100\n45/45 [==============================] - 20s 440ms/step - loss: 0.1621 - accuracy: 0.9461 - val_loss: 0.1381 - val_accuracy: 0.9561\nEpoch 80/100\n45/45 [==============================] - 19s 429ms/step - loss: 0.1604 - accuracy: 0.9449 - val_loss: 0.1368 - val_accuracy: 0.9573\nEpoch 81/100\n45/45 [==============================] - 20s 447ms/step - loss: 0.1599 - accuracy: 0.9452 - val_loss: 0.1387 - val_accuracy: 0.9561\nEpoch 82/100\n45/45 [==============================] - 19s 415ms/step - loss: 0.1609 - accuracy: 0.9452 - val_loss: 0.1415 - val_accuracy: 0.9561\nEpoch 83/100\n45/45 [==============================] - 20s 447ms/step - loss: 0.1547 - accuracy: 0.9465 - val_loss: 0.1389 - val_accuracy: 0.9561\nEpoch 84/100\n45/45 [==============================] - 19s 428ms/step - loss: 0.1535 - accuracy: 0.9478 - val_loss: 0.1385 - val_accuracy: 0.9561\nEpoch 85/100\n45/45 [==============================] - 20s 446ms/step - loss: 0.1582 - accuracy: 0.9456 - val_loss: 0.1385 - val_accuracy: 0.9561\nEpoch 86/100\n45/45 [==============================] - 20s 435ms/step - loss: 0.1551 - accuracy: 0.9466 - val_loss: 0.1454 - val_accuracy: 0.9557\nEpoch 87/100\n45/45 [==============================] - 19s 425ms/step - loss: 0.1607 - accuracy: 0.9440 - val_loss: 0.1380 - val_accuracy: 0.9569\nEpoch 88/100\n45/45 [==============================] - 20s 440ms/step - loss: 0.1566 - accuracy: 0.9477 - val_loss: 0.1396 - val_accuracy: 0.9573\nEpoch 89/100\n45/45 [==============================] - 19s 433ms/step - loss: 0.1579 - accuracy: 0.9475 - val_loss: 0.1393 - val_accuracy: 0.9581\nEpoch 90/100\n45/45 [==============================] - 20s 438ms/step - loss: 0.1489 - accuracy: 0.9478 - val_loss: 0.1438 - val_accuracy: 0.9561\nEpoch 91/100\n45/45 [==============================] - 19s 431ms/step - loss: 0.1549 - accuracy: 0.9452 - val_loss: 0.1406 - val_accuracy: 0.9593\nEpoch 92/100\n45/45 [==============================] - 19s 420ms/step - loss: 0.1544 - accuracy: 0.9459 - val_loss: 0.1361 - val_accuracy: 0.9577\nEpoch 93/100\n45/45 [==============================] - 20s 435ms/step - loss: 0.1596 - accuracy: 0.9447 - val_loss: 0.1389 - val_accuracy: 0.9565\nEpoch 94/100\n45/45 [==============================] - 19s 430ms/step - loss: 0.1539 - accuracy: 0.9473 - val_loss: 0.1402 - val_accuracy: 0.9569\nEpoch 95/100\n45/45 [==============================] - 19s 427ms/step - loss: 0.1518 - accuracy: 0.9465 - val_loss: 0.1393 - val_accuracy: 0.9581\nEpoch 96/100\n45/45 [==============================] - 19s 415ms/step - loss: 0.1580 - accuracy: 0.9466 - val_loss: 0.1371 - val_accuracy: 0.9565\nEpoch 97/100\n45/45 [==============================] - 20s 439ms/step - loss: 0.1537 - accuracy: 0.9465 - val_loss: 0.1377 - val_accuracy: 0.9585\nEpoch 98/100\n45/45 [==============================] - 20s 435ms/step - loss: 0.1528 - accuracy: 0.9456 - val_loss: 0.1391 - val_accuracy: 0.9593\nEpoch 99/100\n45/45 [==============================] - 18s 407ms/step - loss: 0.1500 - accuracy: 0.9447 - val_loss: 0.1440 - val_accuracy: 0.9561\nEpoch 100/100\n45/45 [==============================] - 20s 439ms/step - loss: 0.1548 - accuracy: 0.9475 - val_loss: 0.1405 - val_accuracy: 0.9569\n","output_type":"stream"}]},{"cell_type":"code","source":"test_res=(model.predict(X_test) > 0.5).astype(\"int32\")\ntest_res=test_res.flatten()\ny_test_c = y_test.to_numpy()","metadata":{"execution":{"iopub.status.busy":"2022-04-06T13:23:25.146278Z","iopub.execute_input":"2022-04-06T13:23:25.146476Z","iopub.status.idle":"2022-04-06T13:23:27.149455Z","shell.execute_reply.started":"2022-04-06T13:23:25.146452Z","shell.execute_reply":"2022-04-06T13:23:27.148759Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"count=0\nfor i in range(0,len(y_test_c)):\n  if(y_test_c[i]==test_res[i]):\n    count=count+1\nprint(count)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T13:23:27.150794Z","iopub.execute_input":"2022-04-06T13:23:27.151087Z","iopub.status.idle":"2022-04-06T13:23:27.158111Z","shell.execute_reply.started":"2022-04-06T13:23:27.151050Z","shell.execute_reply":"2022-04-06T13:23:27.157425Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"1699\n","output_type":"stream"}]},{"cell_type":"code","source":"accuracy_5_labled=(count/len(test_res))*100","metadata":{"execution":{"iopub.status.busy":"2022-04-06T13:23:27.159436Z","iopub.execute_input":"2022-04-06T13:23:27.159842Z","iopub.status.idle":"2022-04-06T13:23:27.169708Z","shell.execute_reply.started":"2022-04-06T13:23:27.159808Z","shell.execute_reply":"2022-04-06T13:23:27.168989Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"print(\"Accuracy at 5% labled data\",accuracy_5_labled)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T13:23:27.171600Z","iopub.execute_input":"2022-04-06T13:23:27.172675Z","iopub.status.idle":"2022-04-06T13:23:27.181586Z","shell.execute_reply.started":"2022-04-06T13:23:27.172649Z","shell.execute_reply":"2022-04-06T13:23:27.180919Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Accuracy at 5% labled data 82.958984375\n","output_type":"stream"}]},{"cell_type":"code","source":"print(classification_report(y_test,test_res, target_names = ['Fake','Real']))","metadata":{"execution":{"iopub.status.busy":"2022-04-06T13:23:27.182651Z","iopub.execute_input":"2022-04-06T13:23:27.182959Z","iopub.status.idle":"2022-04-06T13:23:27.197035Z","shell.execute_reply.started":"2022-04-06T13:23:27.182925Z","shell.execute_reply":"2022-04-06T13:23:27.196348Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n        Fake       0.83      1.00      0.91      1700\n        Real       0.00      0.00      0.00       348\n\n    accuracy                           0.83      2048\n   macro avg       0.41      0.50      0.45      2048\nweighted avg       0.69      0.83      0.75      2048\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Traning when data 5% labled and lr=0.0001**","metadata":{}},{"cell_type":"code","source":"X_train1, X_test, y_train1, y_test = train_test_split(data['text'], data['label'],test_size=0.2 ,random_state=0)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T13:23:27.198233Z","iopub.execute_input":"2022-04-06T13:23:27.198577Z","iopub.status.idle":"2022-04-06T13:23:27.206617Z","shell.execute_reply.started":"2022-04-06T13:23:27.198541Z","shell.execute_reply":"2022-04-06T13:23:27.205957Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"X_lvl, X_unl, y_lvl, y_unl = train_test_split(X_train1,y_train1,test_size=0.95,random_state=0)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T13:23:27.207765Z","iopub.execute_input":"2022-04-06T13:23:27.208027Z","iopub.status.idle":"2022-04-06T13:23:27.215452Z","shell.execute_reply.started":"2022-04-06T13:23:27.207975Z","shell.execute_reply":"2022-04-06T13:23:27.214773Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"max_features = 3000\nmaxlen = 50","metadata":{"execution":{"iopub.status.busy":"2022-04-06T13:23:27.217620Z","iopub.execute_input":"2022-04-06T13:23:27.217853Z","iopub.status.idle":"2022-04-06T13:23:27.223074Z","shell.execute_reply.started":"2022-04-06T13:23:27.217830Z","shell.execute_reply":"2022-04-06T13:23:27.222303Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"tokenizer = text.Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(X_lvl)\ntokenized_train = tokenizer.texts_to_sequences(X_lvl)\nX_lvl = sequence.pad_sequences(tokenized_train, maxlen=maxlen)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T13:23:27.224138Z","iopub.execute_input":"2022-04-06T13:23:27.224388Z","iopub.status.idle":"2022-04-06T13:23:27.252075Z","shell.execute_reply.started":"2022-04-06T13:23:27.224355Z","shell.execute_reply":"2022-04-06T13:23:27.251426Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"tokenized_test = tokenizer.texts_to_sequences(X_test)\nX_test = sequence.pad_sequences(tokenized_test, maxlen=maxlen)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T13:23:27.253110Z","iopub.execute_input":"2022-04-06T13:23:27.253321Z","iopub.status.idle":"2022-04-06T13:23:27.302243Z","shell.execute_reply.started":"2022-04-06T13:23:27.253291Z","shell.execute_reply":"2022-04-06T13:23:27.301606Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"tokenized_unl = tokenizer.texts_to_sequences(X_unl)\nX_unl = sequence.pad_sequences(tokenized_unl, maxlen=maxlen)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T13:23:27.303393Z","iopub.execute_input":"2022-04-06T13:23:27.303611Z","iopub.status.idle":"2022-04-06T13:23:27.465049Z","shell.execute_reply.started":"2022-04-06T13:23:27.303581Z","shell.execute_reply":"2022-04-06T13:23:27.464382Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"batch_size = 128","metadata":{"execution":{"iopub.status.busy":"2022-04-06T13:23:27.466096Z","iopub.execute_input":"2022-04-06T13:23:27.466737Z","iopub.status.idle":"2022-04-06T13:23:27.470491Z","shell.execute_reply.started":"2022-04-06T13:23:27.466688Z","shell.execute_reply":"2022-04-06T13:23:27.469876Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras import regularizers\n\ndef build_model():\n  model = Sequential()\n  hp_units = 160\n  model.add(Embedding(max_features, output_dim=100, input_length=maxlen, trainable=False))\n  model.add(LSTM(units=hp_units, return_sequences = True , recurrent_dropout =0.5,dropout=0.5))\n  model.add(LSTM(units=hp_units , recurrent_dropout = 0.5 , dropout = 0.5))\n  model.add(Dense(units=hp_units , activation = 'relu'))\n  model.add(Dense(1, activation='sigmoid'))\n  hp_learning_rate =.0001\n  model.compile(tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),loss='binary_crossentropy', metrics=['accuracy'])\n  return model\n","metadata":{"execution":{"iopub.status.busy":"2022-04-06T13:23:27.471930Z","iopub.execute_input":"2022-04-06T13:23:27.472854Z","iopub.status.idle":"2022-04-06T13:23:27.482193Z","shell.execute_reply.started":"2022-04-06T13:23:27.472817Z","shell.execute_reply":"2022-04-06T13:23:27.480676Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"model=build_model()","metadata":{"execution":{"iopub.status.busy":"2022-04-06T13:23:27.483449Z","iopub.execute_input":"2022-04-06T13:23:27.483793Z","iopub.status.idle":"2022-04-06T13:23:27.704532Z","shell.execute_reply.started":"2022-04-06T13:23:27.483760Z","shell.execute_reply":"2022-04-06T13:23:27.703884Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-06T13:23:27.705581Z","iopub.execute_input":"2022-04-06T13:23:27.705833Z","iopub.status.idle":"2022-04-06T13:23:27.714154Z","shell.execute_reply.started":"2022-04-06T13:23:27.705802Z","shell.execute_reply":"2022-04-06T13:23:27.713363Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_2 (Embedding)      (None, 50, 100)           300000    \n_________________________________________________________________\nlstm_4 (LSTM)                (None, 50, 160)           167040    \n_________________________________________________________________\nlstm_5 (LSTM)                (None, 160)               205440    \n_________________________________________________________________\ndense_4 (Dense)              (None, 160)               25760     \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 161       \n=================================================================\nTotal params: 698,401\nTrainable params: 398,401\nNon-trainable params: 300,000\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"history = model.fit(X_lvl, y_lvl, validation_split=0.3, epochs=300, batch_size=batch_size, shuffle=True, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T13:23:27.715422Z","iopub.execute_input":"2022-04-06T13:23:27.716103Z","iopub.status.idle":"2022-04-06T13:30:02.414665Z","shell.execute_reply.started":"2022-04-06T13:23:27.716070Z","shell.execute_reply":"2022-04-06T13:30:02.414014Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Epoch 1/300\n3/3 [==============================] - 5s 607ms/step - loss: 0.6928 - accuracy: 0.5420 - val_loss: 0.6897 - val_accuracy: 0.8537\nEpoch 2/300\n3/3 [==============================] - 1s 399ms/step - loss: 0.6890 - accuracy: 0.8462 - val_loss: 0.6854 - val_accuracy: 0.8537\nEpoch 3/300\n3/3 [==============================] - 1s 403ms/step - loss: 0.6849 - accuracy: 0.8497 - val_loss: 0.6803 - val_accuracy: 0.8537\nEpoch 4/300\n3/3 [==============================] - 1s 416ms/step - loss: 0.6796 - accuracy: 0.8497 - val_loss: 0.6737 - val_accuracy: 0.8537\nEpoch 5/300\n3/3 [==============================] - 1s 416ms/step - loss: 0.6733 - accuracy: 0.8497 - val_loss: 0.6646 - val_accuracy: 0.8537\nEpoch 6/300\n3/3 [==============================] - 1s 426ms/step - loss: 0.6644 - accuracy: 0.8497 - val_loss: 0.6520 - val_accuracy: 0.8537\nEpoch 7/300\n3/3 [==============================] - 2s 562ms/step - loss: 0.6519 - accuracy: 0.8497 - val_loss: 0.6336 - val_accuracy: 0.8537\nEpoch 8/300\n3/3 [==============================] - 1s 388ms/step - loss: 0.6316 - accuracy: 0.8497 - val_loss: 0.6059 - val_accuracy: 0.8537\nEpoch 9/300\n3/3 [==============================] - 1s 407ms/step - loss: 0.6032 - accuracy: 0.8497 - val_loss: 0.5641 - val_accuracy: 0.8537\nEpoch 10/300\n3/3 [==============================] - 1s 395ms/step - loss: 0.5608 - accuracy: 0.8497 - val_loss: 0.5045 - val_accuracy: 0.8537\nEpoch 11/300\n3/3 [==============================] - 1s 416ms/step - loss: 0.5067 - accuracy: 0.8497 - val_loss: 0.4382 - val_accuracy: 0.8537\nEpoch 12/300\n3/3 [==============================] - 2s 772ms/step - loss: 0.4514 - accuracy: 0.8497 - val_loss: 0.4218 - val_accuracy: 0.8537\nEpoch 13/300\n3/3 [==============================] - 1s 425ms/step - loss: 0.4571 - accuracy: 0.8497 - val_loss: 0.4467 - val_accuracy: 0.8537\nEpoch 14/300\n3/3 [==============================] - 1s 438ms/step - loss: 0.4589 - accuracy: 0.8497 - val_loss: 0.4317 - val_accuracy: 0.8537\nEpoch 15/300\n3/3 [==============================] - 2s 607ms/step - loss: 0.4422 - accuracy: 0.8497 - val_loss: 0.4207 - val_accuracy: 0.8537\nEpoch 16/300\n3/3 [==============================] - 1s 415ms/step - loss: 0.4351 - accuracy: 0.8497 - val_loss: 0.4169 - val_accuracy: 0.8537\nEpoch 17/300\n3/3 [==============================] - 1s 422ms/step - loss: 0.4377 - accuracy: 0.8497 - val_loss: 0.4179 - val_accuracy: 0.8537\nEpoch 18/300\n3/3 [==============================] - 1s 416ms/step - loss: 0.4373 - accuracy: 0.8497 - val_loss: 0.4188 - val_accuracy: 0.8537\nEpoch 19/300\n3/3 [==============================] - 1s 410ms/step - loss: 0.4373 - accuracy: 0.8497 - val_loss: 0.4173 - val_accuracy: 0.8537\nEpoch 20/300\n3/3 [==============================] - 1s 417ms/step - loss: 0.4375 - accuracy: 0.8497 - val_loss: 0.4164 - val_accuracy: 0.8537\nEpoch 21/300\n3/3 [==============================] - 1s 410ms/step - loss: 0.4334 - accuracy: 0.8497 - val_loss: 0.4165 - val_accuracy: 0.8537\nEpoch 22/300\n3/3 [==============================] - 1s 414ms/step - loss: 0.4294 - accuracy: 0.8497 - val_loss: 0.4171 - val_accuracy: 0.8537\nEpoch 23/300\n3/3 [==============================] - 1s 408ms/step - loss: 0.4363 - accuracy: 0.8497 - val_loss: 0.4176 - val_accuracy: 0.8537\nEpoch 24/300\n3/3 [==============================] - 2s 637ms/step - loss: 0.4333 - accuracy: 0.8497 - val_loss: 0.4177 - val_accuracy: 0.8537\nEpoch 25/300\n3/3 [==============================] - 1s 391ms/step - loss: 0.4332 - accuracy: 0.8497 - val_loss: 0.4178 - val_accuracy: 0.8537\nEpoch 26/300\n3/3 [==============================] - 1s 392ms/step - loss: 0.4321 - accuracy: 0.8497 - val_loss: 0.4171 - val_accuracy: 0.8537\nEpoch 27/300\n3/3 [==============================] - 1s 391ms/step - loss: 0.4337 - accuracy: 0.8497 - val_loss: 0.4170 - val_accuracy: 0.8537\nEpoch 28/300\n3/3 [==============================] - 1s 417ms/step - loss: 0.4320 - accuracy: 0.8497 - val_loss: 0.4171 - val_accuracy: 0.8537\nEpoch 29/300\n3/3 [==============================] - 1s 411ms/step - loss: 0.4320 - accuracy: 0.8497 - val_loss: 0.4166 - val_accuracy: 0.8537\nEpoch 30/300\n3/3 [==============================] - 1s 413ms/step - loss: 0.4278 - accuracy: 0.8497 - val_loss: 0.4160 - val_accuracy: 0.8537\nEpoch 31/300\n3/3 [==============================] - 1s 411ms/step - loss: 0.4311 - accuracy: 0.8497 - val_loss: 0.4159 - val_accuracy: 0.8537\nEpoch 32/300\n3/3 [==============================] - 1s 412ms/step - loss: 0.4290 - accuracy: 0.8497 - val_loss: 0.4159 - val_accuracy: 0.8537\nEpoch 33/300\n3/3 [==============================] - 2s 461ms/step - loss: 0.4277 - accuracy: 0.8497 - val_loss: 0.4159 - val_accuracy: 0.8537\nEpoch 34/300\n3/3 [==============================] - 1s 394ms/step - loss: 0.4322 - accuracy: 0.8497 - val_loss: 0.4159 - val_accuracy: 0.8537\nEpoch 35/300\n3/3 [==============================] - 1s 422ms/step - loss: 0.4227 - accuracy: 0.8497 - val_loss: 0.4159 - val_accuracy: 0.8537\nEpoch 36/300\n3/3 [==============================] - 1s 414ms/step - loss: 0.4252 - accuracy: 0.8497 - val_loss: 0.4159 - val_accuracy: 0.8537\nEpoch 37/300\n3/3 [==============================] - 2s 790ms/step - loss: 0.4243 - accuracy: 0.8497 - val_loss: 0.4161 - val_accuracy: 0.8537\nEpoch 38/300\n3/3 [==============================] - 1s 451ms/step - loss: 0.4272 - accuracy: 0.8497 - val_loss: 0.4160 - val_accuracy: 0.8537\nEpoch 39/300\n3/3 [==============================] - 1s 422ms/step - loss: 0.4251 - accuracy: 0.8497 - val_loss: 0.4161 - val_accuracy: 0.8537\nEpoch 40/300\n3/3 [==============================] - 1s 446ms/step - loss: 0.4273 - accuracy: 0.8497 - val_loss: 0.4162 - val_accuracy: 0.8537\nEpoch 41/300\n3/3 [==============================] - 1s 403ms/step - loss: 0.4235 - accuracy: 0.8497 - val_loss: 0.4163 - val_accuracy: 0.8537\nEpoch 42/300\n3/3 [==============================] - 1s 391ms/step - loss: 0.4235 - accuracy: 0.8497 - val_loss: 0.4163 - val_accuracy: 0.8537\nEpoch 43/300\n3/3 [==============================] - 1s 391ms/step - loss: 0.4226 - accuracy: 0.8497 - val_loss: 0.4168 - val_accuracy: 0.8537\nEpoch 44/300\n3/3 [==============================] - 1s 418ms/step - loss: 0.4286 - accuracy: 0.8497 - val_loss: 0.4170 - val_accuracy: 0.8537\nEpoch 45/300\n3/3 [==============================] - 1s 404ms/step - loss: 0.4226 - accuracy: 0.8497 - val_loss: 0.4165 - val_accuracy: 0.8537\nEpoch 46/300\n3/3 [==============================] - 1s 404ms/step - loss: 0.4242 - accuracy: 0.8497 - val_loss: 0.4165 - val_accuracy: 0.8537\nEpoch 47/300\n3/3 [==============================] - 1s 399ms/step - loss: 0.4205 - accuracy: 0.8497 - val_loss: 0.4166 - val_accuracy: 0.8537\nEpoch 48/300\n3/3 [==============================] - 1s 388ms/step - loss: 0.4205 - accuracy: 0.8497 - val_loss: 0.4167 - val_accuracy: 0.8537\nEpoch 49/300\n3/3 [==============================] - 2s 598ms/step - loss: 0.4207 - accuracy: 0.8497 - val_loss: 0.4169 - val_accuracy: 0.8537\nEpoch 50/300\n3/3 [==============================] - 1s 400ms/step - loss: 0.4222 - accuracy: 0.8497 - val_loss: 0.4175 - val_accuracy: 0.8537\nEpoch 51/300\n3/3 [==============================] - 1s 416ms/step - loss: 0.4198 - accuracy: 0.8497 - val_loss: 0.4174 - val_accuracy: 0.8537\nEpoch 52/300\n3/3 [==============================] - 1s 404ms/step - loss: 0.4219 - accuracy: 0.8497 - val_loss: 0.4171 - val_accuracy: 0.8537\nEpoch 53/300\n3/3 [==============================] - 1s 411ms/step - loss: 0.4202 - accuracy: 0.8497 - val_loss: 0.4173 - val_accuracy: 0.8537\nEpoch 54/300\n3/3 [==============================] - 1s 429ms/step - loss: 0.4266 - accuracy: 0.8497 - val_loss: 0.4172 - val_accuracy: 0.8537\nEpoch 55/300\n3/3 [==============================] - 1s 407ms/step - loss: 0.4239 - accuracy: 0.8497 - val_loss: 0.4178 - val_accuracy: 0.8537\nEpoch 56/300\n3/3 [==============================] - 1s 398ms/step - loss: 0.4218 - accuracy: 0.8497 - val_loss: 0.4191 - val_accuracy: 0.8537\nEpoch 57/300\n3/3 [==============================] - 1s 444ms/step - loss: 0.4255 - accuracy: 0.8497 - val_loss: 0.4194 - val_accuracy: 0.8537\nEpoch 58/300\n3/3 [==============================] - 2s 609ms/step - loss: 0.4229 - accuracy: 0.8497 - val_loss: 0.4179 - val_accuracy: 0.8537\nEpoch 59/300\n3/3 [==============================] - 1s 419ms/step - loss: 0.4228 - accuracy: 0.8497 - val_loss: 0.4176 - val_accuracy: 0.8537\nEpoch 60/300\n3/3 [==============================] - 1s 425ms/step - loss: 0.4218 - accuracy: 0.8497 - val_loss: 0.4204 - val_accuracy: 0.8537\nEpoch 61/300\n3/3 [==============================] - 1s 405ms/step - loss: 0.4250 - accuracy: 0.8497 - val_loss: 0.4237 - val_accuracy: 0.8537\nEpoch 62/300\n3/3 [==============================] - 1s 494ms/step - loss: 0.4286 - accuracy: 0.8497 - val_loss: 0.4205 - val_accuracy: 0.8537\nEpoch 63/300\n3/3 [==============================] - 2s 392ms/step - loss: 0.4219 - accuracy: 0.8497 - val_loss: 0.4180 - val_accuracy: 0.8537\nEpoch 64/300\n3/3 [==============================] - 1s 420ms/step - loss: 0.4250 - accuracy: 0.8497 - val_loss: 0.4184 - val_accuracy: 0.8537\nEpoch 65/300\n3/3 [==============================] - 1s 428ms/step - loss: 0.4211 - accuracy: 0.8497 - val_loss: 0.4195 - val_accuracy: 0.8537\nEpoch 66/300\n3/3 [==============================] - 2s 613ms/step - loss: 0.4222 - accuracy: 0.8497 - val_loss: 0.4209 - val_accuracy: 0.8537\nEpoch 67/300\n3/3 [==============================] - 1s 420ms/step - loss: 0.4204 - accuracy: 0.8497 - val_loss: 0.4210 - val_accuracy: 0.8537\nEpoch 68/300\n3/3 [==============================] - 1s 427ms/step - loss: 0.4196 - accuracy: 0.8497 - val_loss: 0.4199 - val_accuracy: 0.8537\nEpoch 69/300\n3/3 [==============================] - 1s 397ms/step - loss: 0.4212 - accuracy: 0.8497 - val_loss: 0.4188 - val_accuracy: 0.8537\nEpoch 70/300\n3/3 [==============================] - 1s 421ms/step - loss: 0.4183 - accuracy: 0.8497 - val_loss: 0.4184 - val_accuracy: 0.8537\nEpoch 71/300\n3/3 [==============================] - 1s 457ms/step - loss: 0.4219 - accuracy: 0.8497 - val_loss: 0.4187 - val_accuracy: 0.8537\nEpoch 72/300\n3/3 [==============================] - 1s 408ms/step - loss: 0.4213 - accuracy: 0.8497 - val_loss: 0.4193 - val_accuracy: 0.8537\nEpoch 73/300\n3/3 [==============================] - 1s 427ms/step - loss: 0.4203 - accuracy: 0.8497 - val_loss: 0.4189 - val_accuracy: 0.8537\nEpoch 74/300\n3/3 [==============================] - 1s 453ms/step - loss: 0.4210 - accuracy: 0.8497 - val_loss: 0.4189 - val_accuracy: 0.8537\nEpoch 75/300\n3/3 [==============================] - 2s 413ms/step - loss: 0.4212 - accuracy: 0.8497 - val_loss: 0.4193 - val_accuracy: 0.8537\nEpoch 76/300\n3/3 [==============================] - 1s 407ms/step - loss: 0.4198 - accuracy: 0.8497 - val_loss: 0.4195 - val_accuracy: 0.8537\nEpoch 77/300\n3/3 [==============================] - 1s 408ms/step - loss: 0.4203 - accuracy: 0.8497 - val_loss: 0.4194 - val_accuracy: 0.8537\nEpoch 78/300\n3/3 [==============================] - 1s 400ms/step - loss: 0.4216 - accuracy: 0.8497 - val_loss: 0.4192 - val_accuracy: 0.8537\nEpoch 79/300\n3/3 [==============================] - 1s 415ms/step - loss: 0.4212 - accuracy: 0.8497 - val_loss: 0.4195 - val_accuracy: 0.8537\nEpoch 80/300\n3/3 [==============================] - 1s 432ms/step - loss: 0.4241 - accuracy: 0.8497 - val_loss: 0.4199 - val_accuracy: 0.8537\nEpoch 81/300\n3/3 [==============================] - 1s 402ms/step - loss: 0.4201 - accuracy: 0.8497 - val_loss: 0.4207 - val_accuracy: 0.8537\nEpoch 82/300\n3/3 [==============================] - 1s 425ms/step - loss: 0.4216 - accuracy: 0.8497 - val_loss: 0.4208 - val_accuracy: 0.8537\nEpoch 83/300\n3/3 [==============================] - 2s 636ms/step - loss: 0.4250 - accuracy: 0.8497 - val_loss: 0.4206 - val_accuracy: 0.8537\nEpoch 84/300\n3/3 [==============================] - 1s 433ms/step - loss: 0.4219 - accuracy: 0.8497 - val_loss: 0.4199 - val_accuracy: 0.8537\nEpoch 85/300\n3/3 [==============================] - 1s 402ms/step - loss: 0.4179 - accuracy: 0.8497 - val_loss: 0.4202 - val_accuracy: 0.8537\nEpoch 86/300\n3/3 [==============================] - 1s 394ms/step - loss: 0.4188 - accuracy: 0.8497 - val_loss: 0.4204 - val_accuracy: 0.8537\nEpoch 87/300\n3/3 [==============================] - 1s 400ms/step - loss: 0.4164 - accuracy: 0.8497 - val_loss: 0.4211 - val_accuracy: 0.8537\nEpoch 88/300\n3/3 [==============================] - 2s 659ms/step - loss: 0.4171 - accuracy: 0.8497 - val_loss: 0.4222 - val_accuracy: 0.8537\nEpoch 89/300\n3/3 [==============================] - 1s 392ms/step - loss: 0.4235 - accuracy: 0.8497 - val_loss: 0.4219 - val_accuracy: 0.8537\nEpoch 90/300\n3/3 [==============================] - 1s 402ms/step - loss: 0.4230 - accuracy: 0.8497 - val_loss: 0.4216 - val_accuracy: 0.8537\nEpoch 91/300\n3/3 [==============================] - 1s 491ms/step - loss: 0.4173 - accuracy: 0.8497 - val_loss: 0.4216 - val_accuracy: 0.8537\nEpoch 92/300\n3/3 [==============================] - 1s 398ms/step - loss: 0.4175 - accuracy: 0.8497 - val_loss: 0.4217 - val_accuracy: 0.8537\nEpoch 93/300\n3/3 [==============================] - 1s 416ms/step - loss: 0.4176 - accuracy: 0.8497 - val_loss: 0.4221 - val_accuracy: 0.8537\nEpoch 94/300\n3/3 [==============================] - 1s 430ms/step - loss: 0.4176 - accuracy: 0.8497 - val_loss: 0.4231 - val_accuracy: 0.8537\nEpoch 95/300\n3/3 [==============================] - 1s 432ms/step - loss: 0.4201 - accuracy: 0.8497 - val_loss: 0.4249 - val_accuracy: 0.8537\nEpoch 96/300\n3/3 [==============================] - 1s 408ms/step - loss: 0.4200 - accuracy: 0.8497 - val_loss: 0.4228 - val_accuracy: 0.8537\nEpoch 97/300\n3/3 [==============================] - 1s 437ms/step - loss: 0.4199 - accuracy: 0.8497 - val_loss: 0.4227 - val_accuracy: 0.8537\nEpoch 98/300\n3/3 [==============================] - 1s 431ms/step - loss: 0.4172 - accuracy: 0.8497 - val_loss: 0.4230 - val_accuracy: 0.8537\nEpoch 99/300\n3/3 [==============================] - 1s 425ms/step - loss: 0.4229 - accuracy: 0.8497 - val_loss: 0.4229 - val_accuracy: 0.8537\nEpoch 100/300\n3/3 [==============================] - 2s 598ms/step - loss: 0.4162 - accuracy: 0.8497 - val_loss: 0.4232 - val_accuracy: 0.8537\nEpoch 101/300\n3/3 [==============================] - 1s 420ms/step - loss: 0.4201 - accuracy: 0.8497 - val_loss: 0.4231 - val_accuracy: 0.8537\nEpoch 102/300\n3/3 [==============================] - 1s 401ms/step - loss: 0.4205 - accuracy: 0.8497 - val_loss: 0.4235 - val_accuracy: 0.8537\nEpoch 103/300\n3/3 [==============================] - 1s 414ms/step - loss: 0.4198 - accuracy: 0.8497 - val_loss: 0.4233 - val_accuracy: 0.8537\nEpoch 104/300\n3/3 [==============================] - 1s 418ms/step - loss: 0.4144 - accuracy: 0.8497 - val_loss: 0.4249 - val_accuracy: 0.8537\nEpoch 105/300\n3/3 [==============================] - 1s 444ms/step - loss: 0.4230 - accuracy: 0.8497 - val_loss: 0.4252 - val_accuracy: 0.8537\nEpoch 106/300\n3/3 [==============================] - 1s 427ms/step - loss: 0.4155 - accuracy: 0.8497 - val_loss: 0.4229 - val_accuracy: 0.8537\nEpoch 107/300\n3/3 [==============================] - 1s 399ms/step - loss: 0.4152 - accuracy: 0.8497 - val_loss: 0.4240 - val_accuracy: 0.8537\nEpoch 108/300\n3/3 [==============================] - 1s 465ms/step - loss: 0.4195 - accuracy: 0.8497 - val_loss: 0.4239 - val_accuracy: 0.8537\nEpoch 109/300\n3/3 [==============================] - 1s 434ms/step - loss: 0.4197 - accuracy: 0.8497 - val_loss: 0.4242 - val_accuracy: 0.8537\nEpoch 110/300\n3/3 [==============================] - 1s 394ms/step - loss: 0.4226 - accuracy: 0.8497 - val_loss: 0.4249 - val_accuracy: 0.8537\nEpoch 111/300\n3/3 [==============================] - 1s 420ms/step - loss: 0.4166 - accuracy: 0.8497 - val_loss: 0.4245 - val_accuracy: 0.8537\nEpoch 112/300\n3/3 [==============================] - 1s 410ms/step - loss: 0.4184 - accuracy: 0.8497 - val_loss: 0.4247 - val_accuracy: 0.8537\nEpoch 113/300\n3/3 [==============================] - 2s 797ms/step - loss: 0.4176 - accuracy: 0.8497 - val_loss: 0.4259 - val_accuracy: 0.8537\nEpoch 114/300\n3/3 [==============================] - 1s 415ms/step - loss: 0.4160 - accuracy: 0.8497 - val_loss: 0.4256 - val_accuracy: 0.8537\nEpoch 115/300\n3/3 [==============================] - 1s 390ms/step - loss: 0.4187 - accuracy: 0.8497 - val_loss: 0.4256 - val_accuracy: 0.8537\nEpoch 116/300\n3/3 [==============================] - 1s 398ms/step - loss: 0.4185 - accuracy: 0.8497 - val_loss: 0.4255 - val_accuracy: 0.8537\nEpoch 117/300\n3/3 [==============================] - 2s 417ms/step - loss: 0.4087 - accuracy: 0.8497 - val_loss: 0.4271 - val_accuracy: 0.8537\nEpoch 118/300\n3/3 [==============================] - 1s 416ms/step - loss: 0.4208 - accuracy: 0.8497 - val_loss: 0.4307 - val_accuracy: 0.8537\nEpoch 119/300\n3/3 [==============================] - 1s 426ms/step - loss: 0.4159 - accuracy: 0.8497 - val_loss: 0.4276 - val_accuracy: 0.8537\nEpoch 120/300\n3/3 [==============================] - 1s 393ms/step - loss: 0.4134 - accuracy: 0.8497 - val_loss: 0.4278 - val_accuracy: 0.8537\nEpoch 121/300\n3/3 [==============================] - 1s 418ms/step - loss: 0.4157 - accuracy: 0.8497 - val_loss: 0.4310 - val_accuracy: 0.8537\nEpoch 122/300\n3/3 [==============================] - 1s 398ms/step - loss: 0.4216 - accuracy: 0.8497 - val_loss: 0.4333 - val_accuracy: 0.8537\nEpoch 123/300\n3/3 [==============================] - 1s 447ms/step - loss: 0.4238 - accuracy: 0.8497 - val_loss: 0.4291 - val_accuracy: 0.8537\nEpoch 124/300\n3/3 [==============================] - 1s 435ms/step - loss: 0.4194 - accuracy: 0.8497 - val_loss: 0.4277 - val_accuracy: 0.8537\nEpoch 125/300\n3/3 [==============================] - 2s 653ms/step - loss: 0.4164 - accuracy: 0.8497 - val_loss: 0.4298 - val_accuracy: 0.8537\nEpoch 126/300\n3/3 [==============================] - 1s 469ms/step - loss: 0.4171 - accuracy: 0.8497 - val_loss: 0.4271 - val_accuracy: 0.8537\nEpoch 127/300\n3/3 [==============================] - 1s 464ms/step - loss: 0.4148 - accuracy: 0.8497 - val_loss: 0.4270 - val_accuracy: 0.8537\nEpoch 128/300\n3/3 [==============================] - 1s 405ms/step - loss: 0.4133 - accuracy: 0.8497 - val_loss: 0.4271 - val_accuracy: 0.8537\nEpoch 129/300\n3/3 [==============================] - 1s 407ms/step - loss: 0.4139 - accuracy: 0.8497 - val_loss: 0.4273 - val_accuracy: 0.8537\nEpoch 130/300\n3/3 [==============================] - 1s 410ms/step - loss: 0.4129 - accuracy: 0.8497 - val_loss: 0.4295 - val_accuracy: 0.8537\nEpoch 131/300\n3/3 [==============================] - 1s 427ms/step - loss: 0.4133 - accuracy: 0.8497 - val_loss: 0.4295 - val_accuracy: 0.8537\nEpoch 132/300\n3/3 [==============================] - 1s 418ms/step - loss: 0.4106 - accuracy: 0.8497 - val_loss: 0.4287 - val_accuracy: 0.8537\nEpoch 133/300\n3/3 [==============================] - 1s 521ms/step - loss: 0.4136 - accuracy: 0.8497 - val_loss: 0.4312 - val_accuracy: 0.8537\nEpoch 134/300\n3/3 [==============================] - 1s 411ms/step - loss: 0.4201 - accuracy: 0.8497 - val_loss: 0.4313 - val_accuracy: 0.8537\nEpoch 135/300\n3/3 [==============================] - 1s 417ms/step - loss: 0.4199 - accuracy: 0.8497 - val_loss: 0.4284 - val_accuracy: 0.8537\nEpoch 136/300\n3/3 [==============================] - 1s 406ms/step - loss: 0.4096 - accuracy: 0.8497 - val_loss: 0.4315 - val_accuracy: 0.8537\nEpoch 137/300\n3/3 [==============================] - 1s 393ms/step - loss: 0.4243 - accuracy: 0.8497 - val_loss: 0.4345 - val_accuracy: 0.8537\nEpoch 138/300\n3/3 [==============================] - 2s 744ms/step - loss: 0.4180 - accuracy: 0.8497 - val_loss: 0.4285 - val_accuracy: 0.8537\nEpoch 139/300\n3/3 [==============================] - 1s 417ms/step - loss: 0.4144 - accuracy: 0.8497 - val_loss: 0.4288 - val_accuracy: 0.8537\nEpoch 140/300\n3/3 [==============================] - 1s 411ms/step - loss: 0.4192 - accuracy: 0.8497 - val_loss: 0.4323 - val_accuracy: 0.8537\nEpoch 141/300\n3/3 [==============================] - 1s 418ms/step - loss: 0.4235 - accuracy: 0.8497 - val_loss: 0.4265 - val_accuracy: 0.8537\nEpoch 142/300\n3/3 [==============================] - 2s 460ms/step - loss: 0.4110 - accuracy: 0.8497 - val_loss: 0.4253 - val_accuracy: 0.8537\nEpoch 143/300\n3/3 [==============================] - 1s 404ms/step - loss: 0.4155 - accuracy: 0.8497 - val_loss: 0.4258 - val_accuracy: 0.8537\nEpoch 144/300\n3/3 [==============================] - 1s 390ms/step - loss: 0.4155 - accuracy: 0.8497 - val_loss: 0.4260 - val_accuracy: 0.8537\nEpoch 145/300\n3/3 [==============================] - 1s 407ms/step - loss: 0.4197 - accuracy: 0.8497 - val_loss: 0.4246 - val_accuracy: 0.8537\nEpoch 146/300\n3/3 [==============================] - 1s 405ms/step - loss: 0.4118 - accuracy: 0.8497 - val_loss: 0.4245 - val_accuracy: 0.8537\nEpoch 147/300\n3/3 [==============================] - 1s 419ms/step - loss: 0.4170 - accuracy: 0.8497 - val_loss: 0.4256 - val_accuracy: 0.8537\nEpoch 148/300\n3/3 [==============================] - 1s 412ms/step - loss: 0.4149 - accuracy: 0.8497 - val_loss: 0.4263 - val_accuracy: 0.8537\nEpoch 149/300\n3/3 [==============================] - 1s 422ms/step - loss: 0.4163 - accuracy: 0.8497 - val_loss: 0.4247 - val_accuracy: 0.8537\nEpoch 150/300\n3/3 [==============================] - 2s 596ms/step - loss: 0.4126 - accuracy: 0.8497 - val_loss: 0.4256 - val_accuracy: 0.8537\nEpoch 151/300\n3/3 [==============================] - 1s 415ms/step - loss: 0.4094 - accuracy: 0.8497 - val_loss: 0.4269 - val_accuracy: 0.8537\nEpoch 152/300\n3/3 [==============================] - 1s 403ms/step - loss: 0.4150 - accuracy: 0.8497 - val_loss: 0.4261 - val_accuracy: 0.8537\nEpoch 153/300\n3/3 [==============================] - 1s 416ms/step - loss: 0.4108 - accuracy: 0.8497 - val_loss: 0.4260 - val_accuracy: 0.8537\nEpoch 154/300\n3/3 [==============================] - 1s 406ms/step - loss: 0.4147 - accuracy: 0.8497 - val_loss: 0.4275 - val_accuracy: 0.8537\nEpoch 155/300\n3/3 [==============================] - 1s 401ms/step - loss: 0.4126 - accuracy: 0.8497 - val_loss: 0.4273 - val_accuracy: 0.8537\nEpoch 156/300\n3/3 [==============================] - 1s 416ms/step - loss: 0.4142 - accuracy: 0.8497 - val_loss: 0.4271 - val_accuracy: 0.8537\nEpoch 157/300\n3/3 [==============================] - 1s 392ms/step - loss: 0.4115 - accuracy: 0.8497 - val_loss: 0.4273 - val_accuracy: 0.8537\nEpoch 158/300\n3/3 [==============================] - 1s 413ms/step - loss: 0.4069 - accuracy: 0.8497 - val_loss: 0.4277 - val_accuracy: 0.8537\nEpoch 159/300\n3/3 [==============================] - 2s 625ms/step - loss: 0.4132 - accuracy: 0.8497 - val_loss: 0.4282 - val_accuracy: 0.8537\nEpoch 160/300\n3/3 [==============================] - 1s 412ms/step - loss: 0.4143 - accuracy: 0.8497 - val_loss: 0.4280 - val_accuracy: 0.8537\nEpoch 161/300\n3/3 [==============================] - 1s 400ms/step - loss: 0.4123 - accuracy: 0.8497 - val_loss: 0.4280 - val_accuracy: 0.8537\nEpoch 162/300\n3/3 [==============================] - 1s 424ms/step - loss: 0.4108 - accuracy: 0.8497 - val_loss: 0.4284 - val_accuracy: 0.8537\nEpoch 163/300\n3/3 [==============================] - 2s 600ms/step - loss: 0.4146 - accuracy: 0.8497 - val_loss: 0.4289 - val_accuracy: 0.8537\nEpoch 164/300\n3/3 [==============================] - 1s 402ms/step - loss: 0.4092 - accuracy: 0.8497 - val_loss: 0.4294 - val_accuracy: 0.8537\nEpoch 165/300\n3/3 [==============================] - 1s 425ms/step - loss: 0.4120 - accuracy: 0.8497 - val_loss: 0.4297 - val_accuracy: 0.8537\nEpoch 166/300\n3/3 [==============================] - 1s 389ms/step - loss: 0.4144 - accuracy: 0.8497 - val_loss: 0.4303 - val_accuracy: 0.8537\nEpoch 167/300\n3/3 [==============================] - 2s 631ms/step - loss: 0.4115 - accuracy: 0.8497 - val_loss: 0.4315 - val_accuracy: 0.8537\nEpoch 168/300\n3/3 [==============================] - 1s 419ms/step - loss: 0.4121 - accuracy: 0.8497 - val_loss: 0.4336 - val_accuracy: 0.8537\nEpoch 169/300\n3/3 [==============================] - 1s 402ms/step - loss: 0.4174 - accuracy: 0.8497 - val_loss: 0.4343 - val_accuracy: 0.8537\nEpoch 170/300\n3/3 [==============================] - 1s 409ms/step - loss: 0.4094 - accuracy: 0.8497 - val_loss: 0.4301 - val_accuracy: 0.8537\nEpoch 171/300\n3/3 [==============================] - 1s 391ms/step - loss: 0.4089 - accuracy: 0.8497 - val_loss: 0.4303 - val_accuracy: 0.8537\nEpoch 172/300\n3/3 [==============================] - 1s 406ms/step - loss: 0.4128 - accuracy: 0.8497 - val_loss: 0.4311 - val_accuracy: 0.8537\nEpoch 173/300\n3/3 [==============================] - 1s 409ms/step - loss: 0.4116 - accuracy: 0.8497 - val_loss: 0.4314 - val_accuracy: 0.8537\nEpoch 174/300\n3/3 [==============================] - 1s 393ms/step - loss: 0.4131 - accuracy: 0.8497 - val_loss: 0.4306 - val_accuracy: 0.8537\nEpoch 175/300\n3/3 [==============================] - 1s 424ms/step - loss: 0.4138 - accuracy: 0.8497 - val_loss: 0.4306 - val_accuracy: 0.8537\nEpoch 176/300\n3/3 [==============================] - 2s 501ms/step - loss: 0.4140 - accuracy: 0.8497 - val_loss: 0.4370 - val_accuracy: 0.8537\nEpoch 177/300\n3/3 [==============================] - 1s 422ms/step - loss: 0.4228 - accuracy: 0.8497 - val_loss: 0.4410 - val_accuracy: 0.8537\nEpoch 178/300\n3/3 [==============================] - 1s 405ms/step - loss: 0.4176 - accuracy: 0.8497 - val_loss: 0.4290 - val_accuracy: 0.8537\nEpoch 179/300\n3/3 [==============================] - 1s 413ms/step - loss: 0.4130 - accuracy: 0.8497 - val_loss: 0.4320 - val_accuracy: 0.8537\nEpoch 180/300\n3/3 [==============================] - 1s 403ms/step - loss: 0.4134 - accuracy: 0.8497 - val_loss: 0.4382 - val_accuracy: 0.8537\nEpoch 181/300\n3/3 [==============================] - 1s 408ms/step - loss: 0.4198 - accuracy: 0.8497 - val_loss: 0.4363 - val_accuracy: 0.8537\nEpoch 182/300\n3/3 [==============================] - 1s 408ms/step - loss: 0.4178 - accuracy: 0.8497 - val_loss: 0.4288 - val_accuracy: 0.8537\nEpoch 183/300\n3/3 [==============================] - 1s 393ms/step - loss: 0.4137 - accuracy: 0.8497 - val_loss: 0.4251 - val_accuracy: 0.8537\nEpoch 184/300\n3/3 [==============================] - 1s 427ms/step - loss: 0.4108 - accuracy: 0.8497 - val_loss: 0.4277 - val_accuracy: 0.8537\nEpoch 185/300\n3/3 [==============================] - 2s 455ms/step - loss: 0.4129 - accuracy: 0.8497 - val_loss: 0.4268 - val_accuracy: 0.8537\nEpoch 186/300\n3/3 [==============================] - 1s 394ms/step - loss: 0.4143 - accuracy: 0.8497 - val_loss: 0.4253 - val_accuracy: 0.8537\nEpoch 187/300\n3/3 [==============================] - 1s 433ms/step - loss: 0.4123 - accuracy: 0.8497 - val_loss: 0.4253 - val_accuracy: 0.8537\nEpoch 188/300\n3/3 [==============================] - 1s 444ms/step - loss: 0.4063 - accuracy: 0.8497 - val_loss: 0.4259 - val_accuracy: 0.8537\nEpoch 189/300\n3/3 [==============================] - 2s 639ms/step - loss: 0.4090 - accuracy: 0.8497 - val_loss: 0.4264 - val_accuracy: 0.8537\nEpoch 190/300\n3/3 [==============================] - 1s 428ms/step - loss: 0.4117 - accuracy: 0.8497 - val_loss: 0.4271 - val_accuracy: 0.8537\nEpoch 191/300\n3/3 [==============================] - 1s 386ms/step - loss: 0.4126 - accuracy: 0.8497 - val_loss: 0.4276 - val_accuracy: 0.8537\nEpoch 192/300\n3/3 [==============================] - 1s 425ms/step - loss: 0.4057 - accuracy: 0.8497 - val_loss: 0.4278 - val_accuracy: 0.8537\nEpoch 193/300\n3/3 [==============================] - 2s 553ms/step - loss: 0.4069 - accuracy: 0.8497 - val_loss: 0.4284 - val_accuracy: 0.8537\nEpoch 194/300\n3/3 [==============================] - 1s 399ms/step - loss: 0.4047 - accuracy: 0.8497 - val_loss: 0.4293 - val_accuracy: 0.8537\nEpoch 195/300\n3/3 [==============================] - 1s 422ms/step - loss: 0.4066 - accuracy: 0.8497 - val_loss: 0.4290 - val_accuracy: 0.8537\nEpoch 196/300\n3/3 [==============================] - 1s 424ms/step - loss: 0.4051 - accuracy: 0.8497 - val_loss: 0.4298 - val_accuracy: 0.8537\nEpoch 197/300\n3/3 [==============================] - 1s 407ms/step - loss: 0.4101 - accuracy: 0.8497 - val_loss: 0.4300 - val_accuracy: 0.8537\nEpoch 198/300\n3/3 [==============================] - 1s 408ms/step - loss: 0.4094 - accuracy: 0.8497 - val_loss: 0.4309 - val_accuracy: 0.8537\nEpoch 199/300\n3/3 [==============================] - 1s 422ms/step - loss: 0.4084 - accuracy: 0.8497 - val_loss: 0.4341 - val_accuracy: 0.8537\nEpoch 200/300\n3/3 [==============================] - 1s 441ms/step - loss: 0.4142 - accuracy: 0.8497 - val_loss: 0.4348 - val_accuracy: 0.8537\nEpoch 201/300\n3/3 [==============================] - 1s 538ms/step - loss: 0.4106 - accuracy: 0.8497 - val_loss: 0.4318 - val_accuracy: 0.8537\nEpoch 202/300\n3/3 [==============================] - 1s 448ms/step - loss: 0.4078 - accuracy: 0.8497 - val_loss: 0.4362 - val_accuracy: 0.8537\nEpoch 203/300\n3/3 [==============================] - 1s 449ms/step - loss: 0.4164 - accuracy: 0.8497 - val_loss: 0.4404 - val_accuracy: 0.8537\nEpoch 204/300\n3/3 [==============================] - 1s 430ms/step - loss: 0.4162 - accuracy: 0.8497 - val_loss: 0.4333 - val_accuracy: 0.8537\nEpoch 205/300\n3/3 [==============================] - 1s 444ms/step - loss: 0.4210 - accuracy: 0.8497 - val_loss: 0.4306 - val_accuracy: 0.8537\nEpoch 206/300\n3/3 [==============================] - 1s 399ms/step - loss: 0.4042 - accuracy: 0.8497 - val_loss: 0.4316 - val_accuracy: 0.8537\nEpoch 207/300\n3/3 [==============================] - 1s 394ms/step - loss: 0.4143 - accuracy: 0.8497 - val_loss: 0.4313 - val_accuracy: 0.8537\nEpoch 208/300\n3/3 [==============================] - 1s 448ms/step - loss: 0.4054 - accuracy: 0.8497 - val_loss: 0.4304 - val_accuracy: 0.8537\nEpoch 209/300\n3/3 [==============================] - 1s 419ms/step - loss: 0.4078 - accuracy: 0.8497 - val_loss: 0.4307 - val_accuracy: 0.8537\nEpoch 210/300\n3/3 [==============================] - 2s 534ms/step - loss: 0.4052 - accuracy: 0.8497 - val_loss: 0.4311 - val_accuracy: 0.8537\nEpoch 211/300\n3/3 [==============================] - 1s 404ms/step - loss: 0.4040 - accuracy: 0.8497 - val_loss: 0.4323 - val_accuracy: 0.8537\nEpoch 212/300\n3/3 [==============================] - 1s 405ms/step - loss: 0.4094 - accuracy: 0.8497 - val_loss: 0.4321 - val_accuracy: 0.8537\nEpoch 213/300\n3/3 [==============================] - 1s 411ms/step - loss: 0.4013 - accuracy: 0.8497 - val_loss: 0.4330 - val_accuracy: 0.8537\nEpoch 214/300\n3/3 [==============================] - 2s 606ms/step - loss: 0.4041 - accuracy: 0.8497 - val_loss: 0.4347 - val_accuracy: 0.8537\nEpoch 215/300\n3/3 [==============================] - 2s 454ms/step - loss: 0.4061 - accuracy: 0.8497 - val_loss: 0.4354 - val_accuracy: 0.8537\nEpoch 216/300\n3/3 [==============================] - 1s 388ms/step - loss: 0.4058 - accuracy: 0.8497 - val_loss: 0.4348 - val_accuracy: 0.8537\nEpoch 217/300\n3/3 [==============================] - 1s 408ms/step - loss: 0.4110 - accuracy: 0.8497 - val_loss: 0.4361 - val_accuracy: 0.8537\nEpoch 218/300\n3/3 [==============================] - 2s 622ms/step - loss: 0.4095 - accuracy: 0.8497 - val_loss: 0.4384 - val_accuracy: 0.8537\nEpoch 219/300\n3/3 [==============================] - 1s 403ms/step - loss: 0.4083 - accuracy: 0.8497 - val_loss: 0.4356 - val_accuracy: 0.8537\nEpoch 220/300\n3/3 [==============================] - 1s 437ms/step - loss: 0.4028 - accuracy: 0.8497 - val_loss: 0.4388 - val_accuracy: 0.8537\nEpoch 221/300\n3/3 [==============================] - 1s 408ms/step - loss: 0.4100 - accuracy: 0.8497 - val_loss: 0.4430 - val_accuracy: 0.8537\nEpoch 222/300\n3/3 [==============================] - 1s 428ms/step - loss: 0.4156 - accuracy: 0.8497 - val_loss: 0.4387 - val_accuracy: 0.8537\nEpoch 223/300\n3/3 [==============================] - 1s 424ms/step - loss: 0.4039 - accuracy: 0.8497 - val_loss: 0.4358 - val_accuracy: 0.8537\nEpoch 224/300\n3/3 [==============================] - 1s 409ms/step - loss: 0.4040 - accuracy: 0.8497 - val_loss: 0.4348 - val_accuracy: 0.8537\nEpoch 225/300\n3/3 [==============================] - 1s 426ms/step - loss: 0.4087 - accuracy: 0.8497 - val_loss: 0.4345 - val_accuracy: 0.8537\nEpoch 226/300\n3/3 [==============================] - 1s 400ms/step - loss: 0.3926 - accuracy: 0.8497 - val_loss: 0.4354 - val_accuracy: 0.8537\nEpoch 227/300\n3/3 [==============================] - 2s 433ms/step - loss: 0.4127 - accuracy: 0.8497 - val_loss: 0.4372 - val_accuracy: 0.8537\nEpoch 228/300\n3/3 [==============================] - 1s 388ms/step - loss: 0.4043 - accuracy: 0.8497 - val_loss: 0.4338 - val_accuracy: 0.8537\nEpoch 229/300\n3/3 [==============================] - 1s 401ms/step - loss: 0.4043 - accuracy: 0.8497 - val_loss: 0.4321 - val_accuracy: 0.8537\nEpoch 230/300\n3/3 [==============================] - 1s 409ms/step - loss: 0.4011 - accuracy: 0.8497 - val_loss: 0.4317 - val_accuracy: 0.8537\nEpoch 231/300\n3/3 [==============================] - 1s 417ms/step - loss: 0.4070 - accuracy: 0.8497 - val_loss: 0.4318 - val_accuracy: 0.8537\nEpoch 232/300\n3/3 [==============================] - 1s 407ms/step - loss: 0.3999 - accuracy: 0.8497 - val_loss: 0.4320 - val_accuracy: 0.8537\nEpoch 233/300\n3/3 [==============================] - 1s 402ms/step - loss: 0.4021 - accuracy: 0.8497 - val_loss: 0.4331 - val_accuracy: 0.8537\nEpoch 234/300\n3/3 [==============================] - 1s 401ms/step - loss: 0.4059 - accuracy: 0.8497 - val_loss: 0.4327 - val_accuracy: 0.8537\nEpoch 235/300\n3/3 [==============================] - 1s 536ms/step - loss: 0.4035 - accuracy: 0.8497 - val_loss: 0.4333 - val_accuracy: 0.8537\nEpoch 236/300\n3/3 [==============================] - 1s 404ms/step - loss: 0.4029 - accuracy: 0.8497 - val_loss: 0.4346 - val_accuracy: 0.8537\nEpoch 237/300\n3/3 [==============================] - 1s 421ms/step - loss: 0.4031 - accuracy: 0.8497 - val_loss: 0.4352 - val_accuracy: 0.8537\nEpoch 238/300\n3/3 [==============================] - 1s 401ms/step - loss: 0.4059 - accuracy: 0.8497 - val_loss: 0.4347 - val_accuracy: 0.8537\nEpoch 239/300\n3/3 [==============================] - 1s 435ms/step - loss: 0.3970 - accuracy: 0.8497 - val_loss: 0.4345 - val_accuracy: 0.8537\nEpoch 240/300\n3/3 [==============================] - 2s 715ms/step - loss: 0.4007 - accuracy: 0.8497 - val_loss: 0.4345 - val_accuracy: 0.8537\nEpoch 241/300\n3/3 [==============================] - 1s 417ms/step - loss: 0.3953 - accuracy: 0.8497 - val_loss: 0.4350 - val_accuracy: 0.8537\nEpoch 242/300\n3/3 [==============================] - 1s 401ms/step - loss: 0.3980 - accuracy: 0.8497 - val_loss: 0.4357 - val_accuracy: 0.8537\nEpoch 243/300\n3/3 [==============================] - 1s 432ms/step - loss: 0.3909 - accuracy: 0.8497 - val_loss: 0.4376 - val_accuracy: 0.8537\nEpoch 244/300\n3/3 [==============================] - 2s 428ms/step - loss: 0.4037 - accuracy: 0.8497 - val_loss: 0.4421 - val_accuracy: 0.8537\nEpoch 245/300\n3/3 [==============================] - 1s 441ms/step - loss: 0.3943 - accuracy: 0.8497 - val_loss: 0.4387 - val_accuracy: 0.8537\nEpoch 246/300\n3/3 [==============================] - 1s 418ms/step - loss: 0.4073 - accuracy: 0.8497 - val_loss: 0.4406 - val_accuracy: 0.8537\nEpoch 247/300\n3/3 [==============================] - 1s 416ms/step - loss: 0.3991 - accuracy: 0.8497 - val_loss: 0.4422 - val_accuracy: 0.8537\nEpoch 248/300\n3/3 [==============================] - 1s 420ms/step - loss: 0.4005 - accuracy: 0.8497 - val_loss: 0.4378 - val_accuracy: 0.8537\nEpoch 249/300\n3/3 [==============================] - 1s 429ms/step - loss: 0.3962 - accuracy: 0.8497 - val_loss: 0.4404 - val_accuracy: 0.8537\nEpoch 250/300\n3/3 [==============================] - 1s 395ms/step - loss: 0.4025 - accuracy: 0.8497 - val_loss: 0.4383 - val_accuracy: 0.8537\nEpoch 251/300\n3/3 [==============================] - 1s 415ms/step - loss: 0.3975 - accuracy: 0.8497 - val_loss: 0.4385 - val_accuracy: 0.8537\nEpoch 252/300\n3/3 [==============================] - 2s 612ms/step - loss: 0.3940 - accuracy: 0.8497 - val_loss: 0.4384 - val_accuracy: 0.8537\nEpoch 253/300\n3/3 [==============================] - 1s 450ms/step - loss: 0.4006 - accuracy: 0.8497 - val_loss: 0.4394 - val_accuracy: 0.8537\nEpoch 254/300\n3/3 [==============================] - 1s 422ms/step - loss: 0.4047 - accuracy: 0.8497 - val_loss: 0.4470 - val_accuracy: 0.8537\nEpoch 255/300\n3/3 [==============================] - 1s 433ms/step - loss: 0.4032 - accuracy: 0.8497 - val_loss: 0.4370 - val_accuracy: 0.8537\nEpoch 256/300\n3/3 [==============================] - 1s 414ms/step - loss: 0.3916 - accuracy: 0.8497 - val_loss: 0.4448 - val_accuracy: 0.8537\nEpoch 257/300\n3/3 [==============================] - 1s 406ms/step - loss: 0.4012 - accuracy: 0.8497 - val_loss: 0.4476 - val_accuracy: 0.8537\nEpoch 258/300\n3/3 [==============================] - 1s 395ms/step - loss: 0.4022 - accuracy: 0.8497 - val_loss: 0.4423 - val_accuracy: 0.8537\nEpoch 259/300\n3/3 [==============================] - 1s 417ms/step - loss: 0.4053 - accuracy: 0.8497 - val_loss: 0.4355 - val_accuracy: 0.8537\nEpoch 260/300\n3/3 [==============================] - 1s 407ms/step - loss: 0.3978 - accuracy: 0.8497 - val_loss: 0.4364 - val_accuracy: 0.8537\nEpoch 261/300\n3/3 [==============================] - 2s 422ms/step - loss: 0.3987 - accuracy: 0.8497 - val_loss: 0.4377 - val_accuracy: 0.8537\nEpoch 262/300\n3/3 [==============================] - 1s 401ms/step - loss: 0.3986 - accuracy: 0.8497 - val_loss: 0.4364 - val_accuracy: 0.8537\nEpoch 263/300\n3/3 [==============================] - 1s 400ms/step - loss: 0.3886 - accuracy: 0.8497 - val_loss: 0.4362 - val_accuracy: 0.8537\nEpoch 264/300\n3/3 [==============================] - 1s 413ms/step - loss: 0.3978 - accuracy: 0.8497 - val_loss: 0.4400 - val_accuracy: 0.8537\nEpoch 265/300\n3/3 [==============================] - 1s 484ms/step - loss: 0.3938 - accuracy: 0.8497 - val_loss: 0.4421 - val_accuracy: 0.8537\nEpoch 266/300\n3/3 [==============================] - 2s 438ms/step - loss: 0.3951 - accuracy: 0.8497 - val_loss: 0.4401 - val_accuracy: 0.8537\nEpoch 267/300\n3/3 [==============================] - 1s 421ms/step - loss: 0.3899 - accuracy: 0.8497 - val_loss: 0.4399 - val_accuracy: 0.8537\nEpoch 268/300\n3/3 [==============================] - 1s 454ms/step - loss: 0.3944 - accuracy: 0.8497 - val_loss: 0.4410 - val_accuracy: 0.8537\nEpoch 269/300\n3/3 [==============================] - 2s 556ms/step - loss: 0.3893 - accuracy: 0.8497 - val_loss: 0.4411 - val_accuracy: 0.8537\nEpoch 270/300\n3/3 [==============================] - 1s 464ms/step - loss: 0.3951 - accuracy: 0.8497 - val_loss: 0.4415 - val_accuracy: 0.8537\nEpoch 271/300\n3/3 [==============================] - 1s 473ms/step - loss: 0.3902 - accuracy: 0.8497 - val_loss: 0.4444 - val_accuracy: 0.8537\nEpoch 272/300\n3/3 [==============================] - 1s 390ms/step - loss: 0.3943 - accuracy: 0.8497 - val_loss: 0.4417 - val_accuracy: 0.8537\nEpoch 273/300\n3/3 [==============================] - 1s 407ms/step - loss: 0.3859 - accuracy: 0.8497 - val_loss: 0.4437 - val_accuracy: 0.8537\nEpoch 274/300\n3/3 [==============================] - 1s 404ms/step - loss: 0.3999 - accuracy: 0.8497 - val_loss: 0.4456 - val_accuracy: 0.8537\nEpoch 275/300\n3/3 [==============================] - 1s 392ms/step - loss: 0.3956 - accuracy: 0.8497 - val_loss: 0.4455 - val_accuracy: 0.8537\nEpoch 276/300\n3/3 [==============================] - 1s 393ms/step - loss: 0.3849 - accuracy: 0.8497 - val_loss: 0.4428 - val_accuracy: 0.8537\nEpoch 277/300\n3/3 [==============================] - 2s 619ms/step - loss: 0.3886 - accuracy: 0.8497 - val_loss: 0.4416 - val_accuracy: 0.8537\nEpoch 278/300\n3/3 [==============================] - 1s 396ms/step - loss: 0.4025 - accuracy: 0.8497 - val_loss: 0.4449 - val_accuracy: 0.8537\nEpoch 279/300\n3/3 [==============================] - 1s 395ms/step - loss: 0.3888 - accuracy: 0.8497 - val_loss: 0.4424 - val_accuracy: 0.8537\nEpoch 280/300\n3/3 [==============================] - 1s 390ms/step - loss: 0.3920 - accuracy: 0.8497 - val_loss: 0.4437 - val_accuracy: 0.8537\nEpoch 281/300\n3/3 [==============================] - 1s 424ms/step - loss: 0.3846 - accuracy: 0.8497 - val_loss: 0.4538 - val_accuracy: 0.8537\nEpoch 282/300\n3/3 [==============================] - 1s 425ms/step - loss: 0.3875 - accuracy: 0.8497 - val_loss: 0.4433 - val_accuracy: 0.8537\nEpoch 283/300\n3/3 [==============================] - 1s 387ms/step - loss: 0.3845 - accuracy: 0.8497 - val_loss: 0.4416 - val_accuracy: 0.8537\nEpoch 284/300\n3/3 [==============================] - 1s 390ms/step - loss: 0.3861 - accuracy: 0.8497 - val_loss: 0.4437 - val_accuracy: 0.8537\nEpoch 285/300\n3/3 [==============================] - 1s 416ms/step - loss: 0.3949 - accuracy: 0.8497 - val_loss: 0.4427 - val_accuracy: 0.8537\nEpoch 286/300\n3/3 [==============================] - 2s 649ms/step - loss: 0.3913 - accuracy: 0.8497 - val_loss: 0.4408 - val_accuracy: 0.8537\nEpoch 287/300\n3/3 [==============================] - 1s 410ms/step - loss: 0.3821 - accuracy: 0.8497 - val_loss: 0.4429 - val_accuracy: 0.8537\nEpoch 288/300\n3/3 [==============================] - 1s 409ms/step - loss: 0.3818 - accuracy: 0.8497 - val_loss: 0.4519 - val_accuracy: 0.8537\nEpoch 289/300\n3/3 [==============================] - 1s 413ms/step - loss: 0.4006 - accuracy: 0.8497 - val_loss: 0.4470 - val_accuracy: 0.8537\nEpoch 290/300\n3/3 [==============================] - 1s 385ms/step - loss: 0.3930 - accuracy: 0.8497 - val_loss: 0.4429 - val_accuracy: 0.8537\nEpoch 291/300\n3/3 [==============================] - 2s 653ms/step - loss: 0.3724 - accuracy: 0.8497 - val_loss: 0.4428 - val_accuracy: 0.8537\nEpoch 292/300\n3/3 [==============================] - 1s 406ms/step - loss: 0.3805 - accuracy: 0.8462 - val_loss: 0.4467 - val_accuracy: 0.8537\nEpoch 293/300\n3/3 [==============================] - 1s 429ms/step - loss: 0.3813 - accuracy: 0.8497 - val_loss: 0.4440 - val_accuracy: 0.8537\nEpoch 294/300\n3/3 [==============================] - 2s 572ms/step - loss: 0.3963 - accuracy: 0.8462 - val_loss: 0.4520 - val_accuracy: 0.8537\nEpoch 295/300\n3/3 [==============================] - 1s 408ms/step - loss: 0.3941 - accuracy: 0.8497 - val_loss: 0.4569 - val_accuracy: 0.8537\nEpoch 296/300\n3/3 [==============================] - 1s 421ms/step - loss: 0.3834 - accuracy: 0.8497 - val_loss: 0.4501 - val_accuracy: 0.8537\nEpoch 297/300\n3/3 [==============================] - 1s 411ms/step - loss: 0.3946 - accuracy: 0.8497 - val_loss: 0.4439 - val_accuracy: 0.8537\nEpoch 298/300\n3/3 [==============================] - 1s 407ms/step - loss: 0.3972 - accuracy: 0.8497 - val_loss: 0.4435 - val_accuracy: 0.8537\nEpoch 299/300\n3/3 [==============================] - 1s 418ms/step - loss: 0.3794 - accuracy: 0.8497 - val_loss: 0.4420 - val_accuracy: 0.8537\nEpoch 300/300\n3/3 [==============================] - 1s 436ms/step - loss: 0.3839 - accuracy: 0.8497 - val_loss: 0.4429 - val_accuracy: 0.8537\n","output_type":"stream"}]},{"cell_type":"code","source":"pred=(model.predict(X_unl) > 0.5).astype(\"int32\")","metadata":{"execution":{"iopub.status.busy":"2022-04-06T13:30:02.416281Z","iopub.execute_input":"2022-04-06T13:30:02.416516Z","iopub.status.idle":"2022-04-06T13:30:12.990204Z","shell.execute_reply.started":"2022-04-06T13:30:02.416483Z","shell.execute_reply":"2022-04-06T13:30:12.989505Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"X_train=np.concatenate((X_lvl,X_unl))\npred2=pred.flatten()\ny_unl = pd.Series(pred2)\ny_train=np.concatenate((y_lvl,y_unl))","metadata":{"execution":{"iopub.status.busy":"2022-04-06T13:30:12.991429Z","iopub.execute_input":"2022-04-06T13:30:12.991698Z","iopub.status.idle":"2022-04-06T13:30:12.998698Z","shell.execute_reply.started":"2022-04-06T13:30:12.991652Z","shell.execute_reply":"2022-04-06T13:30:12.997902Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"model=build_model()","metadata":{"execution":{"iopub.status.busy":"2022-04-06T13:30:13.000170Z","iopub.execute_input":"2022-04-06T13:30:13.000435Z","iopub.status.idle":"2022-04-06T13:30:13.227848Z","shell.execute_reply.started":"2022-04-06T13:30:13.000402Z","shell.execute_reply":"2022-04-06T13:30:13.227117Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_train, y_train, validation_split=0.3, epochs=100, batch_size=batch_size, shuffle=True, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T13:30:13.228962Z","iopub.execute_input":"2022-04-06T13:30:13.229204Z","iopub.status.idle":"2022-04-06T14:03:38.986226Z","shell.execute_reply.started":"2022-04-06T13:30:13.229172Z","shell.execute_reply":"2022-04-06T14:03:38.985376Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Epoch 1/100\n45/45 [==============================] - 23s 434ms/step - loss: 0.4570 - accuracy: 0.9676 - val_loss: 0.0028 - val_accuracy: 1.0000\nEpoch 2/100\n45/45 [==============================] - 19s 420ms/step - loss: 0.0630 - accuracy: 0.9894 - val_loss: 0.0106 - val_accuracy: 1.0000\nEpoch 3/100\n45/45 [==============================] - 20s 433ms/step - loss: 0.0589 - accuracy: 0.9894 - val_loss: 0.0087 - val_accuracy: 1.0000\nEpoch 4/100\n45/45 [==============================] - 20s 434ms/step - loss: 0.0584 - accuracy: 0.9894 - val_loss: 0.0080 - val_accuracy: 1.0000\nEpoch 5/100\n45/45 [==============================] - 19s 427ms/step - loss: 0.0593 - accuracy: 0.9894 - val_loss: 0.0100 - val_accuracy: 1.0000\nEpoch 6/100\n45/45 [==============================] - 19s 432ms/step - loss: 0.0592 - accuracy: 0.9894 - val_loss: 0.0092 - val_accuracy: 1.0000\nEpoch 7/100\n45/45 [==============================] - 19s 423ms/step - loss: 0.0588 - accuracy: 0.9894 - val_loss: 0.0080 - val_accuracy: 1.0000\nEpoch 8/100\n45/45 [==============================] - 20s 438ms/step - loss: 0.0589 - accuracy: 0.9894 - val_loss: 0.0113 - val_accuracy: 1.0000\nEpoch 9/100\n45/45 [==============================] - 19s 424ms/step - loss: 0.0591 - accuracy: 0.9894 - val_loss: 0.0102 - val_accuracy: 1.0000\nEpoch 10/100\n45/45 [==============================] - 19s 421ms/step - loss: 0.0589 - accuracy: 0.9894 - val_loss: 0.0097 - val_accuracy: 1.0000\nEpoch 11/100\n45/45 [==============================] - 20s 435ms/step - loss: 0.0585 - accuracy: 0.9894 - val_loss: 0.0101 - val_accuracy: 1.0000\nEpoch 12/100\n45/45 [==============================] - 19s 418ms/step - loss: 0.0589 - accuracy: 0.9894 - val_loss: 0.0098 - val_accuracy: 1.0000\nEpoch 13/100\n45/45 [==============================] - 19s 427ms/step - loss: 0.0583 - accuracy: 0.9894 - val_loss: 0.0050 - val_accuracy: 1.0000\nEpoch 14/100\n45/45 [==============================] - 20s 435ms/step - loss: 0.0585 - accuracy: 0.9894 - val_loss: 0.0123 - val_accuracy: 1.0000\nEpoch 15/100\n45/45 [==============================] - 19s 420ms/step - loss: 0.0586 - accuracy: 0.9894 - val_loss: 0.0095 - val_accuracy: 1.0000\nEpoch 16/100\n45/45 [==============================] - 20s 445ms/step - loss: 0.0588 - accuracy: 0.9894 - val_loss: 0.0072 - val_accuracy: 1.0000\nEpoch 17/100\n45/45 [==============================] - 18s 408ms/step - loss: 0.0586 - accuracy: 0.9894 - val_loss: 0.0076 - val_accuracy: 1.0000\nEpoch 18/100\n45/45 [==============================] - 20s 438ms/step - loss: 0.0590 - accuracy: 0.9894 - val_loss: 0.0058 - val_accuracy: 1.0000\nEpoch 19/100\n45/45 [==============================] - 19s 419ms/step - loss: 0.0593 - accuracy: 0.9894 - val_loss: 0.0045 - val_accuracy: 1.0000\nEpoch 20/100\n45/45 [==============================] - 19s 434ms/step - loss: 0.0581 - accuracy: 0.9894 - val_loss: 0.0098 - val_accuracy: 1.0000\nEpoch 21/100\n45/45 [==============================] - 19s 426ms/step - loss: 0.0593 - accuracy: 0.9894 - val_loss: 0.0083 - val_accuracy: 1.0000\nEpoch 22/100\n45/45 [==============================] - 19s 423ms/step - loss: 0.0592 - accuracy: 0.9894 - val_loss: 0.0067 - val_accuracy: 1.0000\nEpoch 23/100\n45/45 [==============================] - 20s 437ms/step - loss: 0.0585 - accuracy: 0.9894 - val_loss: 0.0097 - val_accuracy: 1.0000\nEpoch 24/100\n45/45 [==============================] - 19s 427ms/step - loss: 0.0581 - accuracy: 0.9894 - val_loss: 0.0090 - val_accuracy: 1.0000\nEpoch 25/100\n45/45 [==============================] - 19s 432ms/step - loss: 0.0584 - accuracy: 0.9894 - val_loss: 0.0094 - val_accuracy: 1.0000\nEpoch 26/100\n45/45 [==============================] - 20s 435ms/step - loss: 0.0582 - accuracy: 0.9894 - val_loss: 0.0093 - val_accuracy: 1.0000\nEpoch 27/100\n45/45 [==============================] - 19s 420ms/step - loss: 0.0582 - accuracy: 0.9894 - val_loss: 0.0086 - val_accuracy: 1.0000\nEpoch 28/100\n45/45 [==============================] - 20s 441ms/step - loss: 0.0583 - accuracy: 0.9894 - val_loss: 0.0089 - val_accuracy: 1.0000\nEpoch 29/100\n45/45 [==============================] - 19s 419ms/step - loss: 0.0585 - accuracy: 0.9894 - val_loss: 0.0143 - val_accuracy: 1.0000\nEpoch 30/100\n45/45 [==============================] - 20s 442ms/step - loss: 0.0582 - accuracy: 0.9894 - val_loss: 0.0090 - val_accuracy: 1.0000\nEpoch 31/100\n45/45 [==============================] - 19s 427ms/step - loss: 0.0587 - accuracy: 0.9894 - val_loss: 0.0107 - val_accuracy: 1.0000\nEpoch 32/100\n45/45 [==============================] - 20s 450ms/step - loss: 0.0587 - accuracy: 0.9894 - val_loss: 0.0082 - val_accuracy: 1.0000\nEpoch 33/100\n45/45 [==============================] - 20s 441ms/step - loss: 0.0584 - accuracy: 0.9894 - val_loss: 0.0059 - val_accuracy: 1.0000\nEpoch 34/100\n45/45 [==============================] - 20s 450ms/step - loss: 0.0577 - accuracy: 0.9894 - val_loss: 0.0090 - val_accuracy: 1.0000\nEpoch 35/100\n45/45 [==============================] - 21s 467ms/step - loss: 0.0575 - accuracy: 0.9894 - val_loss: 0.0098 - val_accuracy: 1.0000\nEpoch 36/100\n45/45 [==============================] - 20s 444ms/step - loss: 0.0575 - accuracy: 0.9894 - val_loss: 0.0059 - val_accuracy: 1.0000\nEpoch 37/100\n45/45 [==============================] - 20s 440ms/step - loss: 0.0586 - accuracy: 0.9894 - val_loss: 0.0072 - val_accuracy: 1.0000\nEpoch 38/100\n45/45 [==============================] - 19s 422ms/step - loss: 0.0591 - accuracy: 0.9894 - val_loss: 0.0039 - val_accuracy: 1.0000\nEpoch 39/100\n45/45 [==============================] - 19s 422ms/step - loss: 0.0592 - accuracy: 0.9894 - val_loss: 0.0073 - val_accuracy: 1.0000\nEpoch 40/100\n45/45 [==============================] - 20s 434ms/step - loss: 0.0582 - accuracy: 0.9894 - val_loss: 0.0100 - val_accuracy: 1.0000\nEpoch 41/100\n45/45 [==============================] - 19s 433ms/step - loss: 0.0577 - accuracy: 0.9894 - val_loss: 0.0087 - val_accuracy: 1.0000\nEpoch 42/100\n45/45 [==============================] - 20s 451ms/step - loss: 0.0579 - accuracy: 0.9894 - val_loss: 0.0066 - val_accuracy: 1.0000\nEpoch 43/100\n45/45 [==============================] - 19s 429ms/step - loss: 0.0577 - accuracy: 0.9894 - val_loss: 0.0093 - val_accuracy: 1.0000\nEpoch 44/100\n45/45 [==============================] - 19s 429ms/step - loss: 0.0577 - accuracy: 0.9894 - val_loss: 0.0048 - val_accuracy: 1.0000\nEpoch 45/100\n45/45 [==============================] - 20s 441ms/step - loss: 0.0584 - accuracy: 0.9894 - val_loss: 0.0073 - val_accuracy: 1.0000\nEpoch 46/100\n45/45 [==============================] - 20s 439ms/step - loss: 0.0577 - accuracy: 0.9894 - val_loss: 0.0085 - val_accuracy: 1.0000\nEpoch 47/100\n45/45 [==============================] - 20s 454ms/step - loss: 0.0575 - accuracy: 0.9894 - val_loss: 0.0075 - val_accuracy: 1.0000\nEpoch 48/100\n45/45 [==============================] - 19s 416ms/step - loss: 0.0583 - accuracy: 0.9894 - val_loss: 0.0053 - val_accuracy: 1.0000\nEpoch 49/100\n45/45 [==============================] - 19s 433ms/step - loss: 0.0585 - accuracy: 0.9894 - val_loss: 0.0081 - val_accuracy: 1.0000\nEpoch 50/100\n45/45 [==============================] - 20s 434ms/step - loss: 0.0578 - accuracy: 0.9894 - val_loss: 0.0084 - val_accuracy: 1.0000\nEpoch 51/100\n45/45 [==============================] - 19s 416ms/step - loss: 0.0576 - accuracy: 0.9894 - val_loss: 0.0125 - val_accuracy: 1.0000\nEpoch 52/100\n45/45 [==============================] - 19s 430ms/step - loss: 0.0575 - accuracy: 0.9894 - val_loss: 0.0083 - val_accuracy: 1.0000\nEpoch 53/100\n45/45 [==============================] - 19s 420ms/step - loss: 0.0577 - accuracy: 0.9894 - val_loss: 0.0079 - val_accuracy: 1.0000\nEpoch 54/100\n45/45 [==============================] - 19s 432ms/step - loss: 0.0583 - accuracy: 0.9894 - val_loss: 0.0106 - val_accuracy: 1.0000\nEpoch 55/100\n45/45 [==============================] - 20s 436ms/step - loss: 0.0575 - accuracy: 0.9894 - val_loss: 0.0052 - val_accuracy: 1.0000\nEpoch 56/100\n45/45 [==============================] - 18s 405ms/step - loss: 0.0584 - accuracy: 0.9894 - val_loss: 0.0063 - val_accuracy: 1.0000\nEpoch 57/100\n45/45 [==============================] - 20s 452ms/step - loss: 0.0577 - accuracy: 0.9894 - val_loss: 0.0133 - val_accuracy: 1.0000\nEpoch 58/100\n45/45 [==============================] - 19s 422ms/step - loss: 0.0571 - accuracy: 0.9894 - val_loss: 0.0062 - val_accuracy: 1.0000\nEpoch 59/100\n45/45 [==============================] - 20s 440ms/step - loss: 0.0576 - accuracy: 0.9894 - val_loss: 0.0114 - val_accuracy: 1.0000\nEpoch 60/100\n45/45 [==============================] - 19s 431ms/step - loss: 0.0573 - accuracy: 0.9894 - val_loss: 0.0124 - val_accuracy: 1.0000\nEpoch 61/100\n45/45 [==============================] - 20s 425ms/step - loss: 0.0573 - accuracy: 0.9894 - val_loss: 0.0081 - val_accuracy: 1.0000\nEpoch 62/100\n45/45 [==============================] - 19s 433ms/step - loss: 0.0579 - accuracy: 0.9894 - val_loss: 0.0104 - val_accuracy: 1.0000\nEpoch 63/100\n45/45 [==============================] - 19s 422ms/step - loss: 0.0568 - accuracy: 0.9894 - val_loss: 0.0061 - val_accuracy: 1.0000\nEpoch 64/100\n45/45 [==============================] - 19s 429ms/step - loss: 0.0575 - accuracy: 0.9894 - val_loss: 0.0078 - val_accuracy: 1.0000\nEpoch 65/100\n45/45 [==============================] - 20s 438ms/step - loss: 0.0569 - accuracy: 0.9894 - val_loss: 0.0055 - val_accuracy: 1.0000\nEpoch 66/100\n45/45 [==============================] - 19s 425ms/step - loss: 0.0573 - accuracy: 0.9894 - val_loss: 0.0079 - val_accuracy: 1.0000\nEpoch 67/100\n45/45 [==============================] - 20s 434ms/step - loss: 0.0574 - accuracy: 0.9894 - val_loss: 0.0060 - val_accuracy: 1.0000\nEpoch 68/100\n45/45 [==============================] - 19s 421ms/step - loss: 0.0576 - accuracy: 0.9894 - val_loss: 0.0139 - val_accuracy: 1.0000\nEpoch 69/100\n45/45 [==============================] - 19s 421ms/step - loss: 0.0585 - accuracy: 0.9894 - val_loss: 0.0102 - val_accuracy: 1.0000\nEpoch 70/100\n45/45 [==============================] - 20s 446ms/step - loss: 0.0573 - accuracy: 0.9894 - val_loss: 0.0090 - val_accuracy: 1.0000\nEpoch 71/100\n45/45 [==============================] - 19s 424ms/step - loss: 0.0567 - accuracy: 0.9894 - val_loss: 0.0072 - val_accuracy: 1.0000\nEpoch 72/100\n45/45 [==============================] - 20s 436ms/step - loss: 0.0564 - accuracy: 0.9894 - val_loss: 0.0093 - val_accuracy: 1.0000\nEpoch 73/100\n45/45 [==============================] - 18s 409ms/step - loss: 0.0568 - accuracy: 0.9894 - val_loss: 0.0104 - val_accuracy: 1.0000\nEpoch 74/100\n45/45 [==============================] - 20s 437ms/step - loss: 0.0565 - accuracy: 0.9894 - val_loss: 0.0088 - val_accuracy: 1.0000\nEpoch 75/100\n45/45 [==============================] - 20s 434ms/step - loss: 0.0566 - accuracy: 0.9894 - val_loss: 0.0053 - val_accuracy: 1.0000\nEpoch 76/100\n45/45 [==============================] - 19s 412ms/step - loss: 0.0569 - accuracy: 0.9894 - val_loss: 0.0099 - val_accuracy: 1.0000\nEpoch 77/100\n45/45 [==============================] - 19s 426ms/step - loss: 0.0569 - accuracy: 0.9894 - val_loss: 0.0079 - val_accuracy: 1.0000\nEpoch 78/100\n45/45 [==============================] - 19s 417ms/step - loss: 0.0564 - accuracy: 0.9894 - val_loss: 0.0084 - val_accuracy: 1.0000\nEpoch 79/100\n45/45 [==============================] - 19s 432ms/step - loss: 0.0565 - accuracy: 0.9894 - val_loss: 0.0092 - val_accuracy: 1.0000\nEpoch 80/100\n45/45 [==============================] - 19s 412ms/step - loss: 0.0562 - accuracy: 0.9894 - val_loss: 0.0064 - val_accuracy: 1.0000\nEpoch 81/100\n45/45 [==============================] - 19s 426ms/step - loss: 0.0557 - accuracy: 0.9894 - val_loss: 0.0066 - val_accuracy: 1.0000\nEpoch 82/100\n45/45 [==============================] - 19s 434ms/step - loss: 0.0562 - accuracy: 0.9894 - val_loss: 0.0062 - val_accuracy: 1.0000\nEpoch 83/100\n45/45 [==============================] - 19s 419ms/step - loss: 0.0557 - accuracy: 0.9894 - val_loss: 0.0085 - val_accuracy: 1.0000\nEpoch 84/100\n45/45 [==============================] - 19s 434ms/step - loss: 0.0562 - accuracy: 0.9894 - val_loss: 0.0047 - val_accuracy: 1.0000\nEpoch 85/100\n45/45 [==============================] - 20s 436ms/step - loss: 0.0552 - accuracy: 0.9895 - val_loss: 0.0079 - val_accuracy: 1.0000\nEpoch 86/100\n45/45 [==============================] - 20s 450ms/step - loss: 0.0549 - accuracy: 0.9894 - val_loss: 0.0076 - val_accuracy: 1.0000\nEpoch 87/100\n45/45 [==============================] - 21s 464ms/step - loss: 0.0543 - accuracy: 0.9894 - val_loss: 0.0095 - val_accuracy: 1.0000\nEpoch 88/100\n45/45 [==============================] - 20s 436ms/step - loss: 0.0544 - accuracy: 0.9894 - val_loss: 0.0077 - val_accuracy: 1.0000\nEpoch 89/100\n45/45 [==============================] - 20s 454ms/step - loss: 0.0542 - accuracy: 0.9894 - val_loss: 0.0101 - val_accuracy: 1.0000\nEpoch 90/100\n45/45 [==============================] - 19s 428ms/step - loss: 0.0554 - accuracy: 0.9895 - val_loss: 0.0071 - val_accuracy: 1.0000\nEpoch 91/100\n45/45 [==============================] - 20s 445ms/step - loss: 0.0526 - accuracy: 0.9894 - val_loss: 0.0069 - val_accuracy: 1.0000\nEpoch 92/100\n45/45 [==============================] - 21s 458ms/step - loss: 0.0539 - accuracy: 0.9895 - val_loss: 0.0072 - val_accuracy: 1.0000\nEpoch 93/100\n45/45 [==============================] - 20s 435ms/step - loss: 0.0531 - accuracy: 0.9895 - val_loss: 0.0054 - val_accuracy: 1.0000\nEpoch 94/100\n45/45 [==============================] - 20s 453ms/step - loss: 0.0528 - accuracy: 0.9895 - val_loss: 0.0087 - val_accuracy: 1.0000\nEpoch 95/100\n45/45 [==============================] - 21s 459ms/step - loss: 0.0533 - accuracy: 0.9897 - val_loss: 0.0075 - val_accuracy: 1.0000\nEpoch 96/100\n45/45 [==============================] - 19s 432ms/step - loss: 0.0531 - accuracy: 0.9895 - val_loss: 0.0103 - val_accuracy: 1.0000\nEpoch 97/100\n45/45 [==============================] - 20s 455ms/step - loss: 0.0547 - accuracy: 0.9894 - val_loss: 0.0091 - val_accuracy: 1.0000\nEpoch 98/100\n45/45 [==============================] - 20s 453ms/step - loss: 0.0534 - accuracy: 0.9894 - val_loss: 0.0078 - val_accuracy: 1.0000\nEpoch 99/100\n45/45 [==============================] - 20s 439ms/step - loss: 0.0540 - accuracy: 0.9895 - val_loss: 0.0088 - val_accuracy: 1.0000\nEpoch 100/100\n45/45 [==============================] - 21s 463ms/step - loss: 0.0515 - accuracy: 0.9894 - val_loss: 0.0091 - val_accuracy: 1.0000\n","output_type":"stream"}]},{"cell_type":"code","source":"test_res=(model.predict(X_test) > 0.5).astype(\"int32\")\ntest_res=test_res.flatten()\ny_test_c = y_test.to_numpy()","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:03:38.988247Z","iopub.execute_input":"2022-04-06T14:03:38.988525Z","iopub.status.idle":"2022-04-06T14:03:41.078534Z","shell.execute_reply.started":"2022-04-06T14:03:38.988488Z","shell.execute_reply":"2022-04-06T14:03:41.077785Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"count=0\nfor i in range(0,len(y_test_c)):\n  if(y_test_c[i]==test_res[i]):\n    count=count+1\nprint(count)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:03:41.079858Z","iopub.execute_input":"2022-04-06T14:03:41.080122Z","iopub.status.idle":"2022-04-06T14:03:41.088465Z","shell.execute_reply.started":"2022-04-06T14:03:41.080087Z","shell.execute_reply":"2022-04-06T14:03:41.087466Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"1701\n","output_type":"stream"}]},{"cell_type":"code","source":"accuracy_50001_labled=(count/len(test_res))*100","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:03:41.090057Z","iopub.execute_input":"2022-04-06T14:03:41.090616Z","iopub.status.idle":"2022-04-06T14:03:41.098986Z","shell.execute_reply.started":"2022-04-06T14:03:41.090576Z","shell.execute_reply":"2022-04-06T14:03:41.098272Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"print(\"Accuracy at 5% labled data and lr=.0001\",accuracy_50001_labled)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:03:41.101637Z","iopub.execute_input":"2022-04-06T14:03:41.101891Z","iopub.status.idle":"2022-04-06T14:03:41.109409Z","shell.execute_reply.started":"2022-04-06T14:03:41.101855Z","shell.execute_reply":"2022-04-06T14:03:41.108457Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Accuracy at 5% labled data and lr=.0001 83.056640625\n","output_type":"stream"}]},{"cell_type":"code","source":"print(classification_report(y_test,test_res, target_names = ['Fake','Real']))","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:03:41.110663Z","iopub.execute_input":"2022-04-06T14:03:41.111029Z","iopub.status.idle":"2022-04-06T14:03:41.129173Z","shell.execute_reply.started":"2022-04-06T14:03:41.110995Z","shell.execute_reply":"2022-04-06T14:03:41.128336Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n        Fake       0.83      1.00      0.91      1701\n        Real       0.00      0.00      0.00       347\n\n    accuracy                           0.83      2048\n   macro avg       0.42      0.50      0.45      2048\nweighted avg       0.69      0.83      0.75      2048\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Training Model when data is 5% labeled and batch size 256**","metadata":{}},{"cell_type":"code","source":"X_train1, X_test, y_train1, y_test = train_test_split(data['text'], data['label'],test_size=0.2 ,random_state=0)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:03:41.130575Z","iopub.execute_input":"2022-04-06T14:03:41.130829Z","iopub.status.idle":"2022-04-06T14:03:41.139495Z","shell.execute_reply.started":"2022-04-06T14:03:41.130797Z","shell.execute_reply":"2022-04-06T14:03:41.138693Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"X_lvl, X_unl, y_lvl, y_unl = train_test_split(X_train1,y_train1,test_size=0.95,random_state=0)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:03:41.140999Z","iopub.execute_input":"2022-04-06T14:03:41.141318Z","iopub.status.idle":"2022-04-06T14:03:41.148467Z","shell.execute_reply.started":"2022-04-06T14:03:41.141282Z","shell.execute_reply":"2022-04-06T14:03:41.147604Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"max_features = 3000\nmaxlen = 50","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:03:41.149924Z","iopub.execute_input":"2022-04-06T14:03:41.151455Z","iopub.status.idle":"2022-04-06T14:03:41.156975Z","shell.execute_reply.started":"2022-04-06T14:03:41.151420Z","shell.execute_reply":"2022-04-06T14:03:41.156183Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"tokenizer = text.Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(X_lvl)\ntokenized_train = tokenizer.texts_to_sequences(X_lvl)\nX_lvl = sequence.pad_sequences(tokenized_train, maxlen=maxlen)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:03:41.157986Z","iopub.execute_input":"2022-04-06T14:03:41.158245Z","iopub.status.idle":"2022-04-06T14:03:41.185237Z","shell.execute_reply.started":"2022-04-06T14:03:41.158212Z","shell.execute_reply":"2022-04-06T14:03:41.184520Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"tokenized_test = tokenizer.texts_to_sequences(X_test)\nX_test = sequence.pad_sequences(tokenized_test, maxlen=maxlen)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:03:41.188177Z","iopub.execute_input":"2022-04-06T14:03:41.188416Z","iopub.status.idle":"2022-04-06T14:03:41.237942Z","shell.execute_reply.started":"2022-04-06T14:03:41.188393Z","shell.execute_reply":"2022-04-06T14:03:41.237299Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"tokenized_unl = tokenizer.texts_to_sequences(X_unl)\nX_unl = sequence.pad_sequences(tokenized_unl, maxlen=maxlen)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:03:41.239006Z","iopub.execute_input":"2022-04-06T14:03:41.239287Z","iopub.status.idle":"2022-04-06T14:03:41.403690Z","shell.execute_reply.started":"2022-04-06T14:03:41.239241Z","shell.execute_reply":"2022-04-06T14:03:41.403024Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"batch_size = 256","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:03:41.405003Z","iopub.execute_input":"2022-04-06T14:03:41.405258Z","iopub.status.idle":"2022-04-06T14:03:41.409056Z","shell.execute_reply.started":"2022-04-06T14:03:41.405226Z","shell.execute_reply":"2022-04-06T14:03:41.408381Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras import regularizers\n\ndef build_model():\n  model = Sequential()\n  hp_units = 160\n  model.add(Embedding(max_features, output_dim=100, input_length=maxlen, trainable=False))\n  model.add(LSTM(units=hp_units, return_sequences = True , recurrent_dropout =0.5,dropout=0.5))\n  model.add(LSTM(units=hp_units , recurrent_dropout = 0.5 , dropout = 0.5))\n  model.add(Dense(units=hp_units , activation = 'relu'))\n  model.add(Dense(1, activation='sigmoid'))\n  hp_learning_rate = .001\n  model.compile(tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),loss='binary_crossentropy', metrics=['accuracy'])\n  return model","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:03:41.410515Z","iopub.execute_input":"2022-04-06T14:03:41.411006Z","iopub.status.idle":"2022-04-06T14:03:41.419985Z","shell.execute_reply.started":"2022-04-06T14:03:41.410972Z","shell.execute_reply":"2022-04-06T14:03:41.419147Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"model=build_model()","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:03:41.421348Z","iopub.execute_input":"2022-04-06T14:03:41.421714Z","iopub.status.idle":"2022-04-06T14:03:41.657312Z","shell.execute_reply.started":"2022-04-06T14:03:41.421681Z","shell.execute_reply":"2022-04-06T14:03:41.656580Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:03:41.658629Z","iopub.execute_input":"2022-04-06T14:03:41.658879Z","iopub.status.idle":"2022-04-06T14:03:41.667984Z","shell.execute_reply.started":"2022-04-06T14:03:41.658846Z","shell.execute_reply":"2022-04-06T14:03:41.667216Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"Model: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_4 (Embedding)      (None, 50, 100)           300000    \n_________________________________________________________________\nlstm_8 (LSTM)                (None, 50, 160)           167040    \n_________________________________________________________________\nlstm_9 (LSTM)                (None, 160)               205440    \n_________________________________________________________________\ndense_8 (Dense)              (None, 160)               25760     \n_________________________________________________________________\ndense_9 (Dense)              (None, 1)                 161       \n=================================================================\nTotal params: 698,401\nTrainable params: 398,401\nNon-trainable params: 300,000\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"history = model.fit(X_lvl, y_lvl, validation_split=0.3, epochs=300, batch_size=batch_size, shuffle=True, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:03:41.669445Z","iopub.execute_input":"2022-04-06T14:03:41.669831Z","iopub.status.idle":"2022-04-06T14:08:22.504244Z","shell.execute_reply.started":"2022-04-06T14:03:41.669795Z","shell.execute_reply":"2022-04-06T14:08:22.503579Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"Epoch 1/300\n2/2 [==============================] - 6s 921ms/step - loss: 0.6919 - accuracy: 0.5979 - val_loss: 0.6624 - val_accuracy: 0.8537\nEpoch 2/300\n2/2 [==============================] - 1s 465ms/step - loss: 0.6581 - accuracy: 0.8497 - val_loss: 0.5584 - val_accuracy: 0.8537\nEpoch 3/300\n2/2 [==============================] - 1s 889ms/step - loss: 0.5502 - accuracy: 0.8497 - val_loss: 0.4701 - val_accuracy: 0.8537\nEpoch 4/300\n2/2 [==============================] - 1s 442ms/step - loss: 0.4767 - accuracy: 0.8497 - val_loss: 0.4668 - val_accuracy: 0.8537\nEpoch 5/300\n2/2 [==============================] - 1s 438ms/step - loss: 0.4694 - accuracy: 0.8497 - val_loss: 0.4173 - val_accuracy: 0.8537\nEpoch 6/300\n2/2 [==============================] - 1s 440ms/step - loss: 0.4286 - accuracy: 0.8497 - val_loss: 0.4607 - val_accuracy: 0.8537\nEpoch 7/300\n2/2 [==============================] - 1s 468ms/step - loss: 0.4696 - accuracy: 0.8497 - val_loss: 0.4634 - val_accuracy: 0.8537\nEpoch 8/300\n2/2 [==============================] - 1s 470ms/step - loss: 0.4669 - accuracy: 0.8497 - val_loss: 0.4329 - val_accuracy: 0.8537\nEpoch 9/300\n2/2 [==============================] - 1s 469ms/step - loss: 0.4418 - accuracy: 0.8497 - val_loss: 0.4169 - val_accuracy: 0.8537\nEpoch 10/300\n2/2 [==============================] - 1s 428ms/step - loss: 0.4277 - accuracy: 0.8497 - val_loss: 0.4167 - val_accuracy: 0.8537\nEpoch 11/300\n2/2 [==============================] - 1s 426ms/step - loss: 0.4268 - accuracy: 0.8497 - val_loss: 0.4251 - val_accuracy: 0.8537\nEpoch 12/300\n2/2 [==============================] - 1s 437ms/step - loss: 0.4352 - accuracy: 0.8497 - val_loss: 0.4297 - val_accuracy: 0.8537\nEpoch 13/300\n2/2 [==============================] - 1s 437ms/step - loss: 0.4385 - accuracy: 0.8497 - val_loss: 0.4212 - val_accuracy: 0.8537\nEpoch 14/300\n2/2 [==============================] - 1s 430ms/step - loss: 0.4292 - accuracy: 0.8497 - val_loss: 0.4160 - val_accuracy: 0.8537\nEpoch 15/300\n2/2 [==============================] - 1s 867ms/step - loss: 0.4229 - accuracy: 0.8497 - val_loss: 0.4180 - val_accuracy: 0.8537\nEpoch 16/300\n2/2 [==============================] - 1s 486ms/step - loss: 0.4263 - accuracy: 0.8497 - val_loss: 0.4196 - val_accuracy: 0.8537\nEpoch 17/300\n2/2 [==============================] - 1s 472ms/step - loss: 0.4271 - accuracy: 0.8497 - val_loss: 0.4172 - val_accuracy: 0.8537\nEpoch 18/300\n2/2 [==============================] - 1s 464ms/step - loss: 0.4233 - accuracy: 0.8497 - val_loss: 0.4164 - val_accuracy: 0.8537\nEpoch 19/300\n2/2 [==============================] - 1s 494ms/step - loss: 0.4250 - accuracy: 0.8497 - val_loss: 0.4199 - val_accuracy: 0.8537\nEpoch 20/300\n2/2 [==============================] - 1s 444ms/step - loss: 0.4278 - accuracy: 0.8497 - val_loss: 0.4203 - val_accuracy: 0.8537\nEpoch 21/300\n2/2 [==============================] - 1s 445ms/step - loss: 0.4245 - accuracy: 0.8497 - val_loss: 0.4191 - val_accuracy: 0.8537\nEpoch 22/300\n2/2 [==============================] - 1s 450ms/step - loss: 0.4250 - accuracy: 0.8497 - val_loss: 0.4176 - val_accuracy: 0.8537\nEpoch 23/300\n2/2 [==============================] - 1s 472ms/step - loss: 0.4248 - accuracy: 0.8497 - val_loss: 0.4162 - val_accuracy: 0.8537\nEpoch 24/300\n2/2 [==============================] - 1s 465ms/step - loss: 0.4240 - accuracy: 0.8497 - val_loss: 0.4166 - val_accuracy: 0.8537\nEpoch 25/300\n2/2 [==============================] - 1s 476ms/step - loss: 0.4207 - accuracy: 0.8497 - val_loss: 0.4187 - val_accuracy: 0.8537\nEpoch 26/300\n2/2 [==============================] - 1s 449ms/step - loss: 0.4230 - accuracy: 0.8497 - val_loss: 0.4199 - val_accuracy: 0.8537\nEpoch 27/300\n2/2 [==============================] - 1s 794ms/step - loss: 0.4247 - accuracy: 0.8497 - val_loss: 0.4185 - val_accuracy: 0.8537\nEpoch 28/300\n2/2 [==============================] - 1s 479ms/step - loss: 0.4226 - accuracy: 0.8497 - val_loss: 0.4164 - val_accuracy: 0.8537\nEpoch 29/300\n2/2 [==============================] - 1s 478ms/step - loss: 0.4210 - accuracy: 0.8497 - val_loss: 0.4224 - val_accuracy: 0.8537\nEpoch 30/300\n2/2 [==============================] - 1s 526ms/step - loss: 0.4263 - accuracy: 0.8497 - val_loss: 0.4333 - val_accuracy: 0.8537\nEpoch 31/300\n2/2 [==============================] - 2s 571ms/step - loss: 0.4388 - accuracy: 0.8497 - val_loss: 0.4336 - val_accuracy: 0.8537\nEpoch 32/300\n2/2 [==============================] - 1s 429ms/step - loss: 0.4360 - accuracy: 0.8497 - val_loss: 0.4227 - val_accuracy: 0.8537\nEpoch 33/300\n2/2 [==============================] - 1s 417ms/step - loss: 0.4240 - accuracy: 0.8497 - val_loss: 0.4169 - val_accuracy: 0.8537\nEpoch 34/300\n2/2 [==============================] - 1s 427ms/step - loss: 0.4183 - accuracy: 0.8497 - val_loss: 0.4324 - val_accuracy: 0.8537\nEpoch 35/300\n2/2 [==============================] - 1s 425ms/step - loss: 0.4346 - accuracy: 0.8497 - val_loss: 0.4444 - val_accuracy: 0.8537\nEpoch 36/300\n2/2 [==============================] - 1s 484ms/step - loss: 0.4448 - accuracy: 0.8497 - val_loss: 0.4318 - val_accuracy: 0.8537\nEpoch 37/300\n2/2 [==============================] - 1s 421ms/step - loss: 0.4322 - accuracy: 0.8497 - val_loss: 0.4199 - val_accuracy: 0.8537\nEpoch 38/300\n2/2 [==============================] - 1s 677ms/step - loss: 0.4232 - accuracy: 0.8497 - val_loss: 0.4162 - val_accuracy: 0.8537\nEpoch 39/300\n2/2 [==============================] - 1s 427ms/step - loss: 0.4228 - accuracy: 0.8497 - val_loss: 0.4182 - val_accuracy: 0.8537\nEpoch 40/300\n2/2 [==============================] - 1s 426ms/step - loss: 0.4215 - accuracy: 0.8497 - val_loss: 0.4230 - val_accuracy: 0.8537\nEpoch 41/300\n2/2 [==============================] - 1s 429ms/step - loss: 0.4294 - accuracy: 0.8497 - val_loss: 0.4260 - val_accuracy: 0.8537\nEpoch 42/300\n2/2 [==============================] - 1s 430ms/step - loss: 0.4289 - accuracy: 0.8497 - val_loss: 0.4269 - val_accuracy: 0.8537\nEpoch 43/300\n2/2 [==============================] - 1s 431ms/step - loss: 0.4320 - accuracy: 0.8497 - val_loss: 0.4240 - val_accuracy: 0.8537\nEpoch 44/300\n2/2 [==============================] - 1s 434ms/step - loss: 0.4281 - accuracy: 0.8497 - val_loss: 0.4177 - val_accuracy: 0.8537\nEpoch 45/300\n2/2 [==============================] - 1s 457ms/step - loss: 0.4196 - accuracy: 0.8497 - val_loss: 0.4166 - val_accuracy: 0.8537\nEpoch 46/300\n2/2 [==============================] - 1s 460ms/step - loss: 0.4217 - accuracy: 0.8497 - val_loss: 0.4209 - val_accuracy: 0.8537\nEpoch 47/300\n2/2 [==============================] - 1s 453ms/step - loss: 0.4263 - accuracy: 0.8497 - val_loss: 0.4251 - val_accuracy: 0.8537\nEpoch 48/300\n2/2 [==============================] - 1s 504ms/step - loss: 0.4289 - accuracy: 0.8497 - val_loss: 0.4250 - val_accuracy: 0.8537\nEpoch 49/300\n2/2 [==============================] - 1s 533ms/step - loss: 0.4292 - accuracy: 0.8497 - val_loss: 0.4228 - val_accuracy: 0.8537\nEpoch 50/300\n2/2 [==============================] - 1s 640ms/step - loss: 0.4270 - accuracy: 0.8497 - val_loss: 0.4190 - val_accuracy: 0.8537\nEpoch 51/300\n2/2 [==============================] - 1s 441ms/step - loss: 0.4253 - accuracy: 0.8497 - val_loss: 0.4168 - val_accuracy: 0.8537\nEpoch 52/300\n2/2 [==============================] - 1s 455ms/step - loss: 0.4188 - accuracy: 0.8497 - val_loss: 0.4167 - val_accuracy: 0.8537\nEpoch 53/300\n2/2 [==============================] - 1s 475ms/step - loss: 0.4166 - accuracy: 0.8497 - val_loss: 0.4168 - val_accuracy: 0.8537\nEpoch 54/300\n2/2 [==============================] - 1s 435ms/step - loss: 0.4159 - accuracy: 0.8497 - val_loss: 0.4173 - val_accuracy: 0.8537\nEpoch 55/300\n2/2 [==============================] - 1s 428ms/step - loss: 0.4150 - accuracy: 0.8497 - val_loss: 0.4179 - val_accuracy: 0.8537\nEpoch 56/300\n2/2 [==============================] - 1s 434ms/step - loss: 0.4160 - accuracy: 0.8497 - val_loss: 0.4187 - val_accuracy: 0.8537\nEpoch 57/300\n2/2 [==============================] - 1s 477ms/step - loss: 0.4119 - accuracy: 0.8497 - val_loss: 0.4220 - val_accuracy: 0.8537\nEpoch 58/300\n2/2 [==============================] - 1s 432ms/step - loss: 0.4104 - accuracy: 0.8497 - val_loss: 0.4314 - val_accuracy: 0.8537\nEpoch 59/300\n2/2 [==============================] - 1s 433ms/step - loss: 0.4170 - accuracy: 0.8497 - val_loss: 0.4276 - val_accuracy: 0.8537\nEpoch 60/300\n2/2 [==============================] - 1s 496ms/step - loss: 0.4098 - accuracy: 0.8497 - val_loss: 0.4230 - val_accuracy: 0.8537\nEpoch 61/300\n2/2 [==============================] - 1s 437ms/step - loss: 0.4077 - accuracy: 0.8497 - val_loss: 0.4236 - val_accuracy: 0.8537\nEpoch 62/300\n2/2 [==============================] - 1s 528ms/step - loss: 0.4049 - accuracy: 0.8497 - val_loss: 0.4298 - val_accuracy: 0.8537\nEpoch 63/300\n2/2 [==============================] - 1s 433ms/step - loss: 0.4135 - accuracy: 0.8497 - val_loss: 0.4314 - val_accuracy: 0.8537\nEpoch 64/300\n2/2 [==============================] - 1s 458ms/step - loss: 0.4136 - accuracy: 0.8497 - val_loss: 0.4242 - val_accuracy: 0.8537\nEpoch 65/300\n2/2 [==============================] - 2s 1s/step - loss: 0.4088 - accuracy: 0.8497 - val_loss: 0.4284 - val_accuracy: 0.8537\nEpoch 66/300\n2/2 [==============================] - 1s 438ms/step - loss: 0.4066 - accuracy: 0.8497 - val_loss: 0.4398 - val_accuracy: 0.8537\nEpoch 67/300\n2/2 [==============================] - 1s 431ms/step - loss: 0.4188 - accuracy: 0.8497 - val_loss: 0.4307 - val_accuracy: 0.8537\nEpoch 68/300\n2/2 [==============================] - 1s 433ms/step - loss: 0.4096 - accuracy: 0.8497 - val_loss: 0.4224 - val_accuracy: 0.8537\nEpoch 69/300\n2/2 [==============================] - 1s 432ms/step - loss: 0.4014 - accuracy: 0.8497 - val_loss: 0.4231 - val_accuracy: 0.8537\nEpoch 70/300\n2/2 [==============================] - 1s 490ms/step - loss: 0.4006 - accuracy: 0.8497 - val_loss: 0.4352 - val_accuracy: 0.8537\nEpoch 71/300\n2/2 [==============================] - 1s 434ms/step - loss: 0.4092 - accuracy: 0.8497 - val_loss: 0.4450 - val_accuracy: 0.8537\nEpoch 72/300\n2/2 [==============================] - 1s 429ms/step - loss: 0.4140 - accuracy: 0.8497 - val_loss: 0.4384 - val_accuracy: 0.8537\nEpoch 73/300\n2/2 [==============================] - 1s 436ms/step - loss: 0.4050 - accuracy: 0.8497 - val_loss: 0.4331 - val_accuracy: 0.8537\nEpoch 74/300\n2/2 [==============================] - 1s 730ms/step - loss: 0.3910 - accuracy: 0.8497 - val_loss: 0.4367 - val_accuracy: 0.8537\nEpoch 75/300\n2/2 [==============================] - 1s 471ms/step - loss: 0.3824 - accuracy: 0.8497 - val_loss: 0.4680 - val_accuracy: 0.8537\nEpoch 76/300\n2/2 [==============================] - 1s 442ms/step - loss: 0.4129 - accuracy: 0.8497 - val_loss: 0.4518 - val_accuracy: 0.8537\nEpoch 77/300\n2/2 [==============================] - 1s 465ms/step - loss: 0.3768 - accuracy: 0.8497 - val_loss: 0.4609 - val_accuracy: 0.8537\nEpoch 78/300\n2/2 [==============================] - 1s 456ms/step - loss: 0.3840 - accuracy: 0.8497 - val_loss: 0.4430 - val_accuracy: 0.8537\nEpoch 79/300\n2/2 [==============================] - 1s 485ms/step - loss: 0.3715 - accuracy: 0.8497 - val_loss: 0.4383 - val_accuracy: 0.8537\nEpoch 80/300\n2/2 [==============================] - 1s 460ms/step - loss: 0.3687 - accuracy: 0.8497 - val_loss: 0.4439 - val_accuracy: 0.8537\nEpoch 81/300\n2/2 [==============================] - 1s 510ms/step - loss: 0.3537 - accuracy: 0.8497 - val_loss: 0.4713 - val_accuracy: 0.8537\nEpoch 82/300\n2/2 [==============================] - 1s 481ms/step - loss: 0.3754 - accuracy: 0.8531 - val_loss: 0.4963 - val_accuracy: 0.8537\nEpoch 83/300\n2/2 [==============================] - 1s 429ms/step - loss: 0.3622 - accuracy: 0.8497 - val_loss: 0.4734 - val_accuracy: 0.8537\nEpoch 84/300\n2/2 [==============================] - 1s 444ms/step - loss: 0.3594 - accuracy: 0.8601 - val_loss: 0.4774 - val_accuracy: 0.8537\nEpoch 85/300\n2/2 [==============================] - 1s 458ms/step - loss: 0.3453 - accuracy: 0.8462 - val_loss: 0.4852 - val_accuracy: 0.8537\nEpoch 86/300\n2/2 [==============================] - 1s 917ms/step - loss: 0.3318 - accuracy: 0.8636 - val_loss: 0.5278 - val_accuracy: 0.8537\nEpoch 87/300\n2/2 [==============================] - 1s 525ms/step - loss: 0.3490 - accuracy: 0.8497 - val_loss: 0.5306 - val_accuracy: 0.8537\nEpoch 88/300\n2/2 [==============================] - 1s 451ms/step - loss: 0.3287 - accuracy: 0.8636 - val_loss: 0.5443 - val_accuracy: 0.8455\nEpoch 89/300\n2/2 [==============================] - 1s 430ms/step - loss: 0.3537 - accuracy: 0.8741 - val_loss: 0.5251 - val_accuracy: 0.8537\nEpoch 90/300\n2/2 [==============================] - 1s 432ms/step - loss: 0.3342 - accuracy: 0.8566 - val_loss: 0.4546 - val_accuracy: 0.8537\nEpoch 91/300\n2/2 [==============================] - 1s 428ms/step - loss: 0.3688 - accuracy: 0.8462 - val_loss: 0.4707 - val_accuracy: 0.8374\nEpoch 92/300\n2/2 [==============================] - 1s 469ms/step - loss: 0.3902 - accuracy: 0.8881 - val_loss: 0.4575 - val_accuracy: 0.8374\nEpoch 93/300\n2/2 [==============================] - 1s 427ms/step - loss: 0.3885 - accuracy: 0.8601 - val_loss: 0.4363 - val_accuracy: 0.8537\nEpoch 94/300\n2/2 [==============================] - 1s 478ms/step - loss: 0.3450 - accuracy: 0.8601 - val_loss: 0.4603 - val_accuracy: 0.8537\nEpoch 95/300\n2/2 [==============================] - 1s 438ms/step - loss: 0.3511 - accuracy: 0.8462 - val_loss: 0.5138 - val_accuracy: 0.8537\nEpoch 96/300\n2/2 [==============================] - 1s 430ms/step - loss: 0.3500 - accuracy: 0.8531 - val_loss: 0.5048 - val_accuracy: 0.8293\nEpoch 97/300\n2/2 [==============================] - 1s 429ms/step - loss: 0.3694 - accuracy: 0.8462 - val_loss: 0.4891 - val_accuracy: 0.8374\nEpoch 98/300\n2/2 [==============================] - 1s 774ms/step - loss: 0.3765 - accuracy: 0.8322 - val_loss: 0.4687 - val_accuracy: 0.8455\nEpoch 99/300\n2/2 [==============================] - 1s 430ms/step - loss: 0.3311 - accuracy: 0.8706 - val_loss: 0.4590 - val_accuracy: 0.8537\nEpoch 100/300\n2/2 [==============================] - 1s 551ms/step - loss: 0.3261 - accuracy: 0.8601 - val_loss: 0.4825 - val_accuracy: 0.8537\nEpoch 101/300\n2/2 [==============================] - 1s 456ms/step - loss: 0.3406 - accuracy: 0.8531 - val_loss: 0.4683 - val_accuracy: 0.8537\nEpoch 102/300\n2/2 [==============================] - 1s 452ms/step - loss: 0.3263 - accuracy: 0.8566 - val_loss: 0.4392 - val_accuracy: 0.8537\nEpoch 103/300\n2/2 [==============================] - 1s 429ms/step - loss: 0.3459 - accuracy: 0.8497 - val_loss: 0.4338 - val_accuracy: 0.8537\nEpoch 104/300\n2/2 [==============================] - 1s 440ms/step - loss: 0.3266 - accuracy: 0.8601 - val_loss: 0.4405 - val_accuracy: 0.8537\nEpoch 105/300\n2/2 [==============================] - 1s 455ms/step - loss: 0.3488 - accuracy: 0.8427 - val_loss: 0.4602 - val_accuracy: 0.8537\nEpoch 106/300\n2/2 [==============================] - 1s 444ms/step - loss: 0.3259 - accuracy: 0.8636 - val_loss: 0.4940 - val_accuracy: 0.8537\nEpoch 107/300\n2/2 [==============================] - 1s 433ms/step - loss: 0.3468 - accuracy: 0.8601 - val_loss: 0.4784 - val_accuracy: 0.8455\nEpoch 108/300\n2/2 [==============================] - 1s 424ms/step - loss: 0.3113 - accuracy: 0.8741 - val_loss: 0.4689 - val_accuracy: 0.8455\nEpoch 109/300\n2/2 [==============================] - 1s 437ms/step - loss: 0.3107 - accuracy: 0.8671 - val_loss: 0.4792 - val_accuracy: 0.8537\nEpoch 110/300\n2/2 [==============================] - 1s 669ms/step - loss: 0.3221 - accuracy: 0.8636 - val_loss: 0.5239 - val_accuracy: 0.8537\nEpoch 111/300\n2/2 [==============================] - 1s 436ms/step - loss: 0.3298 - accuracy: 0.8462 - val_loss: 0.4883 - val_accuracy: 0.8537\nEpoch 112/300\n2/2 [==============================] - 1s 443ms/step - loss: 0.3408 - accuracy: 0.8566 - val_loss: 0.4436 - val_accuracy: 0.8537\nEpoch 113/300\n2/2 [==============================] - 1s 500ms/step - loss: 0.3248 - accuracy: 0.8392 - val_loss: 0.4373 - val_accuracy: 0.8537\nEpoch 114/300\n2/2 [==============================] - 1s 441ms/step - loss: 0.3330 - accuracy: 0.8671 - val_loss: 0.4423 - val_accuracy: 0.8537\nEpoch 115/300\n2/2 [==============================] - 1s 467ms/step - loss: 0.3225 - accuracy: 0.8636 - val_loss: 0.4724 - val_accuracy: 0.8537\nEpoch 116/300\n2/2 [==============================] - 1s 428ms/step - loss: 0.3249 - accuracy: 0.8671 - val_loss: 0.5379 - val_accuracy: 0.8537\nEpoch 117/300\n2/2 [==============================] - 1s 478ms/step - loss: 0.3162 - accuracy: 0.8706 - val_loss: 0.5418 - val_accuracy: 0.8537\nEpoch 118/300\n2/2 [==============================] - 1s 449ms/step - loss: 0.3365 - accuracy: 0.8636 - val_loss: 0.5537 - val_accuracy: 0.8537\nEpoch 119/300\n2/2 [==============================] - 1s 427ms/step - loss: 0.3396 - accuracy: 0.8392 - val_loss: 0.5660 - val_accuracy: 0.8455\nEpoch 120/300\n2/2 [==============================] - 1s 443ms/step - loss: 0.3134 - accuracy: 0.8741 - val_loss: 0.5655 - val_accuracy: 0.8455\nEpoch 121/300\n2/2 [==============================] - 1s 462ms/step - loss: 0.3207 - accuracy: 0.8462 - val_loss: 0.5435 - val_accuracy: 0.8455\nEpoch 122/300\n2/2 [==============================] - 1s 699ms/step - loss: 0.2976 - accuracy: 0.8811 - val_loss: 0.5119 - val_accuracy: 0.8537\nEpoch 123/300\n2/2 [==============================] - 1s 463ms/step - loss: 0.2931 - accuracy: 0.8566 - val_loss: 0.5048 - val_accuracy: 0.8455\nEpoch 124/300\n2/2 [==============================] - 1s 431ms/step - loss: 0.3128 - accuracy: 0.8776 - val_loss: 0.5053 - val_accuracy: 0.8455\nEpoch 125/300\n2/2 [==============================] - 1s 437ms/step - loss: 0.3031 - accuracy: 0.8706 - val_loss: 0.5086 - val_accuracy: 0.8455\nEpoch 126/300\n2/2 [==============================] - 1s 453ms/step - loss: 0.3389 - accuracy: 0.8531 - val_loss: 0.4966 - val_accuracy: 0.8537\nEpoch 127/300\n2/2 [==============================] - 1s 473ms/step - loss: 0.3172 - accuracy: 0.8566 - val_loss: 0.4704 - val_accuracy: 0.8537\nEpoch 128/300\n2/2 [==============================] - 1s 425ms/step - loss: 0.3087 - accuracy: 0.8531 - val_loss: 0.4612 - val_accuracy: 0.8537\nEpoch 129/300\n2/2 [==============================] - 1s 495ms/step - loss: 0.3088 - accuracy: 0.8497 - val_loss: 0.4737 - val_accuracy: 0.8537\nEpoch 130/300\n2/2 [==============================] - 1s 454ms/step - loss: 0.3074 - accuracy: 0.8636 - val_loss: 0.4848 - val_accuracy: 0.8455\nEpoch 131/300\n2/2 [==============================] - 1s 500ms/step - loss: 0.3285 - accuracy: 0.8531 - val_loss: 0.4899 - val_accuracy: 0.8455\nEpoch 132/300\n2/2 [==============================] - 1s 451ms/step - loss: 0.3016 - accuracy: 0.8881 - val_loss: 0.5496 - val_accuracy: 0.8455\nEpoch 133/300\n2/2 [==============================] - 1s 433ms/step - loss: 0.3211 - accuracy: 0.8601 - val_loss: 0.4755 - val_accuracy: 0.8455\nEpoch 134/300\n2/2 [==============================] - 1s 763ms/step - loss: 0.3084 - accuracy: 0.8671 - val_loss: 0.4593 - val_accuracy: 0.8374\nEpoch 135/300\n2/2 [==============================] - 1s 813ms/step - loss: 0.3456 - accuracy: 0.8462 - val_loss: 0.4391 - val_accuracy: 0.8537\nEpoch 136/300\n2/2 [==============================] - 1s 425ms/step - loss: 0.3142 - accuracy: 0.8811 - val_loss: 0.4516 - val_accuracy: 0.8537\nEpoch 137/300\n2/2 [==============================] - 1s 442ms/step - loss: 0.3521 - accuracy: 0.8531 - val_loss: 0.4628 - val_accuracy: 0.8537\nEpoch 138/300\n2/2 [==============================] - 1s 441ms/step - loss: 0.3400 - accuracy: 0.8601 - val_loss: 0.4440 - val_accuracy: 0.8537\nEpoch 139/300\n2/2 [==============================] - 1s 464ms/step - loss: 0.2970 - accuracy: 0.8531 - val_loss: 0.4386 - val_accuracy: 0.8537\nEpoch 140/300\n2/2 [==============================] - 1s 441ms/step - loss: 0.2986 - accuracy: 0.8741 - val_loss: 0.4473 - val_accuracy: 0.8537\nEpoch 141/300\n2/2 [==============================] - 1s 490ms/step - loss: 0.3232 - accuracy: 0.8497 - val_loss: 0.4679 - val_accuracy: 0.8537\nEpoch 142/300\n2/2 [==============================] - 1s 447ms/step - loss: 0.2964 - accuracy: 0.8636 - val_loss: 0.5066 - val_accuracy: 0.8455\nEpoch 143/300\n2/2 [==============================] - 1s 449ms/step - loss: 0.2839 - accuracy: 0.8916 - val_loss: 0.5123 - val_accuracy: 0.8455\nEpoch 144/300\n2/2 [==============================] - 1s 444ms/step - loss: 0.2895 - accuracy: 0.8916 - val_loss: 0.4921 - val_accuracy: 0.8211\nEpoch 145/300\n2/2 [==============================] - 1s 486ms/step - loss: 0.2753 - accuracy: 0.8811 - val_loss: 0.4895 - val_accuracy: 0.8211\nEpoch 146/300\n2/2 [==============================] - 1s 525ms/step - loss: 0.3179 - accuracy: 0.8601 - val_loss: 0.5165 - val_accuracy: 0.8293\nEpoch 147/300\n2/2 [==============================] - 1s 468ms/step - loss: 0.2812 - accuracy: 0.8706 - val_loss: 0.5754 - val_accuracy: 0.8537\nEpoch 148/300\n2/2 [==============================] - 1s 453ms/step - loss: 0.3103 - accuracy: 0.8636 - val_loss: 0.5241 - val_accuracy: 0.8211\nEpoch 149/300\n2/2 [==============================] - 1s 447ms/step - loss: 0.2616 - accuracy: 0.8811 - val_loss: 0.5182 - val_accuracy: 0.8130\nEpoch 150/300\n2/2 [==============================] - 1s 518ms/step - loss: 0.2604 - accuracy: 0.9231 - val_loss: 0.5498 - val_accuracy: 0.8130\nEpoch 151/300\n2/2 [==============================] - 1s 458ms/step - loss: 0.2798 - accuracy: 0.8706 - val_loss: 0.5866 - val_accuracy: 0.8130\nEpoch 152/300\n2/2 [==============================] - 1s 442ms/step - loss: 0.3324 - accuracy: 0.8741 - val_loss: 0.5729 - val_accuracy: 0.8211\nEpoch 153/300\n2/2 [==============================] - 1s 460ms/step - loss: 0.2794 - accuracy: 0.8741 - val_loss: 0.5315 - val_accuracy: 0.8211\nEpoch 154/300\n2/2 [==============================] - 1s 474ms/step - loss: 0.2657 - accuracy: 0.9021 - val_loss: 0.5195 - val_accuracy: 0.8455\nEpoch 155/300\n2/2 [==============================] - 1s 449ms/step - loss: 0.2808 - accuracy: 0.8706 - val_loss: 0.5577 - val_accuracy: 0.8455\nEpoch 156/300\n2/2 [==============================] - 1s 460ms/step - loss: 0.2571 - accuracy: 0.8811 - val_loss: 0.6502 - val_accuracy: 0.8537\nEpoch 157/300\n2/2 [==============================] - 1s 423ms/step - loss: 0.3129 - accuracy: 0.8531 - val_loss: 0.5178 - val_accuracy: 0.8537\nEpoch 158/300\n2/2 [==============================] - 1s 485ms/step - loss: 0.3106 - accuracy: 0.8741 - val_loss: 0.4584 - val_accuracy: 0.8293\nEpoch 159/300\n2/2 [==============================] - 1s 432ms/step - loss: 0.2949 - accuracy: 0.8916 - val_loss: 0.4600 - val_accuracy: 0.8293\nEpoch 160/300\n2/2 [==============================] - 1s 460ms/step - loss: 0.3216 - accuracy: 0.8706 - val_loss: 0.4655 - val_accuracy: 0.8455\nEpoch 161/300\n2/2 [==============================] - 1s 444ms/step - loss: 0.2744 - accuracy: 0.8951 - val_loss: 0.4962 - val_accuracy: 0.8455\nEpoch 162/300\n2/2 [==============================] - 1s 442ms/step - loss: 0.2923 - accuracy: 0.8951 - val_loss: 0.5024 - val_accuracy: 0.8374\nEpoch 163/300\n2/2 [==============================] - 1s 432ms/step - loss: 0.2638 - accuracy: 0.8846 - val_loss: 0.5117 - val_accuracy: 0.8130\nEpoch 164/300\n2/2 [==============================] - 1s 434ms/step - loss: 0.2951 - accuracy: 0.8846 - val_loss: 0.5129 - val_accuracy: 0.8293\nEpoch 165/300\n2/2 [==============================] - 1s 466ms/step - loss: 0.3082 - accuracy: 0.8776 - val_loss: 0.5204 - val_accuracy: 0.8374\nEpoch 166/300\n2/2 [==============================] - 1s 442ms/step - loss: 0.2925 - accuracy: 0.8706 - val_loss: 0.5658 - val_accuracy: 0.8537\nEpoch 167/300\n2/2 [==============================] - 1s 423ms/step - loss: 0.3351 - accuracy: 0.8601 - val_loss: 0.5723 - val_accuracy: 0.8537\nEpoch 168/300\n2/2 [==============================] - 1s 438ms/step - loss: 0.2662 - accuracy: 0.8986 - val_loss: 0.5664 - val_accuracy: 0.8374\nEpoch 169/300\n2/2 [==============================] - 1s 422ms/step - loss: 0.2746 - accuracy: 0.8636 - val_loss: 0.5587 - val_accuracy: 0.8211\nEpoch 170/300\n2/2 [==============================] - 2s 1s/step - loss: 0.2590 - accuracy: 0.8916 - val_loss: 0.5281 - val_accuracy: 0.8211\nEpoch 171/300\n2/2 [==============================] - 1s 484ms/step - loss: 0.2671 - accuracy: 0.8916 - val_loss: 0.5048 - val_accuracy: 0.8211\nEpoch 172/300\n2/2 [==============================] - 1s 458ms/step - loss: 0.2618 - accuracy: 0.8881 - val_loss: 0.4977 - val_accuracy: 0.8293\nEpoch 173/300\n2/2 [==============================] - 1s 474ms/step - loss: 0.2993 - accuracy: 0.8741 - val_loss: 0.5047 - val_accuracy: 0.8455\nEpoch 174/300\n2/2 [==============================] - 1s 467ms/step - loss: 0.2617 - accuracy: 0.8846 - val_loss: 0.5430 - val_accuracy: 0.8537\nEpoch 175/300\n2/2 [==============================] - 1s 441ms/step - loss: 0.2724 - accuracy: 0.8741 - val_loss: 0.5805 - val_accuracy: 0.8537\nEpoch 176/300\n2/2 [==============================] - 1s 459ms/step - loss: 0.2692 - accuracy: 0.8846 - val_loss: 0.5806 - val_accuracy: 0.8537\nEpoch 177/300\n2/2 [==============================] - 1s 513ms/step - loss: 0.2648 - accuracy: 0.8811 - val_loss: 0.5320 - val_accuracy: 0.8455\nEpoch 178/300\n2/2 [==============================] - 1s 427ms/step - loss: 0.2783 - accuracy: 0.8741 - val_loss: 0.5296 - val_accuracy: 0.8293\nEpoch 179/300\n2/2 [==============================] - 1s 475ms/step - loss: 0.2885 - accuracy: 0.8706 - val_loss: 0.5599 - val_accuracy: 0.8455\nEpoch 180/300\n2/2 [==============================] - 1s 424ms/step - loss: 0.3070 - accuracy: 0.8706 - val_loss: 0.5412 - val_accuracy: 0.8455\nEpoch 181/300\n2/2 [==============================] - 1s 469ms/step - loss: 0.2679 - accuracy: 0.8776 - val_loss: 0.5195 - val_accuracy: 0.8537\nEpoch 182/300\n2/2 [==============================] - 1s 562ms/step - loss: 0.3085 - accuracy: 0.8776 - val_loss: 0.5000 - val_accuracy: 0.8618\nEpoch 183/300\n2/2 [==============================] - 1s 431ms/step - loss: 0.2758 - accuracy: 0.8951 - val_loss: 0.4769 - val_accuracy: 0.8455\nEpoch 184/300\n2/2 [==============================] - 1s 420ms/step - loss: 0.2489 - accuracy: 0.9161 - val_loss: 0.4672 - val_accuracy: 0.8455\nEpoch 185/300\n2/2 [==============================] - 1s 428ms/step - loss: 0.2614 - accuracy: 0.8881 - val_loss: 0.4794 - val_accuracy: 0.8537\nEpoch 186/300\n2/2 [==============================] - 1s 425ms/step - loss: 0.2558 - accuracy: 0.9021 - val_loss: 0.5127 - val_accuracy: 0.8537\nEpoch 187/300\n2/2 [==============================] - 1s 475ms/step - loss: 0.2651 - accuracy: 0.9021 - val_loss: 0.5443 - val_accuracy: 0.8455\nEpoch 188/300\n2/2 [==============================] - 1s 427ms/step - loss: 0.2573 - accuracy: 0.8846 - val_loss: 0.5855 - val_accuracy: 0.8455\nEpoch 189/300\n2/2 [==============================] - 1s 473ms/step - loss: 0.2442 - accuracy: 0.9021 - val_loss: 0.6282 - val_accuracy: 0.8293\nEpoch 190/300\n2/2 [==============================] - 1s 501ms/step - loss: 0.2639 - accuracy: 0.8846 - val_loss: 0.6686 - val_accuracy: 0.8455\nEpoch 191/300\n2/2 [==============================] - 1s 424ms/step - loss: 0.2406 - accuracy: 0.8986 - val_loss: 0.7458 - val_accuracy: 0.8455\nEpoch 192/300\n2/2 [==============================] - 1s 447ms/step - loss: 0.2674 - accuracy: 0.8986 - val_loss: 0.8661 - val_accuracy: 0.8537\nEpoch 193/300\n2/2 [==============================] - 1s 474ms/step - loss: 0.3847 - accuracy: 0.8741 - val_loss: 0.5811 - val_accuracy: 0.8537\nEpoch 194/300\n2/2 [==============================] - 1s 702ms/step - loss: 0.2834 - accuracy: 0.8846 - val_loss: 0.4421 - val_accuracy: 0.8374\nEpoch 195/300\n2/2 [==============================] - 1s 431ms/step - loss: 0.2736 - accuracy: 0.8951 - val_loss: 0.4347 - val_accuracy: 0.8374\nEpoch 196/300\n2/2 [==============================] - 1s 432ms/step - loss: 0.3324 - accuracy: 0.8636 - val_loss: 0.4234 - val_accuracy: 0.8374\nEpoch 197/300\n2/2 [==============================] - 1s 417ms/step - loss: 0.3119 - accuracy: 0.8811 - val_loss: 0.4170 - val_accuracy: 0.8455\nEpoch 198/300\n2/2 [==============================] - 1s 455ms/step - loss: 0.2914 - accuracy: 0.8741 - val_loss: 0.4289 - val_accuracy: 0.8537\nEpoch 199/300\n2/2 [==============================] - 1s 450ms/step - loss: 0.2857 - accuracy: 0.8741 - val_loss: 0.4517 - val_accuracy: 0.8537\nEpoch 200/300\n2/2 [==============================] - 1s 429ms/step - loss: 0.3004 - accuracy: 0.8601 - val_loss: 0.4639 - val_accuracy: 0.8537\nEpoch 201/300\n2/2 [==============================] - 1s 466ms/step - loss: 0.2729 - accuracy: 0.8881 - val_loss: 0.4859 - val_accuracy: 0.8374\nEpoch 202/300\n2/2 [==============================] - 1s 451ms/step - loss: 0.2660 - accuracy: 0.9021 - val_loss: 0.5379 - val_accuracy: 0.7967\nEpoch 203/300\n2/2 [==============================] - 1s 449ms/step - loss: 0.3112 - accuracy: 0.8741 - val_loss: 0.5348 - val_accuracy: 0.8049\nEpoch 204/300\n2/2 [==============================] - 1s 481ms/step - loss: 0.2826 - accuracy: 0.8881 - val_loss: 0.5135 - val_accuracy: 0.8293\nEpoch 205/300\n2/2 [==============================] - 1s 438ms/step - loss: 0.2851 - accuracy: 0.8846 - val_loss: 0.4904 - val_accuracy: 0.8455\nEpoch 206/300\n2/2 [==============================] - 2s 795ms/step - loss: 0.2571 - accuracy: 0.8916 - val_loss: 0.4656 - val_accuracy: 0.8537\nEpoch 207/300\n2/2 [==============================] - 1s 447ms/step - loss: 0.2429 - accuracy: 0.9021 - val_loss: 0.4632 - val_accuracy: 0.8537\nEpoch 208/300\n2/2 [==============================] - 1s 481ms/step - loss: 0.2418 - accuracy: 0.8881 - val_loss: 0.4719 - val_accuracy: 0.8537\nEpoch 209/300\n2/2 [==============================] - 1s 442ms/step - loss: 0.2471 - accuracy: 0.8881 - val_loss: 0.4775 - val_accuracy: 0.8537\nEpoch 210/300\n2/2 [==============================] - 1s 475ms/step - loss: 0.2572 - accuracy: 0.8846 - val_loss: 0.4759 - val_accuracy: 0.8537\nEpoch 211/300\n2/2 [==============================] - 1s 450ms/step - loss: 0.2778 - accuracy: 0.8846 - val_loss: 0.4810 - val_accuracy: 0.8455\nEpoch 212/300\n2/2 [==============================] - 1s 466ms/step - loss: 0.2297 - accuracy: 0.9021 - val_loss: 0.4986 - val_accuracy: 0.8374\nEpoch 213/300\n2/2 [==============================] - 1s 478ms/step - loss: 0.2380 - accuracy: 0.9056 - val_loss: 0.5269 - val_accuracy: 0.8374\nEpoch 214/300\n2/2 [==============================] - 1s 423ms/step - loss: 0.2582 - accuracy: 0.8741 - val_loss: 0.5774 - val_accuracy: 0.8455\nEpoch 215/300\n2/2 [==============================] - 1s 428ms/step - loss: 0.2574 - accuracy: 0.8951 - val_loss: 0.6230 - val_accuracy: 0.8618\nEpoch 216/300\n2/2 [==============================] - 1s 442ms/step - loss: 0.2996 - accuracy: 0.8951 - val_loss: 0.5710 - val_accuracy: 0.8618\nEpoch 217/300\n2/2 [==============================] - 1s 435ms/step - loss: 0.2806 - accuracy: 0.8706 - val_loss: 0.5293 - val_accuracy: 0.8293\nEpoch 218/300\n2/2 [==============================] - 1s 470ms/step - loss: 0.2906 - accuracy: 0.8601 - val_loss: 0.5202 - val_accuracy: 0.8293\nEpoch 219/300\n2/2 [==============================] - 1s 429ms/step - loss: 0.2461 - accuracy: 0.9126 - val_loss: 0.5220 - val_accuracy: 0.8211\nEpoch 220/300\n2/2 [==============================] - 1s 452ms/step - loss: 0.2970 - accuracy: 0.8811 - val_loss: 0.5310 - val_accuracy: 0.8455\nEpoch 221/300\n2/2 [==============================] - 1s 438ms/step - loss: 0.2464 - accuracy: 0.8846 - val_loss: 0.5750 - val_accuracy: 0.8618\nEpoch 222/300\n2/2 [==============================] - 1s 478ms/step - loss: 0.2540 - accuracy: 0.8881 - val_loss: 0.6528 - val_accuracy: 0.8699\nEpoch 223/300\n2/2 [==============================] - 1s 423ms/step - loss: 0.2152 - accuracy: 0.9161 - val_loss: 0.6809 - val_accuracy: 0.8699\nEpoch 224/300\n2/2 [==============================] - 1s 455ms/step - loss: 0.2520 - accuracy: 0.8951 - val_loss: 0.6094 - val_accuracy: 0.8537\nEpoch 225/300\n2/2 [==============================] - 1s 442ms/step - loss: 0.2823 - accuracy: 0.8811 - val_loss: 0.5562 - val_accuracy: 0.8211\nEpoch 226/300\n2/2 [==============================] - 1s 430ms/step - loss: 0.2480 - accuracy: 0.9056 - val_loss: 0.5676 - val_accuracy: 0.8049\nEpoch 227/300\n2/2 [==============================] - 1s 482ms/step - loss: 0.3183 - accuracy: 0.8322 - val_loss: 0.5719 - val_accuracy: 0.8130\nEpoch 228/300\n2/2 [==============================] - 1s 434ms/step - loss: 0.2262 - accuracy: 0.8986 - val_loss: 0.6153 - val_accuracy: 0.8699\nEpoch 229/300\n2/2 [==============================] - 1s 471ms/step - loss: 0.2371 - accuracy: 0.8986 - val_loss: 0.6854 - val_accuracy: 0.8699\nEpoch 230/300\n2/2 [==============================] - 1s 422ms/step - loss: 0.2830 - accuracy: 0.8986 - val_loss: 0.6859 - val_accuracy: 0.8699\nEpoch 231/300\n2/2 [==============================] - 1s 449ms/step - loss: 0.2472 - accuracy: 0.8951 - val_loss: 0.6646 - val_accuracy: 0.8699\nEpoch 232/300\n2/2 [==============================] - 1s 444ms/step - loss: 0.2560 - accuracy: 0.9196 - val_loss: 0.6250 - val_accuracy: 0.8618\nEpoch 233/300\n2/2 [==============================] - 1s 409ms/step - loss: 0.2173 - accuracy: 0.8986 - val_loss: 0.6036 - val_accuracy: 0.8618\nEpoch 234/300\n2/2 [==============================] - 1s 442ms/step - loss: 0.2480 - accuracy: 0.9056 - val_loss: 0.5777 - val_accuracy: 0.8618\nEpoch 235/300\n2/2 [==============================] - 1s 457ms/step - loss: 0.2362 - accuracy: 0.8846 - val_loss: 0.5675 - val_accuracy: 0.8537\nEpoch 236/300\n2/2 [==============================] - 1s 460ms/step - loss: 0.2529 - accuracy: 0.8881 - val_loss: 0.5692 - val_accuracy: 0.8374\nEpoch 237/300\n2/2 [==============================] - 1s 461ms/step - loss: 0.2160 - accuracy: 0.9021 - val_loss: 0.5779 - val_accuracy: 0.8374\nEpoch 238/300\n2/2 [==============================] - 1s 447ms/step - loss: 0.2212 - accuracy: 0.8986 - val_loss: 0.5812 - val_accuracy: 0.8374\nEpoch 239/300\n2/2 [==============================] - 1s 420ms/step - loss: 0.2138 - accuracy: 0.9021 - val_loss: 0.5775 - val_accuracy: 0.8537\nEpoch 240/300\n2/2 [==============================] - 1s 423ms/step - loss: 0.2506 - accuracy: 0.8986 - val_loss: 0.5902 - val_accuracy: 0.8537\nEpoch 241/300\n2/2 [==============================] - 2s 949ms/step - loss: 0.2396 - accuracy: 0.8951 - val_loss: 0.5902 - val_accuracy: 0.8537\nEpoch 242/300\n2/2 [==============================] - 1s 452ms/step - loss: 0.1949 - accuracy: 0.9266 - val_loss: 0.6070 - val_accuracy: 0.8537\nEpoch 243/300\n2/2 [==============================] - 1s 423ms/step - loss: 0.2476 - accuracy: 0.8951 - val_loss: 0.6595 - val_accuracy: 0.8537\nEpoch 244/300\n2/2 [==============================] - 1s 467ms/step - loss: 0.1921 - accuracy: 0.9091 - val_loss: 0.7257 - val_accuracy: 0.8537\nEpoch 245/300\n2/2 [==============================] - 1s 441ms/step - loss: 0.2355 - accuracy: 0.9021 - val_loss: 0.7320 - val_accuracy: 0.8130\nEpoch 246/300\n2/2 [==============================] - 1s 439ms/step - loss: 0.2747 - accuracy: 0.8741 - val_loss: 0.7486 - val_accuracy: 0.8049\nEpoch 247/300\n2/2 [==============================] - 1s 468ms/step - loss: 0.2560 - accuracy: 0.8741 - val_loss: 0.7527 - val_accuracy: 0.8130\nEpoch 248/300\n2/2 [==============================] - 1s 423ms/step - loss: 0.2374 - accuracy: 0.8986 - val_loss: 0.8708 - val_accuracy: 0.8537\nEpoch 249/300\n2/2 [==============================] - 1s 474ms/step - loss: 0.2365 - accuracy: 0.9021 - val_loss: 1.0389 - val_accuracy: 0.8618\nEpoch 250/300\n2/2 [==============================] - 1s 436ms/step - loss: 0.2582 - accuracy: 0.8951 - val_loss: 0.9064 - val_accuracy: 0.8618\nEpoch 251/300\n2/2 [==============================] - 1s 458ms/step - loss: 0.2137 - accuracy: 0.9126 - val_loss: 0.6865 - val_accuracy: 0.8537\nEpoch 252/300\n2/2 [==============================] - 1s 446ms/step - loss: 0.2334 - accuracy: 0.9161 - val_loss: 0.6130 - val_accuracy: 0.8537\nEpoch 253/300\n2/2 [==============================] - 1s 649ms/step - loss: 0.2296 - accuracy: 0.8916 - val_loss: 0.6264 - val_accuracy: 0.8537\nEpoch 254/300\n2/2 [==============================] - 1s 428ms/step - loss: 0.2280 - accuracy: 0.8986 - val_loss: 0.6370 - val_accuracy: 0.8537\nEpoch 255/300\n2/2 [==============================] - 1s 479ms/step - loss: 0.2321 - accuracy: 0.9056 - val_loss: 0.6289 - val_accuracy: 0.8537\nEpoch 256/300\n2/2 [==============================] - 1s 425ms/step - loss: 0.2410 - accuracy: 0.8881 - val_loss: 0.6526 - val_accuracy: 0.8537\nEpoch 257/300\n2/2 [==============================] - 1s 421ms/step - loss: 0.2162 - accuracy: 0.8951 - val_loss: 0.6743 - val_accuracy: 0.8618\nEpoch 258/300\n2/2 [==============================] - 1s 426ms/step - loss: 0.2664 - accuracy: 0.8811 - val_loss: 0.6285 - val_accuracy: 0.8455\nEpoch 259/300\n2/2 [==============================] - 1s 451ms/step - loss: 0.2497 - accuracy: 0.8986 - val_loss: 0.6082 - val_accuracy: 0.8455\nEpoch 260/300\n2/2 [==============================] - 1s 437ms/step - loss: 0.2266 - accuracy: 0.9161 - val_loss: 0.6247 - val_accuracy: 0.8537\nEpoch 261/300\n2/2 [==============================] - 1s 451ms/step - loss: 0.2286 - accuracy: 0.9056 - val_loss: 0.6664 - val_accuracy: 0.8455\nEpoch 262/300\n2/2 [==============================] - 1s 472ms/step - loss: 0.2168 - accuracy: 0.9021 - val_loss: 0.7490 - val_accuracy: 0.8374\nEpoch 263/300\n2/2 [==============================] - 1s 456ms/step - loss: 0.2077 - accuracy: 0.9126 - val_loss: 0.8560 - val_accuracy: 0.8374\nEpoch 264/300\n2/2 [==============================] - 1s 450ms/step - loss: 0.2215 - accuracy: 0.9231 - val_loss: 0.8759 - val_accuracy: 0.8537\nEpoch 265/300\n2/2 [==============================] - 1s 423ms/step - loss: 0.2462 - accuracy: 0.9021 - val_loss: 0.8396 - val_accuracy: 0.8537\nEpoch 266/300\n2/2 [==============================] - 1s 648ms/step - loss: 0.2262 - accuracy: 0.9091 - val_loss: 0.6853 - val_accuracy: 0.8455\nEpoch 267/300\n2/2 [==============================] - 1s 414ms/step - loss: 0.2127 - accuracy: 0.9301 - val_loss: 0.5834 - val_accuracy: 0.8293\nEpoch 268/300\n2/2 [==============================] - 1s 456ms/step - loss: 0.2757 - accuracy: 0.8881 - val_loss: 0.5943 - val_accuracy: 0.8537\nEpoch 269/300\n2/2 [==============================] - 1s 435ms/step - loss: 0.2195 - accuracy: 0.9126 - val_loss: 0.6747 - val_accuracy: 0.8618\nEpoch 270/300\n2/2 [==============================] - 1s 438ms/step - loss: 0.2213 - accuracy: 0.9091 - val_loss: 0.8367 - val_accuracy: 0.8699\nEpoch 271/300\n2/2 [==============================] - 1s 429ms/step - loss: 0.2034 - accuracy: 0.9091 - val_loss: 0.9702 - val_accuracy: 0.8699\nEpoch 272/300\n2/2 [==============================] - 1s 452ms/step - loss: 0.1848 - accuracy: 0.9371 - val_loss: 0.8731 - val_accuracy: 0.8455\nEpoch 273/300\n2/2 [==============================] - 1s 424ms/step - loss: 0.2461 - accuracy: 0.8951 - val_loss: 0.7449 - val_accuracy: 0.8130\nEpoch 274/300\n2/2 [==============================] - 1s 455ms/step - loss: 0.1840 - accuracy: 0.9196 - val_loss: 0.7546 - val_accuracy: 0.8211\nEpoch 275/300\n2/2 [==============================] - 1s 460ms/step - loss: 0.2366 - accuracy: 0.8916 - val_loss: 0.8592 - val_accuracy: 0.8455\nEpoch 276/300\n2/2 [==============================] - 1s 421ms/step - loss: 0.2351 - accuracy: 0.9021 - val_loss: 0.9171 - val_accuracy: 0.8699\nEpoch 277/300\n2/2 [==============================] - 1s 845ms/step - loss: 0.2087 - accuracy: 0.9196 - val_loss: 0.8365 - val_accuracy: 0.8699\nEpoch 278/300\n2/2 [==============================] - 2s 750ms/step - loss: 0.2397 - accuracy: 0.8951 - val_loss: 0.7019 - val_accuracy: 0.8618\nEpoch 279/300\n2/2 [==============================] - 1s 432ms/step - loss: 0.2308 - accuracy: 0.9056 - val_loss: 0.5935 - val_accuracy: 0.8374\nEpoch 280/300\n2/2 [==============================] - 1s 414ms/step - loss: 0.2754 - accuracy: 0.8706 - val_loss: 0.5664 - val_accuracy: 0.8130\nEpoch 281/300\n2/2 [==============================] - 1s 435ms/step - loss: 0.2602 - accuracy: 0.8741 - val_loss: 0.6012 - val_accuracy: 0.8211\nEpoch 282/300\n2/2 [==============================] - 1s 429ms/step - loss: 0.2586 - accuracy: 0.8776 - val_loss: 0.7303 - val_accuracy: 0.8374\nEpoch 283/300\n2/2 [==============================] - 1s 468ms/step - loss: 0.1966 - accuracy: 0.9231 - val_loss: 0.9966 - val_accuracy: 0.8537\nEpoch 284/300\n2/2 [==============================] - 1s 450ms/step - loss: 0.1825 - accuracy: 0.9161 - val_loss: 1.1889 - val_accuracy: 0.8537\nEpoch 285/300\n2/2 [==============================] - 1s 427ms/step - loss: 0.2820 - accuracy: 0.8986 - val_loss: 1.1326 - val_accuracy: 0.8537\nEpoch 286/300\n2/2 [==============================] - 1s 462ms/step - loss: 0.2092 - accuracy: 0.9301 - val_loss: 0.9280 - val_accuracy: 0.8374\nEpoch 287/300\n2/2 [==============================] - 1s 417ms/step - loss: 0.2753 - accuracy: 0.8636 - val_loss: 0.7564 - val_accuracy: 0.8211\nEpoch 288/300\n2/2 [==============================] - 1s 457ms/step - loss: 0.2381 - accuracy: 0.9021 - val_loss: 0.6585 - val_accuracy: 0.8293\nEpoch 289/300\n2/2 [==============================] - 1s 425ms/step - loss: 0.1969 - accuracy: 0.9441 - val_loss: 0.6426 - val_accuracy: 0.8374\nEpoch 290/300\n2/2 [==============================] - 1s 771ms/step - loss: 0.2186 - accuracy: 0.9161 - val_loss: 0.6676 - val_accuracy: 0.8537\nEpoch 291/300\n2/2 [==============================] - 1s 425ms/step - loss: 0.2335 - accuracy: 0.9021 - val_loss: 0.6475 - val_accuracy: 0.8537\nEpoch 292/300\n2/2 [==============================] - 1s 429ms/step - loss: 0.2371 - accuracy: 0.9021 - val_loss: 0.6225 - val_accuracy: 0.8618\nEpoch 293/300\n2/2 [==============================] - 1s 411ms/step - loss: 0.2280 - accuracy: 0.8881 - val_loss: 0.6561 - val_accuracy: 0.8618\nEpoch 294/300\n2/2 [==============================] - 1s 432ms/step - loss: 0.1953 - accuracy: 0.9196 - val_loss: 0.7444 - val_accuracy: 0.8618\nEpoch 295/300\n2/2 [==============================] - 1s 411ms/step - loss: 0.2476 - accuracy: 0.9056 - val_loss: 0.8478 - val_accuracy: 0.8618\nEpoch 296/300\n2/2 [==============================] - 1s 431ms/step - loss: 0.2151 - accuracy: 0.9021 - val_loss: 0.9181 - val_accuracy: 0.8618\nEpoch 297/300\n2/2 [==============================] - 1s 431ms/step - loss: 0.2668 - accuracy: 0.8776 - val_loss: 0.7166 - val_accuracy: 0.8618\nEpoch 298/300\n2/2 [==============================] - 1s 472ms/step - loss: 0.2191 - accuracy: 0.9231 - val_loss: 0.5403 - val_accuracy: 0.8374\nEpoch 299/300\n2/2 [==============================] - 1s 452ms/step - loss: 0.2046 - accuracy: 0.9091 - val_loss: 0.5099 - val_accuracy: 0.8293\nEpoch 300/300\n2/2 [==============================] - 1s 458ms/step - loss: 0.2393 - accuracy: 0.9056 - val_loss: 0.5010 - val_accuracy: 0.8537\n","output_type":"stream"}]},{"cell_type":"code","source":"pred=(model.predict(X_unl) > 0.5).astype(\"int32\")","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:08:22.505967Z","iopub.execute_input":"2022-04-06T14:08:22.506221Z","iopub.status.idle":"2022-04-06T14:08:28.888768Z","shell.execute_reply.started":"2022-04-06T14:08:22.506187Z","shell.execute_reply":"2022-04-06T14:08:28.888018Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"X_train=np.concatenate((X_lvl,X_unl))\npred2=pred.flatten()\ny_unl = pd.Series(pred2)\ny_train=np.concatenate((y_lvl,y_unl))","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:08:28.890162Z","iopub.execute_input":"2022-04-06T14:08:28.890413Z","iopub.status.idle":"2022-04-06T14:08:28.898461Z","shell.execute_reply.started":"2022-04-06T14:08:28.890379Z","shell.execute_reply":"2022-04-06T14:08:28.897223Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"model=build_model()","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:08:28.900305Z","iopub.execute_input":"2022-04-06T14:08:28.900628Z","iopub.status.idle":"2022-04-06T14:08:29.135854Z","shell.execute_reply.started":"2022-04-06T14:08:28.900586Z","shell.execute_reply":"2022-04-06T14:08:29.135102Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_train, y_train, validation_split=0.3, epochs=100, batch_size=batch_size, shuffle=True, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:08:29.136967Z","iopub.execute_input":"2022-04-06T14:08:29.137212Z","iopub.status.idle":"2022-04-06T14:25:04.652762Z","shell.execute_reply.started":"2022-04-06T14:08:29.137179Z","shell.execute_reply":"2022-04-06T14:25:04.652056Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"Epoch 1/100\n23/23 [==============================] - 14s 473ms/step - loss: 0.3162 - accuracy: 0.9365 - val_loss: 0.2207 - val_accuracy: 0.9439\nEpoch 2/100\n23/23 [==============================] - 10s 427ms/step - loss: 0.2216 - accuracy: 0.9426 - val_loss: 0.2185 - val_accuracy: 0.9439\nEpoch 3/100\n23/23 [==============================] - 10s 418ms/step - loss: 0.2214 - accuracy: 0.9426 - val_loss: 0.2171 - val_accuracy: 0.9439\nEpoch 4/100\n23/23 [==============================] - 11s 473ms/step - loss: 0.2203 - accuracy: 0.9426 - val_loss: 0.2164 - val_accuracy: 0.9439\nEpoch 5/100\n23/23 [==============================] - 10s 424ms/step - loss: 0.2201 - accuracy: 0.9426 - val_loss: 0.2160 - val_accuracy: 0.9439\nEpoch 6/100\n23/23 [==============================] - 10s 431ms/step - loss: 0.2210 - accuracy: 0.9426 - val_loss: 0.2160 - val_accuracy: 0.9439\nEpoch 7/100\n23/23 [==============================] - 10s 456ms/step - loss: 0.2218 - accuracy: 0.9426 - val_loss: 0.2171 - val_accuracy: 0.9439\nEpoch 8/100\n23/23 [==============================] - 10s 419ms/step - loss: 0.2215 - accuracy: 0.9426 - val_loss: 0.2177 - val_accuracy: 0.9439\nEpoch 9/100\n23/23 [==============================] - 9s 406ms/step - loss: 0.2219 - accuracy: 0.9426 - val_loss: 0.2211 - val_accuracy: 0.9439\nEpoch 10/100\n23/23 [==============================] - 10s 453ms/step - loss: 0.2213 - accuracy: 0.9426 - val_loss: 0.2157 - val_accuracy: 0.9439\nEpoch 11/100\n23/23 [==============================] - 10s 423ms/step - loss: 0.2212 - accuracy: 0.9426 - val_loss: 0.2156 - val_accuracy: 0.9439\nEpoch 12/100\n23/23 [==============================] - 10s 423ms/step - loss: 0.2192 - accuracy: 0.9426 - val_loss: 0.2151 - val_accuracy: 0.9439\nEpoch 13/100\n23/23 [==============================] - 10s 421ms/step - loss: 0.2182 - accuracy: 0.9426 - val_loss: 0.2124 - val_accuracy: 0.9439\nEpoch 14/100\n23/23 [==============================] - 10s 426ms/step - loss: 0.2154 - accuracy: 0.9426 - val_loss: 0.2083 - val_accuracy: 0.9439\nEpoch 15/100\n23/23 [==============================] - 10s 433ms/step - loss: 0.2134 - accuracy: 0.9426 - val_loss: 0.2016 - val_accuracy: 0.9439\nEpoch 16/100\n23/23 [==============================] - 10s 414ms/step - loss: 0.2087 - accuracy: 0.9426 - val_loss: 0.1889 - val_accuracy: 0.9439\nEpoch 17/100\n23/23 [==============================] - 10s 449ms/step - loss: 0.2048 - accuracy: 0.9426 - val_loss: 0.1868 - val_accuracy: 0.9439\nEpoch 18/100\n23/23 [==============================] - 10s 422ms/step - loss: 0.1956 - accuracy: 0.9426 - val_loss: 0.1804 - val_accuracy: 0.9439\nEpoch 19/100\n23/23 [==============================] - 9s 398ms/step - loss: 0.1923 - accuracy: 0.9426 - val_loss: 0.1724 - val_accuracy: 0.9439\nEpoch 20/100\n23/23 [==============================] - 10s 453ms/step - loss: 0.1924 - accuracy: 0.9426 - val_loss: 0.1764 - val_accuracy: 0.9439\nEpoch 21/100\n23/23 [==============================] - 10s 423ms/step - loss: 0.1905 - accuracy: 0.9433 - val_loss: 0.1686 - val_accuracy: 0.9443\nEpoch 22/100\n23/23 [==============================] - 10s 423ms/step - loss: 0.1899 - accuracy: 0.9433 - val_loss: 0.1729 - val_accuracy: 0.9439\nEpoch 23/100\n23/23 [==============================] - 10s 448ms/step - loss: 0.1871 - accuracy: 0.9435 - val_loss: 0.1787 - val_accuracy: 0.9459\nEpoch 24/100\n23/23 [==============================] - 9s 414ms/step - loss: 0.1866 - accuracy: 0.9435 - val_loss: 0.1650 - val_accuracy: 0.9443\nEpoch 25/100\n23/23 [==============================] - 10s 417ms/step - loss: 0.1846 - accuracy: 0.9431 - val_loss: 0.1650 - val_accuracy: 0.9443\nEpoch 26/100\n23/23 [==============================] - 10s 441ms/step - loss: 0.1858 - accuracy: 0.9423 - val_loss: 0.1632 - val_accuracy: 0.9451\nEpoch 27/100\n23/23 [==============================] - 10s 453ms/step - loss: 0.1862 - accuracy: 0.9440 - val_loss: 0.1717 - val_accuracy: 0.9439\nEpoch 28/100\n23/23 [==============================] - 10s 419ms/step - loss: 0.1805 - accuracy: 0.9430 - val_loss: 0.1641 - val_accuracy: 0.9439\nEpoch 29/100\n23/23 [==============================] - 10s 421ms/step - loss: 0.1784 - accuracy: 0.9428 - val_loss: 0.1593 - val_accuracy: 0.9443\nEpoch 30/100\n23/23 [==============================] - 10s 455ms/step - loss: 0.1774 - accuracy: 0.9452 - val_loss: 0.1582 - val_accuracy: 0.9455\nEpoch 31/100\n23/23 [==============================] - 10s 429ms/step - loss: 0.1785 - accuracy: 0.9445 - val_loss: 0.1613 - val_accuracy: 0.9447\nEpoch 32/100\n23/23 [==============================] - 10s 419ms/step - loss: 0.1779 - accuracy: 0.9444 - val_loss: 0.1585 - val_accuracy: 0.9463\nEpoch 33/100\n23/23 [==============================] - 10s 453ms/step - loss: 0.1792 - accuracy: 0.9451 - val_loss: 0.1607 - val_accuracy: 0.9443\nEpoch 34/100\n23/23 [==============================] - 10s 425ms/step - loss: 0.1741 - accuracy: 0.9435 - val_loss: 0.1595 - val_accuracy: 0.9443\nEpoch 35/100\n23/23 [==============================] - 10s 425ms/step - loss: 0.1723 - accuracy: 0.9435 - val_loss: 0.1536 - val_accuracy: 0.9467\nEpoch 36/100\n23/23 [==============================] - 10s 448ms/step - loss: 0.1758 - accuracy: 0.9438 - val_loss: 0.1564 - val_accuracy: 0.9451\nEpoch 37/100\n23/23 [==============================] - 10s 429ms/step - loss: 0.1737 - accuracy: 0.9433 - val_loss: 0.1646 - val_accuracy: 0.9447\nEpoch 38/100\n23/23 [==============================] - 10s 417ms/step - loss: 0.1762 - accuracy: 0.9437 - val_loss: 0.1555 - val_accuracy: 0.9455\nEpoch 39/100\n23/23 [==============================] - 9s 404ms/step - loss: 0.1713 - accuracy: 0.9447 - val_loss: 0.1574 - val_accuracy: 0.9467\nEpoch 40/100\n23/23 [==============================] - 10s 451ms/step - loss: 0.1755 - accuracy: 0.9424 - val_loss: 0.1602 - val_accuracy: 0.9447\nEpoch 41/100\n23/23 [==============================] - 10s 423ms/step - loss: 0.1756 - accuracy: 0.9437 - val_loss: 0.1585 - val_accuracy: 0.9455\nEpoch 42/100\n23/23 [==============================] - 10s 426ms/step - loss: 0.1740 - accuracy: 0.9449 - val_loss: 0.1554 - val_accuracy: 0.9463\nEpoch 43/100\n23/23 [==============================] - 11s 459ms/step - loss: 0.1771 - accuracy: 0.9440 - val_loss: 0.1498 - val_accuracy: 0.9463\nEpoch 44/100\n23/23 [==============================] - 10s 418ms/step - loss: 0.1700 - accuracy: 0.9449 - val_loss: 0.1515 - val_accuracy: 0.9463\nEpoch 45/100\n23/23 [==============================] - 10s 442ms/step - loss: 0.1713 - accuracy: 0.9444 - val_loss: 0.1523 - val_accuracy: 0.9463\nEpoch 46/100\n23/23 [==============================] - 10s 450ms/step - loss: 0.1705 - accuracy: 0.9449 - val_loss: 0.1544 - val_accuracy: 0.9459\nEpoch 47/100\n23/23 [==============================] - 10s 420ms/step - loss: 0.1702 - accuracy: 0.9431 - val_loss: 0.1595 - val_accuracy: 0.9451\nEpoch 48/100\n23/23 [==============================] - 10s 418ms/step - loss: 0.1712 - accuracy: 0.9451 - val_loss: 0.1547 - val_accuracy: 0.9455\nEpoch 49/100\n23/23 [==============================] - 10s 432ms/step - loss: 0.1666 - accuracy: 0.9466 - val_loss: 0.1566 - val_accuracy: 0.9455\nEpoch 50/100\n23/23 [==============================] - 10s 433ms/step - loss: 0.1715 - accuracy: 0.9456 - val_loss: 0.1524 - val_accuracy: 0.9459\nEpoch 51/100\n23/23 [==============================] - 10s 430ms/step - loss: 0.1668 - accuracy: 0.9437 - val_loss: 0.1597 - val_accuracy: 0.9463\nEpoch 52/100\n23/23 [==============================] - 10s 423ms/step - loss: 0.1672 - accuracy: 0.9470 - val_loss: 0.1566 - val_accuracy: 0.9467\nEpoch 53/100\n23/23 [==============================] - 11s 448ms/step - loss: 0.1680 - accuracy: 0.9442 - val_loss: 0.1629 - val_accuracy: 0.9471\nEpoch 54/100\n23/23 [==============================] - 10s 436ms/step - loss: 0.1652 - accuracy: 0.9452 - val_loss: 0.1548 - val_accuracy: 0.9467\nEpoch 55/100\n23/23 [==============================] - 10s 435ms/step - loss: 0.1627 - accuracy: 0.9444 - val_loss: 0.1541 - val_accuracy: 0.9463\nEpoch 56/100\n23/23 [==============================] - 11s 460ms/step - loss: 0.1650 - accuracy: 0.9459 - val_loss: 0.1603 - val_accuracy: 0.9455\nEpoch 57/100\n23/23 [==============================] - 10s 425ms/step - loss: 0.1635 - accuracy: 0.9454 - val_loss: 0.1553 - val_accuracy: 0.9475\nEpoch 58/100\n23/23 [==============================] - 10s 424ms/step - loss: 0.1632 - accuracy: 0.9454 - val_loss: 0.1567 - val_accuracy: 0.9459\nEpoch 59/100\n23/23 [==============================] - 11s 468ms/step - loss: 0.1637 - accuracy: 0.9458 - val_loss: 0.1545 - val_accuracy: 0.9475\nEpoch 60/100\n23/23 [==============================] - 9s 408ms/step - loss: 0.1616 - accuracy: 0.9456 - val_loss: 0.1526 - val_accuracy: 0.9463\nEpoch 61/100\n23/23 [==============================] - 10s 416ms/step - loss: 0.1552 - accuracy: 0.9466 - val_loss: 0.1573 - val_accuracy: 0.9467\nEpoch 62/100\n23/23 [==============================] - 11s 469ms/step - loss: 0.1692 - accuracy: 0.9447 - val_loss: 0.1529 - val_accuracy: 0.9459\nEpoch 63/100\n23/23 [==============================] - 10s 421ms/step - loss: 0.1606 - accuracy: 0.9463 - val_loss: 0.1532 - val_accuracy: 0.9463\nEpoch 64/100\n23/23 [==============================] - 10s 423ms/step - loss: 0.1656 - accuracy: 0.9466 - val_loss: 0.1546 - val_accuracy: 0.9467\nEpoch 65/100\n23/23 [==============================] - 10s 421ms/step - loss: 0.1636 - accuracy: 0.9447 - val_loss: 0.1531 - val_accuracy: 0.9459\nEpoch 66/100\n23/23 [==============================] - 10s 455ms/step - loss: 0.1581 - accuracy: 0.9487 - val_loss: 0.1592 - val_accuracy: 0.9459\nEpoch 67/100\n23/23 [==============================] - 10s 423ms/step - loss: 0.1650 - accuracy: 0.9475 - val_loss: 0.1576 - val_accuracy: 0.9459\nEpoch 68/100\n23/23 [==============================] - 10s 426ms/step - loss: 0.1577 - accuracy: 0.9473 - val_loss: 0.1525 - val_accuracy: 0.9467\nEpoch 69/100\n23/23 [==============================] - 10s 460ms/step - loss: 0.1600 - accuracy: 0.9449 - val_loss: 0.1566 - val_accuracy: 0.9459\nEpoch 70/100\n23/23 [==============================] - 9s 406ms/step - loss: 0.1611 - accuracy: 0.9449 - val_loss: 0.1566 - val_accuracy: 0.9467\nEpoch 71/100\n23/23 [==============================] - 10s 401ms/step - loss: 0.1614 - accuracy: 0.9451 - val_loss: 0.1576 - val_accuracy: 0.9467\nEpoch 72/100\n23/23 [==============================] - 10s 458ms/step - loss: 0.1657 - accuracy: 0.9449 - val_loss: 0.1618 - val_accuracy: 0.9463\nEpoch 73/100\n23/23 [==============================] - 10s 418ms/step - loss: 0.1583 - accuracy: 0.9475 - val_loss: 0.1539 - val_accuracy: 0.9443\nEpoch 74/100\n23/23 [==============================] - 10s 432ms/step - loss: 0.1594 - accuracy: 0.9438 - val_loss: 0.1539 - val_accuracy: 0.9463\nEpoch 75/100\n23/23 [==============================] - 10s 427ms/step - loss: 0.1600 - accuracy: 0.9466 - val_loss: 0.1588 - val_accuracy: 0.9455\nEpoch 76/100\n23/23 [==============================] - 11s 443ms/step - loss: 0.1606 - accuracy: 0.9452 - val_loss: 0.1562 - val_accuracy: 0.9459\nEpoch 77/100\n23/23 [==============================] - 10s 419ms/step - loss: 0.1598 - accuracy: 0.9475 - val_loss: 0.1546 - val_accuracy: 0.9463\nEpoch 78/100\n23/23 [==============================] - 10s 428ms/step - loss: 0.1564 - accuracy: 0.9468 - val_loss: 0.1539 - val_accuracy: 0.9479\nEpoch 79/100\n23/23 [==============================] - 10s 453ms/step - loss: 0.1592 - accuracy: 0.9487 - val_loss: 0.1536 - val_accuracy: 0.9463\nEpoch 80/100\n23/23 [==============================] - 9s 400ms/step - loss: 0.1499 - accuracy: 0.9482 - val_loss: 0.1563 - val_accuracy: 0.9463\nEpoch 81/100\n23/23 [==============================] - 10s 418ms/step - loss: 0.1541 - accuracy: 0.9494 - val_loss: 0.1548 - val_accuracy: 0.9443\nEpoch 82/100\n23/23 [==============================] - 10s 448ms/step - loss: 0.1571 - accuracy: 0.9478 - val_loss: 0.1552 - val_accuracy: 0.9467\nEpoch 83/100\n23/23 [==============================] - 10s 420ms/step - loss: 0.1552 - accuracy: 0.9470 - val_loss: 0.1551 - val_accuracy: 0.9463\nEpoch 84/100\n23/23 [==============================] - 10s 417ms/step - loss: 0.1580 - accuracy: 0.9461 - val_loss: 0.1519 - val_accuracy: 0.9467\nEpoch 85/100\n23/23 [==============================] - 10s 417ms/step - loss: 0.1514 - accuracy: 0.9499 - val_loss: 0.1537 - val_accuracy: 0.9475\nEpoch 86/100\n23/23 [==============================] - 10s 459ms/step - loss: 0.1517 - accuracy: 0.9480 - val_loss: 0.1527 - val_accuracy: 0.9475\nEpoch 87/100\n23/23 [==============================] - 10s 434ms/step - loss: 0.1614 - accuracy: 0.9478 - val_loss: 0.1628 - val_accuracy: 0.9463\nEpoch 88/100\n23/23 [==============================] - 10s 430ms/step - loss: 0.1543 - accuracy: 0.9491 - val_loss: 0.1519 - val_accuracy: 0.9459\nEpoch 89/100\n23/23 [==============================] - 10s 450ms/step - loss: 0.1555 - accuracy: 0.9456 - val_loss: 0.1518 - val_accuracy: 0.9439\nEpoch 90/100\n23/23 [==============================] - 9s 399ms/step - loss: 0.1529 - accuracy: 0.9458 - val_loss: 0.1514 - val_accuracy: 0.9434\nEpoch 91/100\n23/23 [==============================] - 10s 420ms/step - loss: 0.1559 - accuracy: 0.9471 - val_loss: 0.1565 - val_accuracy: 0.9459\nEpoch 92/100\n23/23 [==============================] - 11s 463ms/step - loss: 0.1503 - accuracy: 0.9494 - val_loss: 0.1544 - val_accuracy: 0.9463\nEpoch 93/100\n23/23 [==============================] - 10s 430ms/step - loss: 0.1488 - accuracy: 0.9508 - val_loss: 0.1615 - val_accuracy: 0.9467\nEpoch 94/100\n23/23 [==============================] - 10s 429ms/step - loss: 0.1464 - accuracy: 0.9499 - val_loss: 0.1551 - val_accuracy: 0.9463\nEpoch 95/100\n23/23 [==============================] - 10s 427ms/step - loss: 0.1484 - accuracy: 0.9485 - val_loss: 0.1571 - val_accuracy: 0.9467\nEpoch 96/100\n23/23 [==============================] - 10s 447ms/step - loss: 0.1511 - accuracy: 0.9501 - val_loss: 0.1558 - val_accuracy: 0.9455\nEpoch 97/100\n23/23 [==============================] - 10s 421ms/step - loss: 0.1487 - accuracy: 0.9468 - val_loss: 0.1611 - val_accuracy: 0.9463\nEpoch 98/100\n23/23 [==============================] - 10s 417ms/step - loss: 0.1451 - accuracy: 0.9510 - val_loss: 0.1569 - val_accuracy: 0.9483\nEpoch 99/100\n23/23 [==============================] - 10s 447ms/step - loss: 0.1512 - accuracy: 0.9478 - val_loss: 0.1566 - val_accuracy: 0.9467\nEpoch 100/100\n23/23 [==============================] - 9s 402ms/step - loss: 0.1520 - accuracy: 0.9468 - val_loss: 0.1613 - val_accuracy: 0.9463\n","output_type":"stream"}]},{"cell_type":"code","source":"test_res=(model.predict(X_test) > 0.5).astype(\"int32\")\ntest_res=test_res.flatten()\ny_test_c = y_test.to_numpy()","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:25:04.654510Z","iopub.execute_input":"2022-04-06T14:25:04.654773Z","iopub.status.idle":"2022-04-06T14:25:06.833659Z","shell.execute_reply.started":"2022-04-06T14:25:04.654722Z","shell.execute_reply":"2022-04-06T14:25:06.832928Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"count=0\nfor i in range(0,len(y_test_c)):\n  if(y_test_c[i]==test_res[i]):\n    count=count+1\nprint(count)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:25:06.834852Z","iopub.execute_input":"2022-04-06T14:25:06.836774Z","iopub.status.idle":"2022-04-06T14:25:06.845466Z","shell.execute_reply.started":"2022-04-06T14:25:06.836722Z","shell.execute_reply":"2022-04-06T14:25:06.844779Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"1698\n","output_type":"stream"}]},{"cell_type":"code","source":"accuracy_5_bs_256_labled=(count/len(test_res))*100","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:25:06.852188Z","iopub.execute_input":"2022-04-06T14:25:06.852375Z","iopub.status.idle":"2022-04-06T14:25:06.856461Z","shell.execute_reply.started":"2022-04-06T14:25:06.852353Z","shell.execute_reply":"2022-04-06T14:25:06.855443Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"print(\"Accuracy at 5% labled data and bs 256\",accuracy_5_bs_256_labled)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:25:06.858035Z","iopub.execute_input":"2022-04-06T14:25:06.858345Z","iopub.status.idle":"2022-04-06T14:25:06.866177Z","shell.execute_reply.started":"2022-04-06T14:25:06.858309Z","shell.execute_reply":"2022-04-06T14:25:06.865187Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"Accuracy at 5% labled data and bs 256 82.91015625\n","output_type":"stream"}]},{"cell_type":"code","source":"print(classification_report(y_test,test_res, target_names = ['Fake','Real']))","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:25:06.867369Z","iopub.execute_input":"2022-04-06T14:25:06.867700Z","iopub.status.idle":"2022-04-06T14:25:06.883591Z","shell.execute_reply.started":"2022-04-06T14:25:06.867667Z","shell.execute_reply":"2022-04-06T14:25:06.882964Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n        Fake       0.83      1.00      0.91      1701\n        Real       0.33      0.01      0.02       347\n\n    accuracy                           0.83      2048\n   macro avg       0.58      0.50      0.46      2048\nweighted avg       0.75      0.83      0.76      2048\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Training Model when 5% labled data and bs=512**","metadata":{}},{"cell_type":"code","source":"X_train1, X_test, y_train1, y_test = train_test_split(data['text'], data['label'],test_size=0.2 ,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:25:06.884654Z","iopub.execute_input":"2022-04-06T14:25:06.884922Z","iopub.status.idle":"2022-04-06T14:25:06.893200Z","shell.execute_reply.started":"2022-04-06T14:25:06.884888Z","shell.execute_reply":"2022-04-06T14:25:06.892501Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"X_lvl, X_unl, y_lvl, y_unl = train_test_split(X_train1,y_train1,test_size=0.95,random_state=0)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:25:06.894477Z","iopub.execute_input":"2022-04-06T14:25:06.894957Z","iopub.status.idle":"2022-04-06T14:25:06.901707Z","shell.execute_reply.started":"2022-04-06T14:25:06.894921Z","shell.execute_reply":"2022-04-06T14:25:06.901068Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"max_features = 3000\nmaxlen = 50","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:25:06.903633Z","iopub.execute_input":"2022-04-06T14:25:06.904353Z","iopub.status.idle":"2022-04-06T14:25:06.907972Z","shell.execute_reply.started":"2022-04-06T14:25:06.904318Z","shell.execute_reply":"2022-04-06T14:25:06.907249Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"tokenizer = text.Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(X_lvl)\ntokenized_train = tokenizer.texts_to_sequences(X_lvl)\nX_lvl = sequence.pad_sequences(tokenized_train, maxlen=maxlen)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:25:06.909112Z","iopub.execute_input":"2022-04-06T14:25:06.909834Z","iopub.status.idle":"2022-04-06T14:25:06.938519Z","shell.execute_reply.started":"2022-04-06T14:25:06.909798Z","shell.execute_reply":"2022-04-06T14:25:06.937833Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"tokenized_test = tokenizer.texts_to_sequences(X_test)\nX_test = sequence.pad_sequences(tokenized_test, maxlen=maxlen)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:25:06.939621Z","iopub.execute_input":"2022-04-06T14:25:06.940253Z","iopub.status.idle":"2022-04-06T14:25:06.990322Z","shell.execute_reply.started":"2022-04-06T14:25:06.940218Z","shell.execute_reply":"2022-04-06T14:25:06.989708Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"tokenized_unl = tokenizer.texts_to_sequences(X_unl)\nX_unl = sequence.pad_sequences(tokenized_unl, maxlen=maxlen)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:25:06.992566Z","iopub.execute_input":"2022-04-06T14:25:06.992840Z","iopub.status.idle":"2022-04-06T14:25:07.153562Z","shell.execute_reply.started":"2022-04-06T14:25:06.992809Z","shell.execute_reply":"2022-04-06T14:25:07.152945Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"batch_size = 512","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:25:07.154689Z","iopub.execute_input":"2022-04-06T14:25:07.154936Z","iopub.status.idle":"2022-04-06T14:25:07.158961Z","shell.execute_reply.started":"2022-04-06T14:25:07.154906Z","shell.execute_reply":"2022-04-06T14:25:07.157517Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras import regularizers\n\ndef build_model():\n  model = Sequential()\n  hp_units = 160\n  model.add(Embedding(max_features, output_dim=100, input_length=maxlen, trainable=False))\n  model.add(LSTM(units=hp_units, return_sequences = True , recurrent_dropout =0.5,dropout=0.5))\n  model.add(LSTM(units=hp_units , recurrent_dropout = 0.5 , dropout = 0.5))\n  model.add(Dense(units=hp_units , activation = 'relu'))\n  model.add(Dense(1, activation='sigmoid'))\n  hp_learning_rate = .001\n  model.compile(tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),loss='binary_crossentropy', metrics=['accuracy'])\n  return model\n","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:25:07.160296Z","iopub.execute_input":"2022-04-06T14:25:07.160779Z","iopub.status.idle":"2022-04-06T14:25:07.169027Z","shell.execute_reply.started":"2022-04-06T14:25:07.160744Z","shell.execute_reply":"2022-04-06T14:25:07.168365Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"model = build_model()","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:25:07.170237Z","iopub.execute_input":"2022-04-06T14:25:07.170667Z","iopub.status.idle":"2022-04-06T14:25:07.395204Z","shell.execute_reply.started":"2022-04-06T14:25:07.170633Z","shell.execute_reply":"2022-04-06T14:25:07.394569Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:25:07.396177Z","iopub.execute_input":"2022-04-06T14:25:07.396395Z","iopub.status.idle":"2022-04-06T14:25:07.407256Z","shell.execute_reply.started":"2022-04-06T14:25:07.396364Z","shell.execute_reply":"2022-04-06T14:25:07.406391Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stdout","text":"Model: \"sequential_6\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_6 (Embedding)      (None, 50, 100)           300000    \n_________________________________________________________________\nlstm_12 (LSTM)               (None, 50, 160)           167040    \n_________________________________________________________________\nlstm_13 (LSTM)               (None, 160)               205440    \n_________________________________________________________________\ndense_12 (Dense)             (None, 160)               25760     \n_________________________________________________________________\ndense_13 (Dense)             (None, 1)                 161       \n=================================================================\nTotal params: 698,401\nTrainable params: 398,401\nNon-trainable params: 300,000\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"history = model.fit(X_lvl, y_lvl, validation_split=0.3, epochs=300, batch_size=batch_size, shuffle=True, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:25:07.408217Z","iopub.execute_input":"2022-04-06T14:25:07.408859Z","iopub.status.idle":"2022-04-06T14:27:33.693973Z","shell.execute_reply.started":"2022-04-06T14:25:07.408823Z","shell.execute_reply":"2022-04-06T14:27:33.693284Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"Epoch 1/300\n1/1 [==============================] - 4s 4s/step - loss: 0.6937 - accuracy: 0.4091 - val_loss: 0.6826 - val_accuracy: 0.8862\nEpoch 2/300\n1/1 [==============================] - 0s 438ms/step - loss: 0.6841 - accuracy: 0.8182 - val_loss: 0.6654 - val_accuracy: 0.8862\nEpoch 3/300\n1/1 [==============================] - 0s 493ms/step - loss: 0.6700 - accuracy: 0.8182 - val_loss: 0.6336 - val_accuracy: 0.8862\nEpoch 4/300\n1/1 [==============================] - 0s 417ms/step - loss: 0.6438 - accuracy: 0.8182 - val_loss: 0.5701 - val_accuracy: 0.8862\nEpoch 5/300\n1/1 [==============================] - 0s 423ms/step - loss: 0.5927 - accuracy: 0.8182 - val_loss: 0.4496 - val_accuracy: 0.8862\nEpoch 6/300\n1/1 [==============================] - 0s 431ms/step - loss: 0.5112 - accuracy: 0.8182 - val_loss: 0.3763 - val_accuracy: 0.8862\nEpoch 7/300\n1/1 [==============================] - 0s 452ms/step - loss: 0.5355 - accuracy: 0.8182 - val_loss: 0.3669 - val_accuracy: 0.8862\nEpoch 8/300\n1/1 [==============================] - 0s 412ms/step - loss: 0.5144 - accuracy: 0.8182 - val_loss: 0.3756 - val_accuracy: 0.8862\nEpoch 9/300\n1/1 [==============================] - 0s 434ms/step - loss: 0.4834 - accuracy: 0.8182 - val_loss: 0.4098 - val_accuracy: 0.8862\nEpoch 10/300\n1/1 [==============================] - 0s 435ms/step - loss: 0.4889 - accuracy: 0.8182 - val_loss: 0.4302 - val_accuracy: 0.8862\nEpoch 11/300\n1/1 [==============================] - 1s 532ms/step - loss: 0.4977 - accuracy: 0.8182 - val_loss: 0.4300 - val_accuracy: 0.8862\nEpoch 12/300\n1/1 [==============================] - 1s 700ms/step - loss: 0.5000 - accuracy: 0.8182 - val_loss: 0.4157 - val_accuracy: 0.8862\nEpoch 13/300\n1/1 [==============================] - 0s 454ms/step - loss: 0.4884 - accuracy: 0.8182 - val_loss: 0.3943 - val_accuracy: 0.8862\nEpoch 14/300\n1/1 [==============================] - 0s 456ms/step - loss: 0.4814 - accuracy: 0.8182 - val_loss: 0.3748 - val_accuracy: 0.8862\nEpoch 15/300\n1/1 [==============================] - 0s 483ms/step - loss: 0.4764 - accuracy: 0.8182 - val_loss: 0.3635 - val_accuracy: 0.8862\nEpoch 16/300\n1/1 [==============================] - 0s 457ms/step - loss: 0.4863 - accuracy: 0.8182 - val_loss: 0.3599 - val_accuracy: 0.8862\nEpoch 17/300\n1/1 [==============================] - 0s 457ms/step - loss: 0.4830 - accuracy: 0.8182 - val_loss: 0.3594 - val_accuracy: 0.8862\nEpoch 18/300\n1/1 [==============================] - 0s 442ms/step - loss: 0.4870 - accuracy: 0.8182 - val_loss: 0.3615 - val_accuracy: 0.8862\nEpoch 19/300\n1/1 [==============================] - 0s 483ms/step - loss: 0.4823 - accuracy: 0.8182 - val_loss: 0.3672 - val_accuracy: 0.8862\nEpoch 20/300\n1/1 [==============================] - 0s 469ms/step - loss: 0.4777 - accuracy: 0.8182 - val_loss: 0.3759 - val_accuracy: 0.8862\nEpoch 21/300\n1/1 [==============================] - 0s 434ms/step - loss: 0.4736 - accuracy: 0.8182 - val_loss: 0.3846 - val_accuracy: 0.8862\nEpoch 22/300\n1/1 [==============================] - 0s 452ms/step - loss: 0.4789 - accuracy: 0.8182 - val_loss: 0.3904 - val_accuracy: 0.8862\nEpoch 23/300\n1/1 [==============================] - 0s 406ms/step - loss: 0.4791 - accuracy: 0.8182 - val_loss: 0.3915 - val_accuracy: 0.8862\nEpoch 24/300\n1/1 [==============================] - 0s 458ms/step - loss: 0.4772 - accuracy: 0.8182 - val_loss: 0.3879 - val_accuracy: 0.8862\nEpoch 25/300\n1/1 [==============================] - 1s 859ms/step - loss: 0.4786 - accuracy: 0.8182 - val_loss: 0.3815 - val_accuracy: 0.8862\nEpoch 26/300\n1/1 [==============================] - 1s 667ms/step - loss: 0.4781 - accuracy: 0.8182 - val_loss: 0.3744 - val_accuracy: 0.8862\nEpoch 27/300\n1/1 [==============================] - 0s 420ms/step - loss: 0.4744 - accuracy: 0.8182 - val_loss: 0.3682 - val_accuracy: 0.8862\nEpoch 28/300\n1/1 [==============================] - 0s 457ms/step - loss: 0.4739 - accuracy: 0.8182 - val_loss: 0.3639 - val_accuracy: 0.8862\nEpoch 29/300\n1/1 [==============================] - 0s 425ms/step - loss: 0.4746 - accuracy: 0.8182 - val_loss: 0.3617 - val_accuracy: 0.8862\nEpoch 30/300\n1/1 [==============================] - 0s 472ms/step - loss: 0.4732 - accuracy: 0.8182 - val_loss: 0.3613 - val_accuracy: 0.8862\nEpoch 31/300\n1/1 [==============================] - 0s 457ms/step - loss: 0.4772 - accuracy: 0.8182 - val_loss: 0.3625 - val_accuracy: 0.8862\nEpoch 32/300\n1/1 [==============================] - 0s 454ms/step - loss: 0.4727 - accuracy: 0.8182 - val_loss: 0.3651 - val_accuracy: 0.8862\nEpoch 33/300\n1/1 [==============================] - 1s 533ms/step - loss: 0.4738 - accuracy: 0.8182 - val_loss: 0.3687 - val_accuracy: 0.8862\nEpoch 34/300\n1/1 [==============================] - 1s 735ms/step - loss: 0.4736 - accuracy: 0.8182 - val_loss: 0.3729 - val_accuracy: 0.8862\nEpoch 35/300\n1/1 [==============================] - 0s 449ms/step - loss: 0.4740 - accuracy: 0.8182 - val_loss: 0.3765 - val_accuracy: 0.8862\nEpoch 36/300\n1/1 [==============================] - 0s 473ms/step - loss: 0.4720 - accuracy: 0.8182 - val_loss: 0.3783 - val_accuracy: 0.8862\nEpoch 37/300\n1/1 [==============================] - 0s 437ms/step - loss: 0.4752 - accuracy: 0.8182 - val_loss: 0.3778 - val_accuracy: 0.8862\nEpoch 38/300\n1/1 [==============================] - 0s 458ms/step - loss: 0.4715 - accuracy: 0.8182 - val_loss: 0.3751 - val_accuracy: 0.8862\nEpoch 39/300\n1/1 [==============================] - 0s 420ms/step - loss: 0.4726 - accuracy: 0.8182 - val_loss: 0.3710 - val_accuracy: 0.8862\nEpoch 40/300\n1/1 [==============================] - 0s 419ms/step - loss: 0.4704 - accuracy: 0.8182 - val_loss: 0.3668 - val_accuracy: 0.8862\nEpoch 41/300\n1/1 [==============================] - 0s 409ms/step - loss: 0.4711 - accuracy: 0.8182 - val_loss: 0.3636 - val_accuracy: 0.8862\nEpoch 42/300\n1/1 [==============================] - 0s 457ms/step - loss: 0.4722 - accuracy: 0.8182 - val_loss: 0.3618 - val_accuracy: 0.8862\nEpoch 43/300\n1/1 [==============================] - 0s 411ms/step - loss: 0.4739 - accuracy: 0.8182 - val_loss: 0.3619 - val_accuracy: 0.8862\nEpoch 44/300\n1/1 [==============================] - 0s 438ms/step - loss: 0.4711 - accuracy: 0.8182 - val_loss: 0.3636 - val_accuracy: 0.8862\nEpoch 45/300\n1/1 [==============================] - 1s 507ms/step - loss: 0.4699 - accuracy: 0.8182 - val_loss: 0.3670 - val_accuracy: 0.8862\nEpoch 46/300\n1/1 [==============================] - 0s 421ms/step - loss: 0.4670 - accuracy: 0.8182 - val_loss: 0.3720 - val_accuracy: 0.8862\nEpoch 47/300\n1/1 [==============================] - 0s 429ms/step - loss: 0.4700 - accuracy: 0.8182 - val_loss: 0.3745 - val_accuracy: 0.8862\nEpoch 48/300\n1/1 [==============================] - 0s 428ms/step - loss: 0.4717 - accuracy: 0.8182 - val_loss: 0.3675 - val_accuracy: 0.8862\nEpoch 49/300\n1/1 [==============================] - 0s 415ms/step - loss: 0.4652 - accuracy: 0.8182 - val_loss: 0.3609 - val_accuracy: 0.8862\nEpoch 50/300\n1/1 [==============================] - 0s 429ms/step - loss: 0.4683 - accuracy: 0.8182 - val_loss: 0.3571 - val_accuracy: 0.8862\nEpoch 51/300\n1/1 [==============================] - 0s 444ms/step - loss: 0.4704 - accuracy: 0.8182 - val_loss: 0.3602 - val_accuracy: 0.8862\nEpoch 52/300\n1/1 [==============================] - 0s 448ms/step - loss: 0.4673 - accuracy: 0.8182 - val_loss: 0.3672 - val_accuracy: 0.8862\nEpoch 53/300\n1/1 [==============================] - 0s 443ms/step - loss: 0.4691 - accuracy: 0.8182 - val_loss: 0.3618 - val_accuracy: 0.8862\nEpoch 54/300\n1/1 [==============================] - 0s 434ms/step - loss: 0.4709 - accuracy: 0.8182 - val_loss: 0.3552 - val_accuracy: 0.8862\nEpoch 55/300\n1/1 [==============================] - 0s 471ms/step - loss: 0.4657 - accuracy: 0.8182 - val_loss: 0.3572 - val_accuracy: 0.8862\nEpoch 56/300\n1/1 [==============================] - 0s 445ms/step - loss: 0.4595 - accuracy: 0.8182 - val_loss: 0.3662 - val_accuracy: 0.8862\nEpoch 57/300\n1/1 [==============================] - 1s 569ms/step - loss: 0.4618 - accuracy: 0.8182 - val_loss: 0.3646 - val_accuracy: 0.8862\nEpoch 58/300\n1/1 [==============================] - 1s 715ms/step - loss: 0.4674 - accuracy: 0.8182 - val_loss: 0.3548 - val_accuracy: 0.8862\nEpoch 59/300\n1/1 [==============================] - 0s 496ms/step - loss: 0.4645 - accuracy: 0.8182 - val_loss: 0.3564 - val_accuracy: 0.8862\nEpoch 60/300\n1/1 [==============================] - 0s 437ms/step - loss: 0.4648 - accuracy: 0.8182 - val_loss: 0.3718 - val_accuracy: 0.8862\nEpoch 61/300\n1/1 [==============================] - 0s 437ms/step - loss: 0.4622 - accuracy: 0.8182 - val_loss: 0.3567 - val_accuracy: 0.8862\nEpoch 62/300\n1/1 [==============================] - 0s 435ms/step - loss: 0.4727 - accuracy: 0.8182 - val_loss: 0.3530 - val_accuracy: 0.8862\nEpoch 63/300\n1/1 [==============================] - 0s 435ms/step - loss: 0.4629 - accuracy: 0.8182 - val_loss: 0.3654 - val_accuracy: 0.8862\nEpoch 64/300\n1/1 [==============================] - 0s 435ms/step - loss: 0.4515 - accuracy: 0.8182 - val_loss: 0.3819 - val_accuracy: 0.8862\nEpoch 65/300\n1/1 [==============================] - 0s 460ms/step - loss: 0.4631 - accuracy: 0.8182 - val_loss: 0.3591 - val_accuracy: 0.8862\nEpoch 66/300\n1/1 [==============================] - 0s 415ms/step - loss: 0.4625 - accuracy: 0.8182 - val_loss: 0.3506 - val_accuracy: 0.8862\nEpoch 67/300\n1/1 [==============================] - 0s 464ms/step - loss: 0.4616 - accuracy: 0.8182 - val_loss: 0.3639 - val_accuracy: 0.8862\nEpoch 68/300\n1/1 [==============================] - 0s 425ms/step - loss: 0.4521 - accuracy: 0.8182 - val_loss: 0.3772 - val_accuracy: 0.8862\nEpoch 69/300\n1/1 [==============================] - 0s 447ms/step - loss: 0.4622 - accuracy: 0.8182 - val_loss: 0.3669 - val_accuracy: 0.8862\nEpoch 70/300\n1/1 [==============================] - 0s 462ms/step - loss: 0.4589 - accuracy: 0.8182 - val_loss: 0.3524 - val_accuracy: 0.8862\nEpoch 71/300\n1/1 [==============================] - 0s 430ms/step - loss: 0.4617 - accuracy: 0.8182 - val_loss: 0.3551 - val_accuracy: 0.8862\nEpoch 72/300\n1/1 [==============================] - 0s 464ms/step - loss: 0.4549 - accuracy: 0.8182 - val_loss: 0.3729 - val_accuracy: 0.8862\nEpoch 73/300\n1/1 [==============================] - 0s 423ms/step - loss: 0.4464 - accuracy: 0.8182 - val_loss: 0.3780 - val_accuracy: 0.8862\nEpoch 74/300\n1/1 [==============================] - 0s 435ms/step - loss: 0.4528 - accuracy: 0.8182 - val_loss: 0.3620 - val_accuracy: 0.8862\nEpoch 75/300\n1/1 [==============================] - 0s 468ms/step - loss: 0.4452 - accuracy: 0.8182 - val_loss: 0.3498 - val_accuracy: 0.8862\nEpoch 76/300\n1/1 [==============================] - 0s 409ms/step - loss: 0.4494 - accuracy: 0.8182 - val_loss: 0.3611 - val_accuracy: 0.8862\nEpoch 77/300\n1/1 [==============================] - 0s 405ms/step - loss: 0.4449 - accuracy: 0.8182 - val_loss: 0.3764 - val_accuracy: 0.8862\nEpoch 78/300\n1/1 [==============================] - 0s 435ms/step - loss: 0.4579 - accuracy: 0.8182 - val_loss: 0.3593 - val_accuracy: 0.8862\nEpoch 79/300\n1/1 [==============================] - 0s 413ms/step - loss: 0.4478 - accuracy: 0.8182 - val_loss: 0.3463 - val_accuracy: 0.8862\nEpoch 80/300\n1/1 [==============================] - 0s 447ms/step - loss: 0.4490 - accuracy: 0.8182 - val_loss: 0.3734 - val_accuracy: 0.8862\nEpoch 81/300\n1/1 [==============================] - 1s 533ms/step - loss: 0.4391 - accuracy: 0.8182 - val_loss: 0.3717 - val_accuracy: 0.8862\nEpoch 82/300\n1/1 [==============================] - 1s 761ms/step - loss: 0.4391 - accuracy: 0.8182 - val_loss: 0.3458 - val_accuracy: 0.8862\nEpoch 83/300\n1/1 [==============================] - 0s 425ms/step - loss: 0.4444 - accuracy: 0.8182 - val_loss: 0.3562 - val_accuracy: 0.8862\nEpoch 84/300\n1/1 [==============================] - 0s 439ms/step - loss: 0.4408 - accuracy: 0.8182 - val_loss: 0.3757 - val_accuracy: 0.8862\nEpoch 85/300\n1/1 [==============================] - 0s 441ms/step - loss: 0.4489 - accuracy: 0.8217 - val_loss: 0.3645 - val_accuracy: 0.8862\nEpoch 86/300\n1/1 [==============================] - 0s 423ms/step - loss: 0.4440 - accuracy: 0.8182 - val_loss: 0.3505 - val_accuracy: 0.8862\nEpoch 87/300\n1/1 [==============================] - 0s 463ms/step - loss: 0.4361 - accuracy: 0.8182 - val_loss: 0.3500 - val_accuracy: 0.8862\nEpoch 88/300\n1/1 [==============================] - 0s 442ms/step - loss: 0.4393 - accuracy: 0.8182 - val_loss: 0.3640 - val_accuracy: 0.8862\nEpoch 89/300\n1/1 [==============================] - 0s 432ms/step - loss: 0.4203 - accuracy: 0.8182 - val_loss: 0.3635 - val_accuracy: 0.8862\nEpoch 90/300\n1/1 [==============================] - 0s 441ms/step - loss: 0.4316 - accuracy: 0.8182 - val_loss: 0.3524 - val_accuracy: 0.8862\nEpoch 91/300\n1/1 [==============================] - 0s 423ms/step - loss: 0.4170 - accuracy: 0.8182 - val_loss: 0.3518 - val_accuracy: 0.8862\nEpoch 92/300\n1/1 [==============================] - 0s 434ms/step - loss: 0.4264 - accuracy: 0.8182 - val_loss: 0.3782 - val_accuracy: 0.8862\nEpoch 93/300\n1/1 [==============================] - 1s 534ms/step - loss: 0.4093 - accuracy: 0.8252 - val_loss: 0.3517 - val_accuracy: 0.8862\nEpoch 94/300\n1/1 [==============================] - 1s 943ms/step - loss: 0.4356 - accuracy: 0.8182 - val_loss: 0.3985 - val_accuracy: 0.8862\nEpoch 95/300\n1/1 [==============================] - 0s 495ms/step - loss: 0.4171 - accuracy: 0.8147 - val_loss: 0.3606 - val_accuracy: 0.8862\nEpoch 96/300\n1/1 [==============================] - 0s 431ms/step - loss: 0.4160 - accuracy: 0.8322 - val_loss: 0.3469 - val_accuracy: 0.8862\nEpoch 97/300\n1/1 [==============================] - 0s 430ms/step - loss: 0.4591 - accuracy: 0.8182 - val_loss: 0.3506 - val_accuracy: 0.8862\nEpoch 98/300\n1/1 [==============================] - 0s 442ms/step - loss: 0.4168 - accuracy: 0.8182 - val_loss: 0.3784 - val_accuracy: 0.8862\nEpoch 99/300\n1/1 [==============================] - 0s 427ms/step - loss: 0.4372 - accuracy: 0.8112 - val_loss: 0.3934 - val_accuracy: 0.8862\nEpoch 100/300\n1/1 [==============================] - 0s 452ms/step - loss: 0.4353 - accuracy: 0.8252 - val_loss: 0.3776 - val_accuracy: 0.8862\nEpoch 101/300\n1/1 [==============================] - 0s 460ms/step - loss: 0.4318 - accuracy: 0.8182 - val_loss: 0.3558 - val_accuracy: 0.8862\nEpoch 102/300\n1/1 [==============================] - 0s 435ms/step - loss: 0.4038 - accuracy: 0.8217 - val_loss: 0.3444 - val_accuracy: 0.8862\nEpoch 103/300\n1/1 [==============================] - 0s 455ms/step - loss: 0.4412 - accuracy: 0.8182 - val_loss: 0.3455 - val_accuracy: 0.8862\nEpoch 104/300\n1/1 [==============================] - 1s 770ms/step - loss: 0.4237 - accuracy: 0.8217 - val_loss: 0.3548 - val_accuracy: 0.8862\nEpoch 105/300\n1/1 [==============================] - 1s 506ms/step - loss: 0.4390 - accuracy: 0.8217 - val_loss: 0.3761 - val_accuracy: 0.8862\nEpoch 106/300\n1/1 [==============================] - 0s 419ms/step - loss: 0.4122 - accuracy: 0.8252 - val_loss: 0.3856 - val_accuracy: 0.8862\nEpoch 107/300\n1/1 [==============================] - 0s 478ms/step - loss: 0.4212 - accuracy: 0.8287 - val_loss: 0.3682 - val_accuracy: 0.8862\nEpoch 108/300\n1/1 [==============================] - 0s 453ms/step - loss: 0.4274 - accuracy: 0.8182 - val_loss: 0.3510 - val_accuracy: 0.8862\nEpoch 109/300\n1/1 [==============================] - 0s 476ms/step - loss: 0.3860 - accuracy: 0.8287 - val_loss: 0.3484 - val_accuracy: 0.8862\nEpoch 110/300\n1/1 [==============================] - 0s 419ms/step - loss: 0.4180 - accuracy: 0.8287 - val_loss: 0.3526 - val_accuracy: 0.8862\nEpoch 111/300\n1/1 [==============================] - 0s 496ms/step - loss: 0.4161 - accuracy: 0.8357 - val_loss: 0.3729 - val_accuracy: 0.8862\nEpoch 112/300\n1/1 [==============================] - 0s 432ms/step - loss: 0.4080 - accuracy: 0.8147 - val_loss: 0.3886 - val_accuracy: 0.8862\nEpoch 113/300\n1/1 [==============================] - 0s 475ms/step - loss: 0.4195 - accuracy: 0.8427 - val_loss: 0.3730 - val_accuracy: 0.8862\nEpoch 114/300\n1/1 [==============================] - 0s 423ms/step - loss: 0.3953 - accuracy: 0.8287 - val_loss: 0.3565 - val_accuracy: 0.8862\nEpoch 115/300\n1/1 [==============================] - 0s 438ms/step - loss: 0.4043 - accuracy: 0.8252 - val_loss: 0.3538 - val_accuracy: 0.8862\nEpoch 116/300\n1/1 [==============================] - 0s 480ms/step - loss: 0.4273 - accuracy: 0.8217 - val_loss: 0.3613 - val_accuracy: 0.8862\nEpoch 117/300\n1/1 [==============================] - 0s 454ms/step - loss: 0.4088 - accuracy: 0.8322 - val_loss: 0.3726 - val_accuracy: 0.8862\nEpoch 118/300\n1/1 [==============================] - 0s 414ms/step - loss: 0.4104 - accuracy: 0.8217 - val_loss: 0.3788 - val_accuracy: 0.8862\nEpoch 119/300\n1/1 [==============================] - 0s 406ms/step - loss: 0.4213 - accuracy: 0.8252 - val_loss: 0.3679 - val_accuracy: 0.8862\nEpoch 120/300\n1/1 [==============================] - 0s 409ms/step - loss: 0.3963 - accuracy: 0.8287 - val_loss: 0.3496 - val_accuracy: 0.8862\nEpoch 121/300\n1/1 [==============================] - 0s 439ms/step - loss: 0.4124 - accuracy: 0.8182 - val_loss: 0.3443 - val_accuracy: 0.8862\nEpoch 122/300\n1/1 [==============================] - 0s 460ms/step - loss: 0.4137 - accuracy: 0.8252 - val_loss: 0.3465 - val_accuracy: 0.8862\nEpoch 123/300\n1/1 [==============================] - 0s 491ms/step - loss: 0.4183 - accuracy: 0.8182 - val_loss: 0.3640 - val_accuracy: 0.8862\nEpoch 124/300\n1/1 [==============================] - 0s 453ms/step - loss: 0.4102 - accuracy: 0.8252 - val_loss: 0.3875 - val_accuracy: 0.8699\nEpoch 125/300\n1/1 [==============================] - 0s 462ms/step - loss: 0.3905 - accuracy: 0.8462 - val_loss: 0.3597 - val_accuracy: 0.8862\nEpoch 126/300\n1/1 [==============================] - 0s 476ms/step - loss: 0.3830 - accuracy: 0.8322 - val_loss: 0.3498 - val_accuracy: 0.8862\nEpoch 127/300\n1/1 [==============================] - 1s 688ms/step - loss: 0.4119 - accuracy: 0.8287 - val_loss: 0.3565 - val_accuracy: 0.8862\nEpoch 128/300\n1/1 [==============================] - 1s 603ms/step - loss: 0.3967 - accuracy: 0.8252 - val_loss: 0.3713 - val_accuracy: 0.8862\nEpoch 129/300\n1/1 [==============================] - 0s 459ms/step - loss: 0.3799 - accuracy: 0.8252 - val_loss: 0.3767 - val_accuracy: 0.8862\nEpoch 130/300\n1/1 [==============================] - 0s 461ms/step - loss: 0.3816 - accuracy: 0.8322 - val_loss: 0.3618 - val_accuracy: 0.8862\nEpoch 131/300\n1/1 [==============================] - 0s 483ms/step - loss: 0.4166 - accuracy: 0.8392 - val_loss: 0.3671 - val_accuracy: 0.8862\nEpoch 132/300\n1/1 [==============================] - 0s 406ms/step - loss: 0.3895 - accuracy: 0.8357 - val_loss: 0.3636 - val_accuracy: 0.8862\nEpoch 133/300\n1/1 [==============================] - 0s 420ms/step - loss: 0.3899 - accuracy: 0.8357 - val_loss: 0.3565 - val_accuracy: 0.8862\nEpoch 134/300\n1/1 [==============================] - 0s 450ms/step - loss: 0.3933 - accuracy: 0.8357 - val_loss: 0.3489 - val_accuracy: 0.8862\nEpoch 135/300\n1/1 [==============================] - 0s 475ms/step - loss: 0.4042 - accuracy: 0.8392 - val_loss: 0.3611 - val_accuracy: 0.8862\nEpoch 136/300\n1/1 [==============================] - 0s 424ms/step - loss: 0.3866 - accuracy: 0.8462 - val_loss: 0.3613 - val_accuracy: 0.8862\nEpoch 137/300\n1/1 [==============================] - 0s 468ms/step - loss: 0.4233 - accuracy: 0.8357 - val_loss: 0.3620 - val_accuracy: 0.8862\nEpoch 138/300\n1/1 [==============================] - 1s 511ms/step - loss: 0.3583 - accuracy: 0.8462 - val_loss: 0.3403 - val_accuracy: 0.8862\nEpoch 139/300\n1/1 [==============================] - 0s 461ms/step - loss: 0.4146 - accuracy: 0.8287 - val_loss: 0.3478 - val_accuracy: 0.8862\nEpoch 140/300\n1/1 [==============================] - 0s 493ms/step - loss: 0.3743 - accuracy: 0.8357 - val_loss: 0.3614 - val_accuracy: 0.8862\nEpoch 141/300\n1/1 [==============================] - 0s 449ms/step - loss: 0.3922 - accuracy: 0.8357 - val_loss: 0.3604 - val_accuracy: 0.8862\nEpoch 142/300\n1/1 [==============================] - 0s 472ms/step - loss: 0.3854 - accuracy: 0.8427 - val_loss: 0.3454 - val_accuracy: 0.8862\nEpoch 143/300\n1/1 [==============================] - 0s 455ms/step - loss: 0.3840 - accuracy: 0.8217 - val_loss: 0.3407 - val_accuracy: 0.8862\nEpoch 144/300\n1/1 [==============================] - 0s 448ms/step - loss: 0.3781 - accuracy: 0.8252 - val_loss: 0.3534 - val_accuracy: 0.8862\nEpoch 145/300\n1/1 [==============================] - 0s 485ms/step - loss: 0.3907 - accuracy: 0.8252 - val_loss: 0.3707 - val_accuracy: 0.8618\nEpoch 146/300\n1/1 [==============================] - 0s 414ms/step - loss: 0.3562 - accuracy: 0.8462 - val_loss: 0.3567 - val_accuracy: 0.8699\nEpoch 147/300\n1/1 [==============================] - 0s 408ms/step - loss: 0.3680 - accuracy: 0.8252 - val_loss: 0.3633 - val_accuracy: 0.8699\nEpoch 148/300\n1/1 [==============================] - 0s 476ms/step - loss: 0.3727 - accuracy: 0.8427 - val_loss: 0.3460 - val_accuracy: 0.8862\nEpoch 149/300\n1/1 [==============================] - 0s 457ms/step - loss: 0.3467 - accuracy: 0.8462 - val_loss: 0.3635 - val_accuracy: 0.8618\nEpoch 150/300\n1/1 [==============================] - 1s 532ms/step - loss: 0.3754 - accuracy: 0.8427 - val_loss: 0.4198 - val_accuracy: 0.8211\nEpoch 151/300\n1/1 [==============================] - 1s 697ms/step - loss: 0.3579 - accuracy: 0.8462 - val_loss: 0.3479 - val_accuracy: 0.8862\nEpoch 152/300\n1/1 [==============================] - 0s 423ms/step - loss: 0.3840 - accuracy: 0.8357 - val_loss: 0.3574 - val_accuracy: 0.8699\nEpoch 153/300\n1/1 [==============================] - 0s 403ms/step - loss: 0.3366 - accuracy: 0.8566 - val_loss: 0.4014 - val_accuracy: 0.8537\nEpoch 154/300\n1/1 [==============================] - 0s 484ms/step - loss: 0.4006 - accuracy: 0.8217 - val_loss: 0.3858 - val_accuracy: 0.8537\nEpoch 155/300\n1/1 [==============================] - 0s 478ms/step - loss: 0.3768 - accuracy: 0.8322 - val_loss: 0.3483 - val_accuracy: 0.8780\nEpoch 156/300\n1/1 [==============================] - 0s 468ms/step - loss: 0.4012 - accuracy: 0.8322 - val_loss: 0.3456 - val_accuracy: 0.8862\nEpoch 157/300\n1/1 [==============================] - 0s 468ms/step - loss: 0.3734 - accuracy: 0.8287 - val_loss: 0.3557 - val_accuracy: 0.8780\nEpoch 158/300\n1/1 [==============================] - 0s 481ms/step - loss: 0.3617 - accuracy: 0.8462 - val_loss: 0.3595 - val_accuracy: 0.8780\nEpoch 159/300\n1/1 [==============================] - 0s 441ms/step - loss: 0.3558 - accuracy: 0.8462 - val_loss: 0.3596 - val_accuracy: 0.8780\nEpoch 160/300\n1/1 [==============================] - 0s 439ms/step - loss: 0.3619 - accuracy: 0.8462 - val_loss: 0.3594 - val_accuracy: 0.8780\nEpoch 161/300\n1/1 [==============================] - 0s 432ms/step - loss: 0.3776 - accuracy: 0.8427 - val_loss: 0.3642 - val_accuracy: 0.8699\nEpoch 162/300\n1/1 [==============================] - 0s 453ms/step - loss: 0.3810 - accuracy: 0.8392 - val_loss: 0.3747 - val_accuracy: 0.8618\nEpoch 163/300\n1/1 [==============================] - 0s 410ms/step - loss: 0.3538 - accuracy: 0.8566 - val_loss: 0.3850 - val_accuracy: 0.8618\nEpoch 164/300\n1/1 [==============================] - 1s 878ms/step - loss: 0.3337 - accuracy: 0.8497 - val_loss: 0.3832 - val_accuracy: 0.8618\nEpoch 165/300\n1/1 [==============================] - 1s 618ms/step - loss: 0.4125 - accuracy: 0.8252 - val_loss: 0.3935 - val_accuracy: 0.8455\nEpoch 166/300\n1/1 [==============================] - 0s 409ms/step - loss: 0.3644 - accuracy: 0.8566 - val_loss: 0.3824 - val_accuracy: 0.8537\nEpoch 167/300\n1/1 [==============================] - 0s 449ms/step - loss: 0.4126 - accuracy: 0.8357 - val_loss: 0.3885 - val_accuracy: 0.8455\nEpoch 168/300\n1/1 [==============================] - 0s 435ms/step - loss: 0.3453 - accuracy: 0.8531 - val_loss: 0.3854 - val_accuracy: 0.8537\nEpoch 169/300\n1/1 [==============================] - 0s 425ms/step - loss: 0.3744 - accuracy: 0.8427 - val_loss: 0.3757 - val_accuracy: 0.8537\nEpoch 170/300\n1/1 [==============================] - 0s 443ms/step - loss: 0.3684 - accuracy: 0.8392 - val_loss: 0.3820 - val_accuracy: 0.8537\nEpoch 171/300\n1/1 [==============================] - 0s 442ms/step - loss: 0.3833 - accuracy: 0.8531 - val_loss: 0.3877 - val_accuracy: 0.8537\nEpoch 172/300\n1/1 [==============================] - 0s 466ms/step - loss: 0.3567 - accuracy: 0.8462 - val_loss: 0.3765 - val_accuracy: 0.8618\nEpoch 173/300\n1/1 [==============================] - 1s 764ms/step - loss: 0.3643 - accuracy: 0.8322 - val_loss: 0.3639 - val_accuracy: 0.8780\nEpoch 174/300\n1/1 [==============================] - 1s 533ms/step - loss: 0.3663 - accuracy: 0.8357 - val_loss: 0.3616 - val_accuracy: 0.8780\nEpoch 175/300\n1/1 [==============================] - 0s 437ms/step - loss: 0.3591 - accuracy: 0.8497 - val_loss: 0.3710 - val_accuracy: 0.8618\nEpoch 176/300\n1/1 [==============================] - 0s 408ms/step - loss: 0.3731 - accuracy: 0.8357 - val_loss: 0.4008 - val_accuracy: 0.8537\nEpoch 177/300\n1/1 [==============================] - 0s 419ms/step - loss: 0.3643 - accuracy: 0.8322 - val_loss: 0.4194 - val_accuracy: 0.8455\nEpoch 178/300\n1/1 [==============================] - 0s 468ms/step - loss: 0.3413 - accuracy: 0.8497 - val_loss: 0.3868 - val_accuracy: 0.8537\nEpoch 179/300\n1/1 [==============================] - 0s 446ms/step - loss: 0.3553 - accuracy: 0.8392 - val_loss: 0.3712 - val_accuracy: 0.8780\nEpoch 180/300\n1/1 [==============================] - 0s 496ms/step - loss: 0.3567 - accuracy: 0.8357 - val_loss: 0.3763 - val_accuracy: 0.8780\nEpoch 181/300\n1/1 [==============================] - 0s 457ms/step - loss: 0.3850 - accuracy: 0.8566 - val_loss: 0.4551 - val_accuracy: 0.8130\nEpoch 182/300\n1/1 [==============================] - 0s 425ms/step - loss: 0.4103 - accuracy: 0.8077 - val_loss: 0.4182 - val_accuracy: 0.8293\nEpoch 183/300\n1/1 [==============================] - 0s 417ms/step - loss: 0.3556 - accuracy: 0.8427 - val_loss: 0.3715 - val_accuracy: 0.8780\nEpoch 184/300\n1/1 [==============================] - 0s 445ms/step - loss: 0.3628 - accuracy: 0.8566 - val_loss: 0.3678 - val_accuracy: 0.8780\nEpoch 185/300\n1/1 [==============================] - 0s 426ms/step - loss: 0.3782 - accuracy: 0.8427 - val_loss: 0.3964 - val_accuracy: 0.8537\nEpoch 186/300\n1/1 [==============================] - 0s 447ms/step - loss: 0.3592 - accuracy: 0.8497 - val_loss: 0.4434 - val_accuracy: 0.8130\nEpoch 187/300\n1/1 [==============================] - 0s 444ms/step - loss: 0.3716 - accuracy: 0.8357 - val_loss: 0.4202 - val_accuracy: 0.8293\nEpoch 188/300\n1/1 [==============================] - 0s 425ms/step - loss: 0.3531 - accuracy: 0.8671 - val_loss: 0.3802 - val_accuracy: 0.8618\nEpoch 189/300\n1/1 [==============================] - 0s 449ms/step - loss: 0.3696 - accuracy: 0.8357 - val_loss: 0.3655 - val_accuracy: 0.8699\nEpoch 190/300\n1/1 [==============================] - 1s 507ms/step - loss: 0.3450 - accuracy: 0.8427 - val_loss: 0.3676 - val_accuracy: 0.8699\nEpoch 191/300\n1/1 [==============================] - 0s 453ms/step - loss: 0.3891 - accuracy: 0.8427 - val_loss: 0.3930 - val_accuracy: 0.8537\nEpoch 192/300\n1/1 [==============================] - 0s 427ms/step - loss: 0.3576 - accuracy: 0.8427 - val_loss: 0.4106 - val_accuracy: 0.8374\nEpoch 193/300\n1/1 [==============================] - 0s 449ms/step - loss: 0.3693 - accuracy: 0.8392 - val_loss: 0.3991 - val_accuracy: 0.8455\nEpoch 194/300\n1/1 [==============================] - 0s 460ms/step - loss: 0.3550 - accuracy: 0.8287 - val_loss: 0.3719 - val_accuracy: 0.8618\nEpoch 195/300\n1/1 [==============================] - 0s 445ms/step - loss: 0.3656 - accuracy: 0.8357 - val_loss: 0.3639 - val_accuracy: 0.8699\nEpoch 196/300\n1/1 [==============================] - 1s 531ms/step - loss: 0.3473 - accuracy: 0.8392 - val_loss: 0.3679 - val_accuracy: 0.8618\nEpoch 197/300\n1/1 [==============================] - 1s 742ms/step - loss: 0.3531 - accuracy: 0.8427 - val_loss: 0.3932 - val_accuracy: 0.8618\nEpoch 198/300\n1/1 [==============================] - 0s 415ms/step - loss: 0.3260 - accuracy: 0.8601 - val_loss: 0.4349 - val_accuracy: 0.8049\nEpoch 199/300\n1/1 [==============================] - 0s 415ms/step - loss: 0.3903 - accuracy: 0.8497 - val_loss: 0.4155 - val_accuracy: 0.8211\nEpoch 200/300\n1/1 [==============================] - 0s 417ms/step - loss: 0.3660 - accuracy: 0.8287 - val_loss: 0.3702 - val_accuracy: 0.8618\nEpoch 201/300\n1/1 [==============================] - 0s 440ms/step - loss: 0.3227 - accuracy: 0.8601 - val_loss: 0.3646 - val_accuracy: 0.8780\nEpoch 202/300\n1/1 [==============================] - 0s 436ms/step - loss: 0.3824 - accuracy: 0.8671 - val_loss: 0.3710 - val_accuracy: 0.8618\nEpoch 203/300\n1/1 [==============================] - 0s 430ms/step - loss: 0.3609 - accuracy: 0.8462 - val_loss: 0.4123 - val_accuracy: 0.8374\nEpoch 204/300\n1/1 [==============================] - 0s 457ms/step - loss: 0.3657 - accuracy: 0.8566 - val_loss: 0.4269 - val_accuracy: 0.8211\nEpoch 205/300\n1/1 [==============================] - 0s 454ms/step - loss: 0.3398 - accuracy: 0.8601 - val_loss: 0.3933 - val_accuracy: 0.8537\nEpoch 206/300\n1/1 [==============================] - 0s 448ms/step - loss: 0.3466 - accuracy: 0.8427 - val_loss: 0.3681 - val_accuracy: 0.8618\nEpoch 207/300\n1/1 [==============================] - 0s 428ms/step - loss: 0.3637 - accuracy: 0.8392 - val_loss: 0.3634 - val_accuracy: 0.8618\nEpoch 208/300\n1/1 [==============================] - 0s 464ms/step - loss: 0.3313 - accuracy: 0.8427 - val_loss: 0.3694 - val_accuracy: 0.8618\nEpoch 209/300\n1/1 [==============================] - 0s 424ms/step - loss: 0.3402 - accuracy: 0.8601 - val_loss: 0.3851 - val_accuracy: 0.8537\nEpoch 210/300\n1/1 [==============================] - 0s 475ms/step - loss: 0.3010 - accuracy: 0.8706 - val_loss: 0.4033 - val_accuracy: 0.8374\nEpoch 211/300\n1/1 [==============================] - 0s 423ms/step - loss: 0.3308 - accuracy: 0.8497 - val_loss: 0.4114 - val_accuracy: 0.8293\nEpoch 212/300\n1/1 [==============================] - 0s 480ms/step - loss: 0.3293 - accuracy: 0.8357 - val_loss: 0.4096 - val_accuracy: 0.8293\nEpoch 213/300\n1/1 [==============================] - 0s 494ms/step - loss: 0.3534 - accuracy: 0.8462 - val_loss: 0.4068 - val_accuracy: 0.8374\nEpoch 214/300\n1/1 [==============================] - 0s 419ms/step - loss: 0.3438 - accuracy: 0.8531 - val_loss: 0.4264 - val_accuracy: 0.8049\nEpoch 215/300\n1/1 [==============================] - 0s 421ms/step - loss: 0.3411 - accuracy: 0.8252 - val_loss: 0.4287 - val_accuracy: 0.8211\nEpoch 216/300\n1/1 [==============================] - 0s 450ms/step - loss: 0.3284 - accuracy: 0.8636 - val_loss: 0.4071 - val_accuracy: 0.8455\nEpoch 217/300\n1/1 [==============================] - 0s 450ms/step - loss: 0.3347 - accuracy: 0.8741 - val_loss: 0.3877 - val_accuracy: 0.8455\nEpoch 218/300\n1/1 [==============================] - 0s 492ms/step - loss: 0.3224 - accuracy: 0.8671 - val_loss: 0.3927 - val_accuracy: 0.8455\nEpoch 219/300\n1/1 [==============================] - 0s 453ms/step - loss: 0.3213 - accuracy: 0.8601 - val_loss: 0.3987 - val_accuracy: 0.8374\nEpoch 220/300\n1/1 [==============================] - 1s 748ms/step - loss: 0.3132 - accuracy: 0.8706 - val_loss: 0.3764 - val_accuracy: 0.8618\nEpoch 221/300\n1/1 [==============================] - 0s 480ms/step - loss: 0.3383 - accuracy: 0.8531 - val_loss: 0.3663 - val_accuracy: 0.8618\nEpoch 222/300\n1/1 [==============================] - 0s 462ms/step - loss: 0.3320 - accuracy: 0.8636 - val_loss: 0.3659 - val_accuracy: 0.8618\nEpoch 223/300\n1/1 [==============================] - 0s 415ms/step - loss: 0.3659 - accuracy: 0.8497 - val_loss: 0.3890 - val_accuracy: 0.8293\nEpoch 224/300\n1/1 [==============================] - 0s 450ms/step - loss: 0.3233 - accuracy: 0.8531 - val_loss: 0.4129 - val_accuracy: 0.8211\nEpoch 225/300\n1/1 [==============================] - 1s 520ms/step - loss: 0.3698 - accuracy: 0.8462 - val_loss: 0.4203 - val_accuracy: 0.8293\nEpoch 226/300\n1/1 [==============================] - 0s 477ms/step - loss: 0.3205 - accuracy: 0.8566 - val_loss: 0.4034 - val_accuracy: 0.8293\nEpoch 227/300\n1/1 [==============================] - 0s 446ms/step - loss: 0.3355 - accuracy: 0.8392 - val_loss: 0.3852 - val_accuracy: 0.8537\nEpoch 228/300\n1/1 [==============================] - 0s 445ms/step - loss: 0.3100 - accuracy: 0.8462 - val_loss: 0.3753 - val_accuracy: 0.8537\nEpoch 229/300\n1/1 [==============================] - 0s 498ms/step - loss: 0.3249 - accuracy: 0.8531 - val_loss: 0.3771 - val_accuracy: 0.8537\nEpoch 230/300\n1/1 [==============================] - 0s 480ms/step - loss: 0.3361 - accuracy: 0.8671 - val_loss: 0.4028 - val_accuracy: 0.8293\nEpoch 231/300\n1/1 [==============================] - 0s 486ms/step - loss: 0.3684 - accuracy: 0.8392 - val_loss: 0.4382 - val_accuracy: 0.7967\nEpoch 232/300\n1/1 [==============================] - 1s 515ms/step - loss: 0.3364 - accuracy: 0.8392 - val_loss: 0.4304 - val_accuracy: 0.8049\nEpoch 233/300\n1/1 [==============================] - 1s 1s/step - loss: 0.2846 - accuracy: 0.8811 - val_loss: 0.4075 - val_accuracy: 0.8211\nEpoch 234/300\n1/1 [==============================] - 0s 415ms/step - loss: 0.3336 - accuracy: 0.8601 - val_loss: 0.3879 - val_accuracy: 0.8537\nEpoch 235/300\n1/1 [==============================] - 0s 452ms/step - loss: 0.3300 - accuracy: 0.8566 - val_loss: 0.3931 - val_accuracy: 0.8455\nEpoch 236/300\n1/1 [==============================] - 0s 456ms/step - loss: 0.3272 - accuracy: 0.8427 - val_loss: 0.3956 - val_accuracy: 0.8455\nEpoch 237/300\n1/1 [==============================] - 0s 450ms/step - loss: 0.3168 - accuracy: 0.8601 - val_loss: 0.4264 - val_accuracy: 0.8049\nEpoch 238/300\n1/1 [==============================] - 0s 458ms/step - loss: 0.3216 - accuracy: 0.8706 - val_loss: 0.4426 - val_accuracy: 0.8049\nEpoch 239/300\n1/1 [==============================] - 1s 501ms/step - loss: 0.3210 - accuracy: 0.8811 - val_loss: 0.4051 - val_accuracy: 0.8130\nEpoch 240/300\n1/1 [==============================] - 0s 426ms/step - loss: 0.3122 - accuracy: 0.8531 - val_loss: 0.3714 - val_accuracy: 0.8618\nEpoch 241/300\n1/1 [==============================] - 0s 419ms/step - loss: 0.3299 - accuracy: 0.8531 - val_loss: 0.3692 - val_accuracy: 0.8780\nEpoch 242/300\n1/1 [==============================] - 1s 766ms/step - loss: 0.3587 - accuracy: 0.8601 - val_loss: 0.3719 - val_accuracy: 0.8699\nEpoch 243/300\n1/1 [==============================] - 0s 451ms/step - loss: 0.3474 - accuracy: 0.8462 - val_loss: 0.3930 - val_accuracy: 0.8211\nEpoch 244/300\n1/1 [==============================] - 0s 420ms/step - loss: 0.3390 - accuracy: 0.8531 - val_loss: 0.4256 - val_accuracy: 0.7967\nEpoch 245/300\n1/1 [==============================] - 0s 428ms/step - loss: 0.2999 - accuracy: 0.8566 - val_loss: 0.4217 - val_accuracy: 0.7967\nEpoch 246/300\n1/1 [==============================] - 0s 477ms/step - loss: 0.3309 - accuracy: 0.8497 - val_loss: 0.3962 - val_accuracy: 0.8374\nEpoch 247/300\n1/1 [==============================] - 0s 439ms/step - loss: 0.2854 - accuracy: 0.8811 - val_loss: 0.3794 - val_accuracy: 0.8618\nEpoch 248/300\n1/1 [==============================] - 0s 458ms/step - loss: 0.3115 - accuracy: 0.8462 - val_loss: 0.3835 - val_accuracy: 0.8537\nEpoch 249/300\n1/1 [==============================] - 1s 502ms/step - loss: 0.3438 - accuracy: 0.8671 - val_loss: 0.3990 - val_accuracy: 0.8293\nEpoch 250/300\n1/1 [==============================] - 0s 433ms/step - loss: 0.2728 - accuracy: 0.8951 - val_loss: 0.4216 - val_accuracy: 0.8049\nEpoch 251/300\n1/1 [==============================] - 0s 434ms/step - loss: 0.3183 - accuracy: 0.8566 - val_loss: 0.4140 - val_accuracy: 0.8130\nEpoch 252/300\n1/1 [==============================] - 1s 515ms/step - loss: 0.2897 - accuracy: 0.8706 - val_loss: 0.4000 - val_accuracy: 0.8293\nEpoch 253/300\n1/1 [==============================] - 0s 468ms/step - loss: 0.3348 - accuracy: 0.8671 - val_loss: 0.3854 - val_accuracy: 0.8537\nEpoch 254/300\n1/1 [==============================] - 0s 444ms/step - loss: 0.2761 - accuracy: 0.8706 - val_loss: 0.3816 - val_accuracy: 0.8537\nEpoch 255/300\n1/1 [==============================] - 0s 435ms/step - loss: 0.3218 - accuracy: 0.8636 - val_loss: 0.3995 - val_accuracy: 0.8293\nEpoch 256/300\n1/1 [==============================] - 0s 416ms/step - loss: 0.2918 - accuracy: 0.8706 - val_loss: 0.4128 - val_accuracy: 0.8130\nEpoch 257/300\n1/1 [==============================] - 0s 435ms/step - loss: 0.3106 - accuracy: 0.8601 - val_loss: 0.4308 - val_accuracy: 0.7967\nEpoch 258/300\n1/1 [==============================] - 0s 442ms/step - loss: 0.3390 - accuracy: 0.8531 - val_loss: 0.3946 - val_accuracy: 0.8211\nEpoch 259/300\n1/1 [==============================] - 0s 416ms/step - loss: 0.2824 - accuracy: 0.8811 - val_loss: 0.3763 - val_accuracy: 0.8455\nEpoch 260/300\n1/1 [==============================] - 0s 485ms/step - loss: 0.2965 - accuracy: 0.8636 - val_loss: 0.3777 - val_accuracy: 0.8374\nEpoch 261/300\n1/1 [==============================] - 0s 447ms/step - loss: 0.3058 - accuracy: 0.8671 - val_loss: 0.3918 - val_accuracy: 0.8211\nEpoch 262/300\n1/1 [==============================] - 0s 415ms/step - loss: 0.3108 - accuracy: 0.8566 - val_loss: 0.4160 - val_accuracy: 0.7967\nEpoch 263/300\n1/1 [==============================] - 0s 451ms/step - loss: 0.3297 - accuracy: 0.8357 - val_loss: 0.4164 - val_accuracy: 0.8049\nEpoch 264/300\n1/1 [==============================] - 0s 432ms/step - loss: 0.3225 - accuracy: 0.8531 - val_loss: 0.3921 - val_accuracy: 0.8211\nEpoch 265/300\n1/1 [==============================] - 1s 514ms/step - loss: 0.3279 - accuracy: 0.8531 - val_loss: 0.3799 - val_accuracy: 0.8374\nEpoch 266/300\n1/1 [==============================] - 1s 692ms/step - loss: 0.2956 - accuracy: 0.8706 - val_loss: 0.3811 - val_accuracy: 0.8618\nEpoch 267/300\n1/1 [==============================] - 0s 442ms/step - loss: 0.3139 - accuracy: 0.8776 - val_loss: 0.3900 - val_accuracy: 0.8293\nEpoch 268/300\n1/1 [==============================] - 0s 427ms/step - loss: 0.2612 - accuracy: 0.8846 - val_loss: 0.4079 - val_accuracy: 0.8130\nEpoch 269/300\n1/1 [==============================] - 0s 412ms/step - loss: 0.3053 - accuracy: 0.8776 - val_loss: 0.4087 - val_accuracy: 0.8049\nEpoch 270/300\n1/1 [==============================] - 0s 412ms/step - loss: 0.2911 - accuracy: 0.8636 - val_loss: 0.3989 - val_accuracy: 0.8130\nEpoch 271/300\n1/1 [==============================] - 0s 444ms/step - loss: 0.2762 - accuracy: 0.8776 - val_loss: 0.3969 - val_accuracy: 0.8130\nEpoch 272/300\n1/1 [==============================] - 0s 422ms/step - loss: 0.3115 - accuracy: 0.8636 - val_loss: 0.4138 - val_accuracy: 0.8049\nEpoch 273/300\n1/1 [==============================] - 0s 456ms/step - loss: 0.3018 - accuracy: 0.8636 - val_loss: 0.4095 - val_accuracy: 0.8130\nEpoch 274/300\n1/1 [==============================] - 0s 428ms/step - loss: 0.2770 - accuracy: 0.8986 - val_loss: 0.4064 - val_accuracy: 0.8130\nEpoch 275/300\n1/1 [==============================] - 0s 434ms/step - loss: 0.3125 - accuracy: 0.8706 - val_loss: 0.3910 - val_accuracy: 0.8130\nEpoch 276/300\n1/1 [==============================] - 0s 470ms/step - loss: 0.3583 - accuracy: 0.8636 - val_loss: 0.3925 - val_accuracy: 0.8211\nEpoch 277/300\n1/1 [==============================] - 0s 465ms/step - loss: 0.3344 - accuracy: 0.8497 - val_loss: 0.3870 - val_accuracy: 0.8211\nEpoch 278/300\n1/1 [==============================] - 0s 434ms/step - loss: 0.2653 - accuracy: 0.8986 - val_loss: 0.3865 - val_accuracy: 0.8211\nEpoch 279/300\n1/1 [==============================] - 0s 423ms/step - loss: 0.2908 - accuracy: 0.8636 - val_loss: 0.3823 - val_accuracy: 0.8293\nEpoch 280/300\n1/1 [==============================] - 0s 451ms/step - loss: 0.2999 - accuracy: 0.8531 - val_loss: 0.3792 - val_accuracy: 0.8293\nEpoch 281/300\n1/1 [==============================] - 0s 458ms/step - loss: 0.3206 - accuracy: 0.8811 - val_loss: 0.3738 - val_accuracy: 0.8293\nEpoch 282/300\n1/1 [==============================] - 0s 444ms/step - loss: 0.3321 - accuracy: 0.8497 - val_loss: 0.3775 - val_accuracy: 0.8293\nEpoch 283/300\n1/1 [==============================] - 0s 425ms/step - loss: 0.2820 - accuracy: 0.8811 - val_loss: 0.3965 - val_accuracy: 0.8211\nEpoch 284/300\n1/1 [==============================] - 0s 455ms/step - loss: 0.3113 - accuracy: 0.8601 - val_loss: 0.4030 - val_accuracy: 0.8211\nEpoch 285/300\n1/1 [==============================] - 0s 471ms/step - loss: 0.2985 - accuracy: 0.8636 - val_loss: 0.3939 - val_accuracy: 0.8211\nEpoch 286/300\n1/1 [==============================] - 0s 406ms/step - loss: 0.3032 - accuracy: 0.8531 - val_loss: 0.3854 - val_accuracy: 0.8130\nEpoch 287/300\n1/1 [==============================] - 1s 509ms/step - loss: 0.2706 - accuracy: 0.8846 - val_loss: 0.3847 - val_accuracy: 0.8211\nEpoch 288/300\n1/1 [==============================] - 0s 418ms/step - loss: 0.3090 - accuracy: 0.8706 - val_loss: 0.3977 - val_accuracy: 0.8211\nEpoch 289/300\n1/1 [==============================] - 1s 543ms/step - loss: 0.2955 - accuracy: 0.8776 - val_loss: 0.4408 - val_accuracy: 0.7805\nEpoch 290/300\n1/1 [==============================] - 1s 745ms/step - loss: 0.2943 - accuracy: 0.8601 - val_loss: 0.4635 - val_accuracy: 0.7805\nEpoch 291/300\n1/1 [==============================] - 0s 414ms/step - loss: 0.2948 - accuracy: 0.8706 - val_loss: 0.4382 - val_accuracy: 0.7724\nEpoch 292/300\n1/1 [==============================] - 0s 463ms/step - loss: 0.2771 - accuracy: 0.8916 - val_loss: 0.4136 - val_accuracy: 0.7967\nEpoch 293/300\n1/1 [==============================] - 0s 444ms/step - loss: 0.2573 - accuracy: 0.9161 - val_loss: 0.4092 - val_accuracy: 0.8293\nEpoch 294/300\n1/1 [==============================] - 0s 445ms/step - loss: 0.3096 - accuracy: 0.8671 - val_loss: 0.4218 - val_accuracy: 0.8293\nEpoch 295/300\n1/1 [==============================] - 1s 506ms/step - loss: 0.2583 - accuracy: 0.8881 - val_loss: 0.4400 - val_accuracy: 0.7967\nEpoch 296/300\n1/1 [==============================] - 0s 425ms/step - loss: 0.2672 - accuracy: 0.8916 - val_loss: 0.4831 - val_accuracy: 0.7886\nEpoch 297/300\n1/1 [==============================] - 0s 436ms/step - loss: 0.3239 - accuracy: 0.8741 - val_loss: 0.4710 - val_accuracy: 0.7642\nEpoch 298/300\n1/1 [==============================] - 0s 466ms/step - loss: 0.2886 - accuracy: 0.8741 - val_loss: 0.4194 - val_accuracy: 0.8130\nEpoch 299/300\n1/1 [==============================] - 0s 459ms/step - loss: 0.2997 - accuracy: 0.8776 - val_loss: 0.3897 - val_accuracy: 0.8293\nEpoch 300/300\n1/1 [==============================] - 0s 443ms/step - loss: 0.3263 - accuracy: 0.8706 - val_loss: 0.3840 - val_accuracy: 0.8374\n","output_type":"stream"}]},{"cell_type":"code","source":"pred=(model.predict(X_unl) > 0.50).astype(\"int32\")","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:27:33.695756Z","iopub.execute_input":"2022-04-06T14:27:33.696070Z","iopub.status.idle":"2022-04-06T14:27:40.573512Z","shell.execute_reply.started":"2022-04-06T14:27:33.696014Z","shell.execute_reply":"2022-04-06T14:27:40.572788Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"X_train=np.concatenate((X_lvl,X_unl))\npred2=pred.flatten()\ny_unl = pd.Series(pred2)\ny_train=np.concatenate((y_lvl,y_unl))","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:27:40.574640Z","iopub.execute_input":"2022-04-06T14:27:40.576609Z","iopub.status.idle":"2022-04-06T14:27:40.581072Z","shell.execute_reply.started":"2022-04-06T14:27:40.576576Z","shell.execute_reply":"2022-04-06T14:27:40.580421Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_train, y_train, validation_split=0.3, epochs=100, batch_size=batch_size, shuffle=True, verbose = 1)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:27:40.582324Z","iopub.execute_input":"2022-04-06T14:27:40.582868Z","iopub.status.idle":"2022-04-06T14:36:18.672316Z","shell.execute_reply.started":"2022-04-06T14:27:40.582831Z","shell.execute_reply":"2022-04-06T14:36:18.671601Z"},"trusted":true},"execution_count":85,"outputs":[{"name":"stdout","text":"Epoch 1/100\n12/12 [==============================] - 5s 416ms/step - loss: 0.1448 - accuracy: 0.9583 - val_loss: 0.1048 - val_accuracy: 0.9707\nEpoch 2/100\n12/12 [==============================] - 5s 438ms/step - loss: 0.1254 - accuracy: 0.9644 - val_loss: 0.0841 - val_accuracy: 0.9707\nEpoch 3/100\n12/12 [==============================] - 5s 412ms/step - loss: 0.1149 - accuracy: 0.9646 - val_loss: 0.0773 - val_accuracy: 0.9703\nEpoch 4/100\n12/12 [==============================] - 5s 423ms/step - loss: 0.1144 - accuracy: 0.9660 - val_loss: 0.0752 - val_accuracy: 0.9707\nEpoch 5/100\n12/12 [==============================] - 5s 434ms/step - loss: 0.1133 - accuracy: 0.9651 - val_loss: 0.0761 - val_accuracy: 0.9711\nEpoch 6/100\n12/12 [==============================] - 5s 456ms/step - loss: 0.1141 - accuracy: 0.9651 - val_loss: 0.0747 - val_accuracy: 0.9707\nEpoch 7/100\n12/12 [==============================] - 5s 445ms/step - loss: 0.1106 - accuracy: 0.9655 - val_loss: 0.0763 - val_accuracy: 0.9707\nEpoch 8/100\n12/12 [==============================] - 5s 400ms/step - loss: 0.1043 - accuracy: 0.9667 - val_loss: 0.0747 - val_accuracy: 0.9707\nEpoch 9/100\n12/12 [==============================] - 5s 442ms/step - loss: 0.1050 - accuracy: 0.9670 - val_loss: 0.0726 - val_accuracy: 0.9707\nEpoch 10/100\n12/12 [==============================] - 5s 420ms/step - loss: 0.1078 - accuracy: 0.9656 - val_loss: 0.0729 - val_accuracy: 0.9707\nEpoch 11/100\n12/12 [==============================] - 5s 434ms/step - loss: 0.1071 - accuracy: 0.9669 - val_loss: 0.0758 - val_accuracy: 0.9703\nEpoch 12/100\n12/12 [==============================] - 5s 455ms/step - loss: 0.1023 - accuracy: 0.9670 - val_loss: 0.0651 - val_accuracy: 0.9723\nEpoch 13/100\n12/12 [==============================] - 5s 450ms/step - loss: 0.1061 - accuracy: 0.9663 - val_loss: 0.0725 - val_accuracy: 0.9707\nEpoch 14/100\n12/12 [==============================] - 5s 408ms/step - loss: 0.1095 - accuracy: 0.9662 - val_loss: 0.0695 - val_accuracy: 0.9711\nEpoch 15/100\n12/12 [==============================] - 5s 433ms/step - loss: 0.1080 - accuracy: 0.9667 - val_loss: 0.0707 - val_accuracy: 0.9715\nEpoch 16/100\n12/12 [==============================] - 5s 409ms/step - loss: 0.1001 - accuracy: 0.9677 - val_loss: 0.0681 - val_accuracy: 0.9711\nEpoch 17/100\n12/12 [==============================] - 5s 448ms/step - loss: 0.1043 - accuracy: 0.9677 - val_loss: 0.0697 - val_accuracy: 0.9740\nEpoch 18/100\n12/12 [==============================] - 6s 474ms/step - loss: 0.1068 - accuracy: 0.9667 - val_loss: 0.0716 - val_accuracy: 0.9731\nEpoch 19/100\n12/12 [==============================] - 5s 448ms/step - loss: 0.1070 - accuracy: 0.9656 - val_loss: 0.0719 - val_accuracy: 0.9707\nEpoch 20/100\n12/12 [==============================] - 5s 404ms/step - loss: 0.1002 - accuracy: 0.9681 - val_loss: 0.0672 - val_accuracy: 0.9731\nEpoch 21/100\n12/12 [==============================] - 5s 394ms/step - loss: 0.1083 - accuracy: 0.9663 - val_loss: 0.0708 - val_accuracy: 0.9711\nEpoch 22/100\n12/12 [==============================] - 5s 442ms/step - loss: 0.1033 - accuracy: 0.9674 - val_loss: 0.0796 - val_accuracy: 0.9703\nEpoch 23/100\n12/12 [==============================] - 5s 407ms/step - loss: 0.1065 - accuracy: 0.9669 - val_loss: 0.0749 - val_accuracy: 0.9707\nEpoch 24/100\n12/12 [==============================] - 5s 450ms/step - loss: 0.1010 - accuracy: 0.9684 - val_loss: 0.0734 - val_accuracy: 0.9711\nEpoch 25/100\n12/12 [==============================] - 6s 463ms/step - loss: 0.0956 - accuracy: 0.9690 - val_loss: 0.0678 - val_accuracy: 0.9723\nEpoch 26/100\n12/12 [==============================] - 5s 435ms/step - loss: 0.0995 - accuracy: 0.9690 - val_loss: 0.0709 - val_accuracy: 0.9711\nEpoch 27/100\n12/12 [==============================] - 5s 400ms/step - loss: 0.1013 - accuracy: 0.9677 - val_loss: 0.0692 - val_accuracy: 0.9715\nEpoch 28/100\n12/12 [==============================] - 5s 442ms/step - loss: 0.1028 - accuracy: 0.9676 - val_loss: 0.0680 - val_accuracy: 0.9719\nEpoch 29/100\n12/12 [==============================] - 5s 406ms/step - loss: 0.0995 - accuracy: 0.9674 - val_loss: 0.0728 - val_accuracy: 0.9711\nEpoch 30/100\n12/12 [==============================] - 6s 479ms/step - loss: 0.0988 - accuracy: 0.9679 - val_loss: 0.0678 - val_accuracy: 0.9727\nEpoch 31/100\n12/12 [==============================] - 6s 469ms/step - loss: 0.1051 - accuracy: 0.9667 - val_loss: 0.0704 - val_accuracy: 0.9711\nEpoch 32/100\n12/12 [==============================] - 5s 448ms/step - loss: 0.0987 - accuracy: 0.9669 - val_loss: 0.0723 - val_accuracy: 0.9711\nEpoch 33/100\n12/12 [==============================] - 5s 409ms/step - loss: 0.1015 - accuracy: 0.9676 - val_loss: 0.0696 - val_accuracy: 0.9736\nEpoch 34/100\n12/12 [==============================] - 5s 450ms/step - loss: 0.0982 - accuracy: 0.9693 - val_loss: 0.0738 - val_accuracy: 0.9711\nEpoch 35/100\n12/12 [==============================] - 5s 428ms/step - loss: 0.1008 - accuracy: 0.9690 - val_loss: 0.0762 - val_accuracy: 0.9703\nEpoch 36/100\n12/12 [==============================] - 5s 460ms/step - loss: 0.0973 - accuracy: 0.9683 - val_loss: 0.0759 - val_accuracy: 0.9711\nEpoch 37/100\n12/12 [==============================] - 6s 478ms/step - loss: 0.1020 - accuracy: 0.9698 - val_loss: 0.0763 - val_accuracy: 0.9703\nEpoch 38/100\n12/12 [==============================] - 5s 445ms/step - loss: 0.1040 - accuracy: 0.9686 - val_loss: 0.0815 - val_accuracy: 0.9703\nEpoch 39/100\n12/12 [==============================] - 5s 413ms/step - loss: 0.1052 - accuracy: 0.9665 - val_loss: 0.0758 - val_accuracy: 0.9719\nEpoch 40/100\n12/12 [==============================] - 5s 441ms/step - loss: 0.1040 - accuracy: 0.9681 - val_loss: 0.0715 - val_accuracy: 0.9715\nEpoch 41/100\n12/12 [==============================] - 5s 417ms/step - loss: 0.1017 - accuracy: 0.9691 - val_loss: 0.0758 - val_accuracy: 0.9719\nEpoch 42/100\n12/12 [==============================] - 5s 400ms/step - loss: 0.1008 - accuracy: 0.9688 - val_loss: 0.0707 - val_accuracy: 0.9723\nEpoch 43/100\n12/12 [==============================] - 6s 490ms/step - loss: 0.1008 - accuracy: 0.9676 - val_loss: 0.0741 - val_accuracy: 0.9707\nEpoch 44/100\n12/12 [==============================] - 5s 410ms/step - loss: 0.0962 - accuracy: 0.9686 - val_loss: 0.0754 - val_accuracy: 0.9707\nEpoch 45/100\n12/12 [==============================] - 5s 455ms/step - loss: 0.1019 - accuracy: 0.9681 - val_loss: 0.0754 - val_accuracy: 0.9707\nEpoch 46/100\n12/12 [==============================] - 5s 409ms/step - loss: 0.0978 - accuracy: 0.9690 - val_loss: 0.0772 - val_accuracy: 0.9707\nEpoch 47/100\n12/12 [==============================] - 5s 453ms/step - loss: 0.0996 - accuracy: 0.9684 - val_loss: 0.0707 - val_accuracy: 0.9731\nEpoch 48/100\n12/12 [==============================] - 5s 417ms/step - loss: 0.0968 - accuracy: 0.9677 - val_loss: 0.0679 - val_accuracy: 0.9727\nEpoch 49/100\n12/12 [==============================] - 5s 444ms/step - loss: 0.0993 - accuracy: 0.9693 - val_loss: 0.0728 - val_accuracy: 0.9715\nEpoch 50/100\n12/12 [==============================] - 6s 435ms/step - loss: 0.0962 - accuracy: 0.9700 - val_loss: 0.0701 - val_accuracy: 0.9723\nEpoch 51/100\n12/12 [==============================] - 5s 444ms/step - loss: 0.0994 - accuracy: 0.9672 - val_loss: 0.0669 - val_accuracy: 0.9744\nEpoch 52/100\n12/12 [==============================] - 5s 417ms/step - loss: 0.0965 - accuracy: 0.9712 - val_loss: 0.0779 - val_accuracy: 0.9707\nEpoch 53/100\n12/12 [==============================] - 5s 434ms/step - loss: 0.0917 - accuracy: 0.9693 - val_loss: 0.0724 - val_accuracy: 0.9715\nEpoch 54/100\n12/12 [==============================] - 5s 400ms/step - loss: 0.1038 - accuracy: 0.9648 - val_loss: 0.0791 - val_accuracy: 0.9711\nEpoch 55/100\n12/12 [==============================] - 5s 453ms/step - loss: 0.0971 - accuracy: 0.9705 - val_loss: 0.0671 - val_accuracy: 0.9727\nEpoch 56/100\n12/12 [==============================] - 5s 458ms/step - loss: 0.1006 - accuracy: 0.9670 - val_loss: 0.0752 - val_accuracy: 0.9703\nEpoch 57/100\n12/12 [==============================] - 5s 440ms/step - loss: 0.0941 - accuracy: 0.9674 - val_loss: 0.0726 - val_accuracy: 0.9711\nEpoch 58/100\n12/12 [==============================] - 5s 404ms/step - loss: 0.0968 - accuracy: 0.9679 - val_loss: 0.0671 - val_accuracy: 0.9731\nEpoch 59/100\n12/12 [==============================] - 5s 416ms/step - loss: 0.0973 - accuracy: 0.9686 - val_loss: 0.0691 - val_accuracy: 0.9723\nEpoch 60/100\n12/12 [==============================] - 5s 394ms/step - loss: 0.0978 - accuracy: 0.9693 - val_loss: 0.0718 - val_accuracy: 0.9715\nEpoch 61/100\n12/12 [==============================] - 5s 409ms/step - loss: 0.0981 - accuracy: 0.9677 - val_loss: 0.0699 - val_accuracy: 0.9740\nEpoch 62/100\n12/12 [==============================] - 6s 512ms/step - loss: 0.0964 - accuracy: 0.9696 - val_loss: 0.0700 - val_accuracy: 0.9727\nEpoch 63/100\n12/12 [==============================] - 5s 399ms/step - loss: 0.0942 - accuracy: 0.9688 - val_loss: 0.0671 - val_accuracy: 0.9727\nEpoch 64/100\n12/12 [==============================] - 5s 455ms/step - loss: 0.0981 - accuracy: 0.9676 - val_loss: 0.0798 - val_accuracy: 0.9711\nEpoch 65/100\n12/12 [==============================] - 5s 404ms/step - loss: 0.0997 - accuracy: 0.9683 - val_loss: 0.0727 - val_accuracy: 0.9723\nEpoch 66/100\n12/12 [==============================] - 5s 433ms/step - loss: 0.0951 - accuracy: 0.9683 - val_loss: 0.0723 - val_accuracy: 0.9711\nEpoch 67/100\n12/12 [==============================] - 5s 409ms/step - loss: 0.0987 - accuracy: 0.9681 - val_loss: 0.0715 - val_accuracy: 0.9715\nEpoch 68/100\n12/12 [==============================] - 6s 489ms/step - loss: 0.0943 - accuracy: 0.9717 - val_loss: 0.0712 - val_accuracy: 0.9715\nEpoch 69/100\n12/12 [==============================] - 5s 404ms/step - loss: 0.0954 - accuracy: 0.9714 - val_loss: 0.0704 - val_accuracy: 0.9731\nEpoch 70/100\n12/12 [==============================] - 5s 447ms/step - loss: 0.0934 - accuracy: 0.9674 - val_loss: 0.0803 - val_accuracy: 0.9703\nEpoch 71/100\n12/12 [==============================] - 5s 404ms/step - loss: 0.0998 - accuracy: 0.9691 - val_loss: 0.0754 - val_accuracy: 0.9703\nEpoch 72/100\n12/12 [==============================] - 5s 448ms/step - loss: 0.0995 - accuracy: 0.9683 - val_loss: 0.0726 - val_accuracy: 0.9715\nEpoch 73/100\n12/12 [==============================] - 5s 392ms/step - loss: 0.0919 - accuracy: 0.9684 - val_loss: 0.0700 - val_accuracy: 0.9731\nEpoch 74/100\n12/12 [==============================] - 5s 404ms/step - loss: 0.0967 - accuracy: 0.9695 - val_loss: 0.0699 - val_accuracy: 0.9727\nEpoch 75/100\n12/12 [==============================] - 6s 483ms/step - loss: 0.0989 - accuracy: 0.9690 - val_loss: 0.0732 - val_accuracy: 0.9707\nEpoch 76/100\n12/12 [==============================] - 5s 402ms/step - loss: 0.0973 - accuracy: 0.9669 - val_loss: 0.0749 - val_accuracy: 0.9711\nEpoch 77/100\n12/12 [==============================] - 6s 458ms/step - loss: 0.0957 - accuracy: 0.9696 - val_loss: 0.0694 - val_accuracy: 0.9723\nEpoch 78/100\n12/12 [==============================] - 5s 408ms/step - loss: 0.0883 - accuracy: 0.9724 - val_loss: 0.0715 - val_accuracy: 0.9715\nEpoch 79/100\n12/12 [==============================] - 5s 431ms/step - loss: 0.0953 - accuracy: 0.9686 - val_loss: 0.0717 - val_accuracy: 0.9719\nEpoch 80/100\n12/12 [==============================] - 5s 410ms/step - loss: 0.0971 - accuracy: 0.9688 - val_loss: 0.0834 - val_accuracy: 0.9703\nEpoch 81/100\n12/12 [==============================] - 5s 434ms/step - loss: 0.0955 - accuracy: 0.9696 - val_loss: 0.0688 - val_accuracy: 0.9723\nEpoch 82/100\n12/12 [==============================] - 5s 403ms/step - loss: 0.0977 - accuracy: 0.9702 - val_loss: 0.0769 - val_accuracy: 0.9707\nEpoch 83/100\n12/12 [==============================] - 6s 496ms/step - loss: 0.0870 - accuracy: 0.9698 - val_loss: 0.0710 - val_accuracy: 0.9723\nEpoch 84/100\n12/12 [==============================] - 5s 406ms/step - loss: 0.0859 - accuracy: 0.9726 - val_loss: 0.0656 - val_accuracy: 0.9740\nEpoch 85/100\n12/12 [==============================] - 5s 438ms/step - loss: 0.0958 - accuracy: 0.9660 - val_loss: 0.0713 - val_accuracy: 0.9723\nEpoch 86/100\n12/12 [==============================] - 5s 398ms/step - loss: 0.0898 - accuracy: 0.9712 - val_loss: 0.0714 - val_accuracy: 0.9723\nEpoch 87/100\n12/12 [==============================] - 5s 436ms/step - loss: 0.0928 - accuracy: 0.9688 - val_loss: 0.0747 - val_accuracy: 0.9711\nEpoch 88/100\n12/12 [==============================] - 5s 400ms/step - loss: 0.0899 - accuracy: 0.9702 - val_loss: 0.0692 - val_accuracy: 0.9740\nEpoch 89/100\n12/12 [==============================] - 6s 499ms/step - loss: 0.0965 - accuracy: 0.9690 - val_loss: 0.0776 - val_accuracy: 0.9707\nEpoch 90/100\n12/12 [==============================] - 5s 416ms/step - loss: 0.0974 - accuracy: 0.9684 - val_loss: 0.0817 - val_accuracy: 0.9711\nEpoch 91/100\n12/12 [==============================] - 5s 420ms/step - loss: 0.0977 - accuracy: 0.9693 - val_loss: 0.0773 - val_accuracy: 0.9707\nEpoch 92/100\n12/12 [==============================] - 5s 408ms/step - loss: 0.0945 - accuracy: 0.9695 - val_loss: 0.0741 - val_accuracy: 0.9715\nEpoch 93/100\n12/12 [==============================] - 5s 409ms/step - loss: 0.0922 - accuracy: 0.9700 - val_loss: 0.0702 - val_accuracy: 0.9719\nEpoch 94/100\n12/12 [==============================] - 5s 436ms/step - loss: 0.0906 - accuracy: 0.9705 - val_loss: 0.0720 - val_accuracy: 0.9723\nEpoch 95/100\n12/12 [==============================] - 5s 412ms/step - loss: 0.0978 - accuracy: 0.9674 - val_loss: 0.0729 - val_accuracy: 0.9719\nEpoch 96/100\n12/12 [==============================] - 6s 499ms/step - loss: 0.0947 - accuracy: 0.9703 - val_loss: 0.0720 - val_accuracy: 0.9731\nEpoch 97/100\n12/12 [==============================] - 5s 408ms/step - loss: 0.0919 - accuracy: 0.9700 - val_loss: 0.0674 - val_accuracy: 0.9736\nEpoch 98/100\n12/12 [==============================] - 5s 440ms/step - loss: 0.0956 - accuracy: 0.9691 - val_loss: 0.0735 - val_accuracy: 0.9727\nEpoch 99/100\n12/12 [==============================] - 5s 407ms/step - loss: 0.0895 - accuracy: 0.9719 - val_loss: 0.0718 - val_accuracy: 0.9719\nEpoch 100/100\n12/12 [==============================] - 5s 445ms/step - loss: 0.0864 - accuracy: 0.9717 - val_loss: 0.0677 - val_accuracy: 0.9719\n","output_type":"stream"}]},{"cell_type":"code","source":"test_res=(model.predict(X_test) > 0.5).astype(\"int32\")\ntest_res=test_res.flatten()\ny_test_c = y_test.to_numpy()","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:36:18.673818Z","iopub.execute_input":"2022-04-06T14:36:18.674181Z","iopub.status.idle":"2022-04-06T14:36:20.686063Z","shell.execute_reply.started":"2022-04-06T14:36:18.674143Z","shell.execute_reply":"2022-04-06T14:36:20.685347Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"count=0\nfor i in range(0,len(y_test_c)):\n  if(y_test_c[i]==test_res[i]):\n    count=count+1\nprint(count)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:36:20.687353Z","iopub.execute_input":"2022-04-06T14:36:20.687610Z","iopub.status.idle":"2022-04-06T14:36:20.696549Z","shell.execute_reply.started":"2022-04-06T14:36:20.687575Z","shell.execute_reply":"2022-04-06T14:36:20.695643Z"},"trusted":true},"execution_count":87,"outputs":[{"name":"stdout","text":"1697\n","output_type":"stream"}]},{"cell_type":"code","source":"accuracy_5_labled_bs_512=(count/len(test_res))*100","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:36:20.698081Z","iopub.execute_input":"2022-04-06T14:36:20.698341Z","iopub.status.idle":"2022-04-06T14:36:20.704110Z","shell.execute_reply.started":"2022-04-06T14:36:20.698307Z","shell.execute_reply":"2022-04-06T14:36:20.703256Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"print(\"Accuracy at 5% labled data and bs=512\",accuracy_5_labled_bs_512)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:36:20.705267Z","iopub.execute_input":"2022-04-06T14:36:20.705652Z","iopub.status.idle":"2022-04-06T14:36:20.715370Z","shell.execute_reply.started":"2022-04-06T14:36:20.705617Z","shell.execute_reply":"2022-04-06T14:36:20.714370Z"},"trusted":true},"execution_count":89,"outputs":[{"name":"stdout","text":"Accuracy at 5% labled data and bs=512 82.861328125\n","output_type":"stream"}]},{"cell_type":"code","source":"print(classification_report(y_test,test_res, target_names = ['Fake','Real']))","metadata":{"execution":{"iopub.status.busy":"2022-04-06T14:36:20.716519Z","iopub.execute_input":"2022-04-06T14:36:20.716784Z","iopub.status.idle":"2022-04-06T14:36:20.732209Z","shell.execute_reply.started":"2022-04-06T14:36:20.716716Z","shell.execute_reply":"2022-04-06T14:36:20.731400Z"},"trusted":true},"execution_count":90,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n        Fake       0.83      1.00      0.91      1700\n        Real       0.00      0.00      0.00       348\n\n    accuracy                           0.83      2048\n   macro avg       0.41      0.50      0.45      2048\nweighted avg       0.69      0.83      0.75      2048\n\n","output_type":"stream"}]}]}